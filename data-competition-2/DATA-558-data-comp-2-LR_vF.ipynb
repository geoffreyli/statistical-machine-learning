{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATA 558: Data Competition 2\n",
    "\n",
    "### Logistic Regression Models (Prompt from HW6)\n",
    "\n",
    "Geoffrey Li\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "import datetime\n",
    "import random\n",
    "from timeit import default_timer as timer\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1: Define Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computegrad(x, y, beta, lamb):\n",
    "    p = np.identity(len(x)) - np.diag(1/(1+np.exp(np.multiply(-y, x@beta))).reshape(1, -1)[0])\n",
    "    return -1/len(x) * x.T @ p @ y + 2*lamb*beta\n",
    "\n",
    "\n",
    "def computeobj(x, y, beta, lamb):\n",
    "    return 1/(len(x))*np.sum(np.log(1+np.exp(np.multiply(-y, x@beta)))) + lamb*np.sum(beta**2)\n",
    "\n",
    "\n",
    "def backtracking(curr_beta, lamb, x, y, eta_t=1, alpha=0.5, gamma=0.5, max_iter=100):\n",
    "    grad_curr_beta = computegrad(x, y, curr_beta, lamb)  # Gradient at current beta\n",
    "    norm_grad_curr_beta = np.sqrt(np.sum(grad_curr_beta ** 2))  # Norm of the gradient at current beta\n",
    "    found_eta_t = False\n",
    "    i = 0  # Iteration counter\n",
    "\n",
    "    while (found_eta_t is False and i < max_iter):\n",
    "        if (computeobj(x, y, curr_beta - eta_t * grad_curr_beta, lamb) <\n",
    "                computeobj(x, y, curr_beta, lamb) - alpha * eta_t * norm_grad_curr_beta ** 2):\n",
    "            found_eta_t = True\n",
    "        elif i == max_iter - 1:\n",
    "            raise ('Maximum number of iterations of backtracking reached')\n",
    "        else:\n",
    "            eta_t *= gamma\n",
    "            i += 1\n",
    "\n",
    "    return eta_t\n",
    "\n",
    "\n",
    "def initstepsize(x, lamb):\n",
    "    return 1/(max(np.linalg.eigh(1/len(x)*x.T@x)[0]) + lamb)\n",
    "\n",
    "\n",
    "def fastgradalgo(beta_init, lamb, x, y, theta_init, ss_init, targ_acc, max_iter=1000):\n",
    "    beta_values = list()\n",
    "    beta_values.append(beta_init)\n",
    "    theta = theta_init\n",
    "\n",
    "    grad_theta = computegrad(x, y, theta, lamb)\n",
    "    grad_beta = computegrad(x, y, beta_init, lamb)\n",
    "    norm_grad_beta = np.sqrt(np.sum(grad_beta ** 2))\n",
    "\n",
    "    tuned_step_size = ss_init\n",
    "\n",
    "    t = 0\n",
    "\n",
    "    while t < max_iter and norm_grad_beta > targ_acc:\n",
    "        grad_theta = computegrad(x, y, theta, lamb)\n",
    "\n",
    "        tuned_step_size = backtracking(beta_values[t], lamb, x, y, \n",
    "                                       eta_t=tuned_step_size, alpha=0.5, gamma=0.8, max_iter=20)\n",
    "\n",
    "        beta_values.append(theta - tuned_step_size * grad_theta)\n",
    "        theta = beta_values[t + 1] + (t / (t + 3)) * (beta_values[t + 1] - beta_values[t])\n",
    "\n",
    "        t += 1\n",
    "\n",
    "        grad_beta = computegrad(x, y, beta_values[t], lamb)\n",
    "        norm_grad_beta = np.sqrt(np.sum(grad_beta ** 2))\n",
    "\n",
    "    return beta_values\n",
    "\n",
    "\n",
    "def misclassificationerror(y, x, b):\n",
    "    return 1 - np.mean(\n",
    "        np.fromiter(map(lambda p: 1 if p >= 0.5 else -1, 1/(1+np.exp(-x@b))), \n",
    "                    dtype=np.int).reshape(-1,1) == y)\n",
    "\n",
    "def misclassificationerror_transform(y, x, b, pos_class, neg_class):\n",
    "    return 1 - np.mean(\n",
    "        np.fromiter(map(lambda p: pos_class if p >= 0.5 else neg_class, 1/(1+np.exp(-x@b))), \n",
    "                    dtype=np.int) == y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_transform(x, b, pos_class, neg_class):\n",
    "    return np.fromiter(map(lambda p: pos_class if p >= 0.5 else neg_class, 1/(1+np.exp(-x@b))), dtype=np.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mylogistic(x_train, y_train, init_eta, target_accuracy, lamb):\n",
    "    init_beta = np.zeros(x_train.shape[1])[:, np.newaxis]\n",
    "    init_theta = np.zeros(x_train.shape[1])[:, np.newaxis]\n",
    "    \n",
    "    # Run fast gradient and train classifier\n",
    "    beta_opt = fastgradalgo(init_beta, lamb, x_train, y_train, init_theta, init_eta, target_accuracy, max_iter=1000)\n",
    "    beta_opt_T = beta_opt[len(beta_opt)-1]\n",
    "    \n",
    "    return beta_opt_T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2: Loading and processing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.load(path+'train_features.npy')\n",
    "y_train = np.load(path+'train_labels.npy')\n",
    "\n",
    "X_val = np.load(path+'val_features.npy')\n",
    "y_val = np.load(path+'val_labels.npy')\n",
    "\n",
    "X_test = np.load(path+'test_features.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize the data\n",
    "scaler = preprocessing.StandardScaler().fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_val = scaler.transform(X_val)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subsets training and validation data based on input classes\n",
    "def subset_data(pos_class, neg_class, X_train, y_train, X_val=None, y_val=None):\n",
    "    train_subset = (y_train == pos_class) | (y_train == neg_class)\n",
    "    y_train_subset = y_train[np.where(train_subset)]\n",
    "    X_train_subset = X_train[train_subset.nonzero()[0]]\n",
    "    y_train_subset = np.fromiter(map(lambda n: 1 if n == pos_class else -1, y_train_subset), dtype=int).reshape(-1, 1)\n",
    "   \n",
    "    if X_val != None and y_val != None:\n",
    "        val_subset = (y_val == pos_class) | (y_val == neg_class)\n",
    "        y_val_subset = y_val[np.where(val_subset)]\n",
    "        X_val_subset = X_val[val_subset.nonzero()[0]]\n",
    "        y_val_subset = np.fromiter(map(lambda n: 1 if n == pos_class else -1, y_val_subset), dtype=int).reshape(-1, 1)\n",
    "        return X_train_subset, y_train_subset, X_val_subset, y_val_subset\n",
    "    \n",
    "    return X_train_subset, y_train_subset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Subset training and val data to class 1 as the positive class and class 0 as the negative class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_subset, y_train_subset, X_val_subset, y_val_subset = subset_data(1, 0, X_train, y_train, X_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3: Training model with default params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pick two classes of your choice from the dataset. Train an L2-regularized logistic regression classifier on the training set using your own fast gradient algorithm with $\\lambda = 1$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize and train classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize fast gradient\n",
    "init_beta = np.zeros(X_train_subset.shape[1])[:, np.newaxis]\n",
    "init_theta = np.zeros(X_train_subset.shape[1])[:, np.newaxis]\n",
    "lambduh = 1\n",
    "target_accuracy = 10**-3\n",
    "init_eta = initstepsize(X_train_subset, lambduh)\n",
    "\n",
    "# Train classifier\n",
    "beta_opt_naive = fastgradalgo(init_beta, lambduh, X_train_subset, y_train_subset, \n",
    "                              init_theta, init_eta, target_accuracy)\n",
    "\n",
    "beta_opt_naive_T = beta_opt_naive[len(beta_opt_naive)-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot, with different colors, the misclassification error on the training set and on the validation set vs iterations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot misclassification error\n",
    "plt.figure(figsize=(10,8))\n",
    "plt.plot(range(0,len(beta_opt_naive)),\n",
    "         list(map(lambda b: misclassificationerror_transform(y_train,X_train,b,1,0),beta_opt_naive)))\n",
    "plt.plot(range(0,len(beta_opt_naive)),\n",
    "         list(map(lambda b: misclassificationerror_transform(y_val,X_val,b,1,0),beta_opt_naive)))\n",
    "plt.legend(['Training data', 'Validation data'], loc='upper right')\n",
    "plt.title('Misclassification Error vs. Iteration t')\n",
    "plt.xlabel('Iteration t')\n",
    "plt.ylabel('Misclassification Error');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above plot, we see that the misclassification error on the training data and validation data quickly approach 0.98. This makes sense as we only chose 2 classes out of 100 for our model. At best, we should expect to predict correctly for 2 out of 100 classes, leading to a misclassification error of 0.98 (since we have a balanced multi-class classification task).\n",
    "\n",
    "For the training data, our model appears to stabilize at around 100 iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "preds\n",
       "0    5266\n",
       "1    4734\n",
       "dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_preds = predict_transform(X_test, beta_opt_naive_T, 1, 0)\n",
    "pd.DataFrame({'preds':y_preds}).groupby('preds').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({'Category':y_preds}).reset_index()\\\n",
    ".rename(columns={'index':'Id'}).to_csv('./comp2-subm_log-lam1.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Misclassification Error on Test Set (from Kaggle): 0.98"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4: Training model with opt $\\lambda$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the value of the regularization parameter $\\lambda$ using cross-validation; you may use scikit-learn’s built-in functions for this purpose. Train an L2-regularized logistic regression classifier on the training set using your own fast gradient algorithm with that value of $\\lambda$ found by cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/utils/validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.985"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "\n",
    "clf = LogisticRegressionCV(Cs=10, penalty='l2', fit_intercept=False, cv=5)\n",
    "clf.fit(X_train_subset, y_train_subset)\n",
    "clf.score(X_val_subset, y_val_subset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our L2-regularized logistic regression classifier appears to perform well on the 2-class subset, with a score of 0.985 (misclassification error of 0.015)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0099"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best C: 0.000774263682681127\n",
      "Best Lamba:  0.6457748325074419\n"
     ]
    }
   ],
   "source": [
    "print(\"Best C:\", clf.C_[0])\n",
    "print(\"Best Lamba: \",1/(clf.C_[0]*len(X_train_subset)*2))\n",
    "opt_lamb = 1/(clf.C_[0]*len(X_train_subset)*2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we train our L2-regularized logistic regression classifier with the optimal lambda we found above using sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize fast gradient\n",
    "init_beta = np.zeros(X_train_subset.shape[1])[:, np.newaxis]\n",
    "init_theta = np.zeros(X_train_subset.shape[1])[:, np.newaxis]\n",
    "lambduh = opt_lamb\n",
    "target_accuracy = 10**-3\n",
    "init_eta = initstepsize(X_train_subset, lambduh)\n",
    "\n",
    "# Train classifier\n",
    "beta_opt = fastgradalgo(init_beta, lambduh, X_train_subset, y_train_subset, \n",
    "                              init_theta, init_eta, target_accuracy)\n",
    "\n",
    "beta_opt_T = beta_opt[len(beta_opt)-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot misclassification error\n",
    "plt.figure(figsize=(10,8))\n",
    "plt.plot(range(0,len(beta_opt)),\n",
    "         list(map(lambda b: misclassificationerror_transform(y_train,X_train,b,1,0),beta_opt)))\n",
    "plt.plot(range(0,len(beta_opt)),\n",
    "         list(map(lambda b: misclassificationerror_transform(y_val,X_val,b,1,0),beta_opt)))\n",
    "plt.legend(['Training data', 'Validation data'], loc='upper right')\n",
    "plt.title('Misclassification Error vs. Iteration t')\n",
    "plt.xlabel('Iteration t')\n",
    "plt.ylabel('Misclassification Error');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see a similar story as above, our models approach a misclassifiaction error of approximately 0.98 at around 100 iterations (on the training data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds = predict_transform(X_test, beta_opt_T, 1, 0)\n",
    "pd.DataFrame({'preds':y_preds}).groupby('preds').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({'Category':y_preds}).reset_index()\\\n",
    ".rename(columns={'index':'Id'}).to_csv('./comp2-subm_log-lam-opt.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Misclassification Error on Test Set (from Kaggle): 0.98"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5: Training with pairwise Logistic Classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section I'm trying something beyond the scope of the prompt. Here I'm training 4,950 pariwise one-vs-one (OVO) L2-regularized logistic regression classifiers using my own home-grown classifier. Predictions are found using majority vote, with ties broken by random choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training (0,1) model...\n",
      "Training (0,2) model...\n",
      "Training (0,3) model...\n",
      "Training (0,4) model...\n",
      "Training (0,5) model...\n",
      "Training (0,6) model...\n",
      "Training (0,7) model...\n",
      "Training (0,8) model...\n",
      "Training (0,9) model...\n",
      "Training (0,10) model...\n",
      "Training (0,11) model...\n",
      "Training (0,12) model...\n",
      "Training (0,13) model...\n",
      "Training (0,14) model...\n",
      "Training (0,15) model...\n",
      "Training (0,16) model...\n",
      "Training (0,17) model...\n",
      "Training (0,18) model...\n",
      "Training (0,19) model...\n",
      "Training (0,20) model...\n",
      "Training (0,21) model...\n",
      "Training (0,22) model...\n",
      "Training (0,23) model...\n",
      "Training (0,24) model...\n",
      "Training (0,25) model...\n",
      "Training (0,26) model...\n",
      "Training (0,27) model...\n",
      "Training (0,28) model...\n",
      "Training (0,29) model...\n",
      "Training (0,30) model...\n",
      "Training (0,31) model...\n",
      "Training (0,32) model...\n",
      "Training (0,33) model...\n",
      "Training (0,34) model...\n",
      "Training (0,35) model...\n",
      "Training (0,36) model...\n",
      "Training (0,37) model...\n",
      "Training (0,38) model...\n",
      "Training (0,39) model...\n",
      "Training (0,40) model...\n",
      "Training (0,41) model...\n",
      "Training (0,42) model...\n",
      "Training (0,43) model...\n",
      "Training (0,44) model...\n",
      "Training (0,45) model...\n",
      "Training (0,46) model...\n",
      "Training (0,47) model...\n",
      "Training (0,48) model...\n",
      "Training (0,49) model...\n",
      "Training (0,50) model...\n",
      "Training (0,51) model...\n",
      "Training (0,52) model...\n",
      "Training (0,53) model...\n",
      "Training (0,54) model...\n",
      "Training (0,55) model...\n",
      "Training (0,56) model...\n",
      "Training (0,57) model...\n",
      "Training (0,58) model...\n",
      "Training (0,59) model...\n",
      "Training (0,60) model...\n",
      "Training (0,61) model...\n",
      "Training (0,62) model...\n",
      "Training (0,63) model...\n",
      "Training (0,64) model...\n",
      "Training (0,65) model...\n",
      "Training (0,66) model...\n",
      "Training (0,67) model...\n",
      "Training (0,68) model...\n",
      "Training (0,69) model...\n",
      "Training (0,70) model...\n",
      "Training (0,71) model...\n",
      "Training (0,72) model...\n",
      "Training (0,73) model...\n",
      "Training (0,74) model...\n",
      "Training (0,75) model...\n",
      "Training (0,76) model...\n",
      "Training (0,77) model...\n",
      "Training (0,78) model...\n",
      "Training (0,79) model...\n",
      "Training (0,80) model...\n",
      "Training (0,81) model...\n",
      "Training (0,82) model...\n",
      "Training (0,83) model...\n",
      "Training (0,84) model...\n",
      "Training (0,85) model...\n",
      "Training (0,86) model...\n",
      "Training (0,87) model...\n",
      "Training (0,88) model...\n",
      "Training (0,89) model...\n",
      "Training (0,90) model...\n",
      "Training (0,91) model...\n",
      "Training (0,92) model...\n",
      "Training (0,93) model...\n",
      "Training (0,94) model...\n",
      "Training (0,95) model...\n",
      "Training (0,96) model...\n",
      "Training (0,97) model...\n",
      "Training (0,98) model...\n",
      "Training (0,99) model...\n",
      "Training (1,2) model...\n",
      "Training (1,3) model...\n",
      "Training (1,4) model...\n",
      "Training (1,5) model...\n",
      "Training (1,6) model...\n",
      "Training (1,7) model...\n",
      "Training (1,8) model...\n",
      "Training (1,9) model...\n",
      "Training (1,10) model...\n",
      "Training (1,11) model...\n",
      "Training (1,12) model...\n",
      "Training (1,13) model...\n",
      "Training (1,14) model...\n",
      "Training (1,15) model...\n",
      "Training (1,16) model...\n",
      "Training (1,17) model...\n",
      "Training (1,18) model...\n",
      "Training (1,19) model...\n",
      "Training (1,20) model...\n",
      "Training (1,21) model...\n",
      "Training (1,22) model...\n",
      "Training (1,23) model...\n",
      "Training (1,24) model...\n",
      "Training (1,25) model...\n",
      "Training (1,26) model...\n",
      "Training (1,27) model...\n",
      "Training (1,28) model...\n",
      "Training (1,29) model...\n",
      "Training (1,30) model...\n",
      "Training (1,31) model...\n",
      "Training (1,32) model...\n",
      "Training (1,33) model...\n",
      "Training (1,34) model...\n",
      "Training (1,35) model...\n",
      "Training (1,36) model...\n",
      "Training (1,37) model...\n",
      "Training (1,38) model...\n",
      "Training (1,39) model...\n",
      "Training (1,40) model...\n",
      "Training (1,41) model...\n",
      "Training (1,42) model...\n",
      "Training (1,43) model...\n",
      "Training (1,44) model...\n",
      "Training (1,45) model...\n",
      "Training (1,46) model...\n",
      "Training (1,47) model...\n",
      "Training (1,48) model...\n",
      "Training (1,49) model...\n",
      "Training (1,50) model...\n",
      "Training (1,51) model...\n",
      "Training (1,52) model...\n",
      "Training (1,53) model...\n",
      "Training (1,54) model...\n",
      "Training (1,55) model...\n",
      "Training (1,56) model...\n",
      "Training (1,57) model...\n",
      "Training (1,58) model...\n",
      "Training (1,59) model...\n",
      "Training (1,60) model...\n",
      "Training (1,61) model...\n",
      "Training (1,62) model...\n",
      "Training (1,63) model...\n",
      "Training (1,64) model...\n",
      "Training (1,65) model...\n",
      "Training (1,66) model...\n",
      "Training (1,67) model...\n",
      "Training (1,68) model...\n",
      "Training (1,69) model...\n",
      "Training (1,70) model...\n",
      "Training (1,71) model...\n",
      "Training (1,72) model...\n",
      "Training (1,73) model...\n",
      "Training (1,74) model...\n",
      "Training (1,75) model...\n",
      "Training (1,76) model...\n",
      "Training (1,77) model...\n",
      "Training (1,78) model...\n",
      "Training (1,79) model...\n",
      "Training (1,80) model...\n",
      "Training (1,81) model...\n",
      "Training (1,82) model...\n",
      "Training (1,83) model...\n",
      "Training (1,84) model...\n",
      "Training (1,85) model...\n",
      "Training (1,86) model...\n",
      "Training (1,87) model...\n",
      "Training (1,88) model...\n",
      "Training (1,89) model...\n",
      "Training (1,90) model...\n",
      "Training (1,91) model...\n",
      "Training (1,92) model...\n",
      "Training (1,93) model...\n",
      "Training (1,94) model...\n",
      "Training (1,95) model...\n",
      "Training (1,96) model...\n",
      "Training (1,97) model...\n",
      "Training (1,98) model...\n",
      "Training (1,99) model...\n",
      "Training (2,3) model...\n",
      "Training (2,4) model...\n",
      "Training (2,5) model...\n",
      "Training (2,6) model...\n",
      "Training (2,7) model...\n",
      "Training (2,8) model...\n",
      "Training (2,9) model...\n",
      "Training (2,10) model...\n",
      "Training (2,11) model...\n",
      "Training (2,12) model...\n",
      "Training (2,13) model...\n",
      "Training (2,14) model...\n",
      "Training (2,15) model...\n",
      "Training (2,16) model...\n",
      "Training (2,17) model...\n",
      "Training (2,18) model...\n",
      "Training (2,19) model...\n",
      "Training (2,20) model...\n",
      "Training (2,21) model...\n",
      "Training (2,22) model...\n",
      "Training (2,23) model...\n",
      "Training (2,24) model...\n",
      "Training (2,25) model...\n",
      "Training (2,26) model...\n",
      "Training (2,27) model...\n",
      "Training (2,28) model...\n",
      "Training (2,29) model...\n",
      "Training (2,30) model...\n",
      "Training (2,31) model...\n",
      "Training (2,32) model...\n",
      "Training (2,33) model...\n",
      "Training (2,34) model...\n",
      "Training (2,35) model...\n",
      "Training (2,36) model...\n",
      "Training (2,37) model...\n",
      "Training (2,38) model...\n",
      "Training (2,39) model...\n",
      "Training (2,40) model...\n",
      "Training (2,41) model...\n",
      "Training (2,42) model...\n",
      "Training (2,43) model...\n",
      "Training (2,44) model...\n",
      "Training (2,45) model...\n",
      "Training (2,46) model...\n",
      "Training (2,47) model...\n",
      "Training (2,48) model...\n",
      "Training (2,49) model...\n",
      "Training (2,50) model...\n",
      "Training (2,51) model...\n",
      "Training (2,52) model...\n",
      "Training (2,53) model...\n",
      "Training (2,54) model...\n",
      "Training (2,55) model...\n",
      "Training (2,56) model...\n",
      "Training (2,57) model...\n",
      "Training (2,58) model...\n",
      "Training (2,59) model...\n",
      "Training (2,60) model...\n",
      "Training (2,61) model...\n",
      "Training (2,62) model...\n",
      "Training (2,63) model...\n",
      "Training (2,64) model...\n",
      "Training (2,65) model...\n",
      "Training (2,66) model...\n",
      "Training (2,67) model...\n",
      "Training (2,68) model...\n",
      "Training (2,69) model...\n",
      "Training (2,70) model...\n",
      "Training (2,71) model...\n",
      "Training (2,72) model...\n",
      "Training (2,73) model...\n",
      "Training (2,74) model...\n",
      "Training (2,75) model...\n",
      "Training (2,76) model...\n",
      "Training (2,77) model...\n",
      "Training (2,78) model...\n",
      "Training (2,79) model...\n",
      "Training (2,80) model...\n",
      "Training (2,81) model...\n",
      "Training (2,82) model...\n",
      "Training (2,83) model...\n",
      "Training (2,84) model...\n",
      "Training (2,85) model...\n",
      "Training (2,86) model...\n",
      "Training (2,87) model...\n",
      "Training (2,88) model...\n",
      "Training (2,89) model...\n",
      "Training (2,90) model...\n",
      "Training (2,91) model...\n",
      "Training (2,92) model...\n",
      "Training (2,93) model...\n",
      "Training (2,94) model...\n",
      "Training (2,95) model...\n",
      "Training (2,96) model...\n",
      "Training (2,97) model...\n",
      "Training (2,98) model...\n",
      "Training (2,99) model...\n",
      "Training (3,4) model...\n",
      "Training (3,5) model...\n",
      "Training (3,6) model...\n",
      "Training (3,7) model...\n",
      "Training (3,8) model...\n",
      "Training (3,9) model...\n",
      "Training (3,10) model...\n",
      "Training (3,11) model...\n",
      "Training (3,12) model...\n",
      "Training (3,13) model...\n",
      "Training (3,14) model...\n",
      "Training (3,15) model...\n",
      "Training (3,16) model...\n",
      "Training (3,17) model...\n",
      "Training (3,18) model...\n",
      "Training (3,19) model...\n",
      "Training (3,20) model...\n",
      "Training (3,21) model...\n",
      "Training (3,22) model...\n",
      "Training (3,23) model...\n",
      "Training (3,24) model...\n",
      "Training (3,25) model...\n",
      "Training (3,26) model...\n",
      "Training (3,27) model...\n",
      "Training (3,28) model...\n",
      "Training (3,29) model...\n",
      "Training (3,30) model...\n",
      "Training (3,31) model...\n",
      "Training (3,32) model...\n",
      "Training (3,33) model...\n",
      "Training (3,34) model...\n",
      "Training (3,35) model...\n",
      "Training (3,36) model...\n",
      "Training (3,37) model...\n",
      "Training (3,38) model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training (3,39) model...\n",
      "Training (3,40) model...\n",
      "Training (3,41) model...\n",
      "Training (3,42) model...\n",
      "Training (3,43) model...\n",
      "Training (3,44) model...\n",
      "Training (3,45) model...\n",
      "Training (3,46) model...\n",
      "Training (3,47) model...\n",
      "Training (3,48) model...\n",
      "Training (3,49) model...\n",
      "Training (3,50) model...\n",
      "Training (3,51) model...\n",
      "Training (3,52) model...\n",
      "Training (3,53) model...\n",
      "Training (3,54) model...\n",
      "Training (3,55) model...\n",
      "Training (3,56) model...\n",
      "Training (3,57) model...\n",
      "Training (3,58) model...\n",
      "Training (3,59) model...\n",
      "Training (3,60) model...\n",
      "Training (3,61) model...\n",
      "Training (3,62) model...\n",
      "Training (3,63) model...\n",
      "Training (3,64) model...\n",
      "Training (3,65) model...\n",
      "Training (3,66) model...\n",
      "Training (3,67) model...\n",
      "Training (3,68) model...\n",
      "Training (3,69) model...\n",
      "Training (3,70) model...\n",
      "Training (3,71) model...\n",
      "Training (3,72) model...\n",
      "Training (3,73) model...\n",
      "Training (3,74) model...\n",
      "Training (3,75) model...\n",
      "Training (3,76) model...\n",
      "Training (3,77) model...\n",
      "Training (3,78) model...\n",
      "Training (3,79) model...\n",
      "Training (3,80) model...\n",
      "Training (3,81) model...\n",
      "Training (3,82) model...\n",
      "Training (3,83) model...\n",
      "Training (3,84) model...\n",
      "Training (3,85) model...\n",
      "Training (3,86) model...\n",
      "Training (3,87) model...\n",
      "Training (3,88) model...\n",
      "Training (3,89) model...\n",
      "Training (3,90) model...\n",
      "Training (3,91) model...\n",
      "Training (3,92) model...\n",
      "Training (3,93) model...\n",
      "Training (3,94) model...\n",
      "Training (3,95) model...\n",
      "Training (3,96) model...\n",
      "Training (3,97) model...\n",
      "Training (3,98) model...\n",
      "Training (3,99) model...\n",
      "Training (4,5) model...\n",
      "Training (4,6) model...\n",
      "Training (4,7) model...\n",
      "Training (4,8) model...\n",
      "Training (4,9) model...\n",
      "Training (4,10) model...\n",
      "Training (4,11) model...\n",
      "Training (4,12) model...\n",
      "Training (4,13) model...\n",
      "Training (4,14) model...\n",
      "Training (4,15) model...\n",
      "Training (4,16) model...\n",
      "Training (4,17) model...\n",
      "Training (4,18) model...\n",
      "Training (4,19) model...\n",
      "Training (4,20) model...\n",
      "Training (4,21) model...\n",
      "Training (4,22) model...\n",
      "Training (4,23) model...\n",
      "Training (4,24) model...\n",
      "Training (4,25) model...\n",
      "Training (4,26) model...\n",
      "Training (4,27) model...\n",
      "Training (4,28) model...\n",
      "Training (4,29) model...\n",
      "Training (4,30) model...\n",
      "Training (4,31) model...\n",
      "Training (4,32) model...\n",
      "Training (4,33) model...\n",
      "Training (4,34) model...\n",
      "Training (4,35) model...\n",
      "Training (4,36) model...\n",
      "Training (4,37) model...\n",
      "Training (4,38) model...\n",
      "Training (4,39) model...\n",
      "Training (4,40) model...\n",
      "Training (4,41) model...\n",
      "Training (4,42) model...\n",
      "Training (4,43) model...\n",
      "Training (4,44) model...\n",
      "Training (4,45) model...\n",
      "Training (4,46) model...\n",
      "Training (4,47) model...\n",
      "Training (4,48) model...\n",
      "Training (4,49) model...\n",
      "Training (4,50) model...\n",
      "Training (4,51) model...\n",
      "Training (4,52) model...\n",
      "Training (4,53) model...\n",
      "Training (4,54) model...\n",
      "Training (4,55) model...\n",
      "Training (4,56) model...\n",
      "Training (4,57) model...\n",
      "Training (4,58) model...\n",
      "Training (4,59) model...\n",
      "Training (4,60) model...\n",
      "Training (4,61) model...\n"
     ]
    }
   ],
   "source": [
    "# Initialize fast gradient\n",
    "target_accuracy = 10**-2\n",
    "opt_lamb_pairwise = list()\n",
    "classes = 100\n",
    "\n",
    "# Store trained beta values in a list of length 100, one entry for each pairwise classifier\n",
    "pairwise_clfs = dict()\n",
    "\n",
    "for i in range(classes):\n",
    "    for j in range(i+1, classes):\n",
    "        print('Training ('+str(i)+','+str(j)+') model...')\n",
    "        X_train_subset, y_train_subset, X_val_subset, y_val_subset = subset_data(i, j, X_train, y_train, X_val, y_val)\n",
    "        init_beta = np.zeros(X_train_subset.shape[1])[:, np.newaxis]\n",
    "        init_theta = np.zeros(X_train_subset.shape[1])[:, np.newaxis]\n",
    "        \n",
    "        # Run CV to find optimal lambda\n",
    "#         clf = LogisticRegressionCV(Cs=10, penalty='l2', fit_intercept=False, cv=5)\n",
    "#         clf.fit(X_train_subset, y_train_subset)\n",
    "#         opt_lamb = 1/(clf.C_[0]*len(X_train_subset)*2)\n",
    "        opt_lamb = 1\n",
    "        \n",
    "        \n",
    "        opt_lamb_pairwise.append(opt_lamb)\n",
    "        init_eta = initstepsize(X_train_subset, opt_lamb)\n",
    "        \n",
    "        # Train classifier\n",
    "        beta_opt_pairwise = fastgradalgo(init_beta, opt_lamb, X_train_subset, y_train_subset, \n",
    "                                         init_theta, init_eta, target_accuracy, max_iter=20)\n",
    "        \n",
    "        pairwise_clfs[(i, j)] = beta_opt_pairwise[len(beta_opt_pairwise)-1]\n",
    "\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def majority_vote(array):\n",
    "    most = max(list(map(array.count, array)))\n",
    "    return random.choice(list(set(filter(lambda x: array.count(x) == most, array))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_pairwise(betas, x):\n",
    "    preds = list(map(lambda p: p[0] if 1/(1+np.exp(-x@betas[p])) > 0.5 else p[1], betas))\n",
    "    return majority_vote(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation set predictions\n",
    "y_val_preds = list(map(lambda n: predict_pairwise(pairwise_clfs, n), X_val))\n",
    "\n",
    "# Misclassification Error Rate for Validation Set\n",
    "1 - np.mean(y_val_preds == y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test set predictions\n",
    "y_test_preds = list(map(lambda n: predict_pairwise(pairwise_clfs, n), X_test))\n",
    "\n",
    "# Write to CSV for Kaggle submission\n",
    "pd.DataFrame({'Category':y_test_preds}).reset_index()\\\n",
    "             .rename(columns={'index':'Id'}).to_csv('./comp2-subm_log-pairwise.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Misclassification Error on Test Set (from Kaggle): 0.45 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comments: not bad! Our accuracy was 0.55. Let's try with sklearn, since training time took awhile and sklearn appears to be slightly more optimized."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pairwise Predictions with sklearn.linear_model.LogisticRegressionCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section I'm training 4,950 pairwise one-vs-one (OVO) L2-regularized logistic regression classifiers with optimal lambdas found using cross-validation. Predictions are found using majority vote, with ties broken by random choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model 0: (0,1) ...\n",
      "2.269513574981829\n",
      "Training model 0: (0,2) ...\n",
      "2.143749234994175\n",
      "Training model 0: (0,3) ...\n",
      "1.7185978879861068\n",
      "Training model 0: (0,4) ...\n",
      "1.5827356700028758\n",
      "Training model 0: (0,5) ...\n",
      "1.4544363610039\n",
      "Training model 0: (0,6) ...\n",
      "2.048685435001971\n",
      "Training model 0: (0,7) ...\n",
      "1.4625382960075513\n",
      "Training model 0: (0,8) ...\n",
      "1.7417152500129305\n",
      "Training model 0: (0,9) ...\n",
      "1.4613639099989086\n",
      "Training model 0: (0,10) ...\n",
      "1.3737677090102807\n",
      "Training model 0: (0,11) ...\n",
      "1.4739647739916109\n",
      "Training model 0: (0,12) ...\n",
      "1.2806072810199112\n",
      "Training model 0: (0,13) ...\n",
      "1.8573483219952323\n",
      "Training model 0: (0,14) ...\n",
      "1.470893492019968\n",
      "Training model 0: (0,15) ...\n",
      "1.74674628500361\n",
      "Training model 0: (0,16) ...\n",
      "1.588332448998699\n",
      "Training model 0: (0,17) ...\n",
      "1.4057825930067338\n",
      "Training model 0: (0,18) ...\n",
      "1.3344219439895824\n",
      "Training model 0: (0,19) ...\n",
      "1.3688303510134574\n",
      "Training model 0: (0,20) ...\n",
      "1.615255647979211\n",
      "Training model 0: (0,21) ...\n",
      "1.3663102469872683\n",
      "Training model 0: (0,22) ...\n",
      "1.4224291999998968\n",
      "Training model 0: (0,23) ...\n",
      "1.5005693680141121\n",
      "Training model 0: (0,24) ...\n",
      "1.2638623910024762\n",
      "Training model 0: (0,25) ...\n",
      "1.3349051809927914\n",
      "Training model 0: (0,26) ...\n",
      "1.8093160860007629\n",
      "Training model 0: (0,27) ...\n",
      "1.6850253140146378\n",
      "Training model 0: (0,28) ...\n",
      "1.7105576460016891\n",
      "Training model 0: (0,29) ...\n",
      "1.9013672879955266\n",
      "Training model 0: (0,30) ...\n",
      "1.7414966709911823\n",
      "Training model 0: (0,31) ...\n",
      "2.3467040410032496\n",
      "Training model 0: (0,32) ...\n",
      "1.897230884002056\n",
      "Training model 0: (0,33) ...\n",
      "2.061951973999385\n",
      "Training model 0: (0,34) ...\n",
      "1.8204800410021562\n",
      "Training model 0: (0,35) ...\n",
      "1.9432380719808862\n",
      "Training model 0: (0,36) ...\n",
      "1.9537798470119014\n",
      "Training model 0: (0,37) ...\n",
      "1.7508597080013715\n",
      "Training model 0: (0,38) ...\n",
      "1.5082561080052983\n",
      "Training model 0: (0,39) ...\n",
      "1.910042400995735\n",
      "Training model 0: (0,40) ...\n",
      "1.6452788629976567\n",
      "Training model 0: (0,41) ...\n",
      "1.7327549129840918\n",
      "Training model 0: (0,42) ...\n",
      "1.4853271309984848\n",
      "Training model 0: (0,43) ...\n",
      "1.9119867609988432\n",
      "Training model 0: (0,44) ...\n",
      "1.590856495022308\n",
      "Training model 0: (0,45) ...\n",
      "1.5308531890041195\n",
      "Training model 0: (0,46) ...\n",
      "1.4171972850163002\n",
      "Training model 0: (0,47) ...\n",
      "1.6547434410022106\n",
      "Training model 0: (0,48) ...\n",
      "1.4893610479775816\n",
      "Training model 0: (0,49) ...\n",
      "1.6342573799774982\n",
      "Training model 0: (0,50) ...\n",
      "1.8706221540051047\n",
      "Training model 0: (0,51) ...\n",
      "1.7335478370077908\n",
      "Training model 0: (0,52) ...\n",
      "1.783856055000797\n",
      "Training model 0: (0,53) ...\n",
      "1.8277680960018188\n",
      "Training model 0: (0,54) ...\n",
      "1.458695434994297\n",
      "Training model 0: (0,55) ...\n",
      "1.641948639007751\n",
      "Training model 0: (0,56) ...\n",
      "1.7202311269938946\n",
      "Training model 0: (0,57) ...\n",
      "1.7831936349975877\n",
      "Training model 0: (0,58) ...\n",
      "1.7782437629939523\n",
      "Training model 0: (0,59) ...\n",
      "2.0879081939929165\n",
      "Training model 0: (0,60) ...\n",
      "2.0411788689962123\n",
      "Training model 0: (0,61) ...\n",
      "1.873868405004032\n",
      "Training model 0: (0,62) ...\n",
      "1.7794360510015395\n",
      "Training model 0: (0,63) ...\n",
      "1.9390112530090846\n",
      "Training model 0: (0,64) ...\n",
      "1.7281688310031313\n",
      "Training model 0: (0,65) ...\n",
      "1.6056956840038765\n",
      "Training model 0: (0,66) ...\n",
      "1.7454802439897321\n",
      "Training model 0: (0,67) ...\n",
      "1.5308787979884073\n",
      "Training model 0: (0,68) ...\n",
      "1.3777954899996985\n",
      "Training model 0: (0,69) ...\n",
      "1.8527970200229902\n",
      "Training model 0: (0,70) ...\n",
      "1.6710689419996925\n",
      "Training model 0: (0,71) ...\n",
      "2.6103336150117684\n",
      "Training model 0: (0,72) ...\n",
      "1.4154359640087932\n",
      "Training model 0: (0,73) ...\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "\n",
    "maxiter = 1000\n",
    "target_accuracy = 1e-5\n",
    "classes = 100\n",
    "pairwise_clfs_sk = dict()\n",
    "opt_lamb_pairwise_sk = dict()\n",
    "t = 0\n",
    "\n",
    "for i in range(classes):\n",
    "    for j in range(i+1, classes):\n",
    "        print('Training model '+str(t)+': ('+str(i)+','+str(j)+') ...')\n",
    "        start = timer()\n",
    "        X_train_subset, y_train_subset = subset_data(i, j, X_train, y_train)\n",
    "        \n",
    "        clf = LogisticRegressionCV(penalty='l2', Cs=10, cv=5, \n",
    "                                   fit_intercept=False, max_iter=maxiter, tol=target_accuracy)\n",
    "        clf.fit(X_train_subset, y_train_subset.squeeze())\n",
    "        \n",
    "        pairwise_clfs_sk[(i, j)] = clf\n",
    "        opt_lamb_pairwise_sk[(i, j)] = clf.C_[0]\n",
    "        \n",
    "        end = timer()\n",
    "        print(end - start)\n",
    "        t += 1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_pairwise_sk(clfs, x):\n",
    "    preds = list(map(lambda c: c[0] if clfs[c].predict(x.reshape(1, -1)) == 1 else c[1], clfs))\n",
    "    return majority_vote(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation set predictions\n",
    "y_val_preds_sk = list(map(lambda n: predict_pairwise_sk(pairwise_clfs_sk, n), X_val))\n",
    "\n",
    "# Misclassification Error Rate for Validation Set\n",
    "1 - np.mean(y_val_preds_sk == y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test set predictions\n",
    "y_test_preds_sk = list(map(lambda n: predict_pairwise_sk(pairwise_clfs_sk, n), X_test))\n",
    "\n",
    "# Write to CSV for Kaggle submission\n",
    "pd.DataFrame({'Category':y_test_preds_sk}).reset_index()\\\n",
    "             .rename(columns={'index':'Id'}).to_csv('./comp2-subm_log-pairwise-sk.csv', index=False)\n",
    "\n",
    "# Write trained models to pickle file\n",
    "pickle.dump( pairwise_clfs_sk, open( \"pairwise_clfs_sk.p\", \"wb\" ) )\n",
    "\n",
    "# Write optimal lambdas to pickle file\n",
    "pickle.dump( opt_lamb_pairwise_sk, open( \"opt_lamb_pairwise_sk.p\", \"wb\" ) )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Misclassification Error on Test Set (from Kaggle): 0.429"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With an accuracy of 0.57099 on Kaggle, I'm pleased with the result! It looks like the optimal lambdas and lowered tolerance resulted in a few more percentage points of performance."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
