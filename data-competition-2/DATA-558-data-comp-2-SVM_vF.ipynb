{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATA 558: Data Competition 2\n",
    "\n",
    "### SVM Models (from HW7 Prompt)\n",
    "\n",
    "Geoffrey Li\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "import datetime\n",
    "import random\n",
    "from timeit import default_timer as timer\n",
    "import pickle\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1: Define Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad(alpha, K, y, lam):\n",
    "    return -2*np.mean(np.maximum(0, 1-y*K.dot(alpha))*y*K, axis=1) + 2*lam*K.dot(alpha)\n",
    "\n",
    "def obj(alpha, K, y, lam):\n",
    "    return np.mean(np.maximum(0, 1-y*K.dot(alpha))**2) + lam*alpha.dot(K).dot(alpha)\n",
    "\n",
    "def computegram(X, kernel, **kwargs):\n",
    "    n = len(X)\n",
    "    K = np.zeros((n, n))\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            if 'power' in kwargs:\n",
    "                K[i, j] = kernel(X[i], X[j], kwargs['power'])\n",
    "            elif 'sigma' in kwargs:\n",
    "                K[i, j] = kernel(X[i], X[j], kwargs['sigma'])\n",
    "    \n",
    "    return K\n",
    "\n",
    "\n",
    "def bt_line_search(beta, K, y, lam, eta=1, alpha=0.5, betaparam=0.5, maxiter=10):\n",
    "    grad_beta = grad(beta, K, y, lam)\n",
    "    norm_grad_beta = np.linalg.norm(grad_beta)\n",
    "    found_eta = 0\n",
    "    iter = 0\n",
    "    while found_eta == 0 and iter < maxiter:\n",
    "        if obj(beta - eta * grad_beta, K, y, lam) < \\\n",
    "                        obj(beta, K, y, lam) - alpha * eta * norm_grad_beta ** 2:\n",
    "            found_eta = 1\n",
    "        elif iter == maxiter-1:\n",
    "#             print('Max number of iterations of backtracking line search reached')\n",
    "            break\n",
    "        else:\n",
    "            eta *= betaparam\n",
    "            iter += 1\n",
    "    return eta\n",
    "\n",
    "def fastgradalgo(beta_init, theta_init, K, y, lam, eta_init, maxiter, eps=1e-5):\n",
    "    beta = beta_init\n",
    "    theta = theta_init\n",
    "    eta = eta_init\n",
    "    grad_theta = grad(theta, K, y, lam)\n",
    "    grad_beta = grad(beta, K, y, lam)\n",
    "    grad_beta_norm = np.linalg.norm(grad_beta)\n",
    "    iter = 0\n",
    "    beta_list = list()\n",
    "    while iter < maxiter and grad_beta_norm > eps:\n",
    "#         print('Fastgradalgo Iteration:', iter)\n",
    "        \n",
    "        eta = bt_line_search(theta, K, y, lam, eta=eta)\n",
    "#         print('Eta:', eta)\n",
    "        \n",
    "        beta_new = theta - eta*grad_theta\n",
    "        theta = beta_new + iter/(iter+3)*(beta_new-beta)\n",
    "        \n",
    "        grad_theta = grad(theta, K, y, lam)\n",
    "        grad_beta = grad(beta, K, y, lam)        \n",
    "        beta = beta_new.copy()\n",
    "        \n",
    "        iter += 1\n",
    "        if iter % 1 == 0:\n",
    "            beta_list.append(beta_new)\n",
    "        \n",
    "        grad_beta_norm = np.linalg.norm(grad_beta)\n",
    "#         print('Norm of Gradient at Current Iteration:', grad_beta_norm)\n",
    "#         print('Objective Value at Current Iteration:', obj(beta, K, y, lam))\n",
    "        \n",
    "    return beta_list\n",
    "\n",
    "def initstepsize(K, lam):\n",
    "    n = len(K)\n",
    "    return 1 / scipy.linalg.eigh(2 / n * np.dot(K, K) + 2 * lam * K, eigvals=(n - 1, n - 1), eigvals_only=True)[0]\n",
    "\n",
    "\n",
    "def gram_linear(X, Z=None):\n",
    "    return X@Z.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def misclassification_error(beta, X_train, X_test, y_test, kernel, **kwargs):\n",
    "    n_test = len(y_test)\n",
    "    y_pred = np.zeros(n_test)\n",
    "    y_vals = np.zeros(n_test)\n",
    "    for i in range(n_test):\n",
    "        if 'sigma' in kwargs:\n",
    "            sigma = kwargs['sigma']\n",
    "            y_vals[i] = np.dot(kernel(X_train, X_test[i, :].reshape(1, -1), sigma).reshape(-1), beta)\n",
    "        else:\n",
    "            y_vals[i] = np.dot(kernel(X_train, X_test[i, :]).reshape(-1), beta)\n",
    "    y_pred = np.sign(y_vals)\n",
    "    return np.mean(y_pred != y_test), y_vals "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mysvm(K, y, lam, eta_init, eps=1e-5):\n",
    "    alpha_init = np.zeros(len(K))[:, np.newaxis]\n",
    "    theta_init = np.zeros(len(K))[:, np.newaxis]\n",
    "    \n",
    "    opt_alpha = fastgradalgo(alpha_init, theta_init, K, y, lam, eta_init, maxiter=1000, eps=1e-3)    \n",
    "    \n",
    "    return opt_alpha"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2: Loading and processing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_unstd = np.load(path+'train_features.npy')\n",
    "y_train = np.load(path+'train_labels.npy')\n",
    "\n",
    "X_val_unstd = np.load(path+'val_features.npy')\n",
    "y_val = np.load(path+'val_labels.npy')\n",
    "\n",
    "X_test_unstd = np.load(path+'test_features.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize the data\n",
    "scaler = preprocessing.StandardScaler().fit(X_train_unstd)\n",
    "X_train = scaler.transform(X_train_unstd)\n",
    "X_val = scaler.transform(X_val_unstd)\n",
    "X_test = scaler.transform(X_test_unstd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subsets training and validation data based on input classes\n",
    "def subset_data(pos_class, neg_class, X_train, y_train, X_val=None, y_val=None):\n",
    "    train_subset = (np.isin(y_train, pos_class)) | (np.isin(y_train, neg_class))\n",
    "    y_train_subset = y_train[np.where(train_subset)]\n",
    "    X_train_subset = X_train[train_subset.nonzero()[0]]\n",
    "    if type(pos_class) == list:\n",
    "        y_train_subset = \\\n",
    "            np.fromiter(map(lambda n: 1 if n in pos_class else -1, y_train_subset), dtype=int).reshape(-1, 1)\n",
    "    else:\n",
    "        y_train_subset = \\\n",
    "            np.fromiter(map(lambda n: 1 if n == pos_class else -1, y_train_subset), dtype=int).reshape(-1, 1)\n",
    "   \n",
    "    if X_val is not None and y_val is not None:\n",
    "        val_subset = (np.isin(y_val, pos_class)) | (np.isin(y_val, neg_class))\n",
    "        y_val_subset = y_val[np.where(val_subset)]\n",
    "        X_val_subset = X_val[val_subset.nonzero()[0]]\n",
    "        if type(pos_class) == list:\n",
    "            y_val_subset = \\\n",
    "                np.fromiter(map(lambda n: 1 if n in pos_class else -1, y_val_subset), dtype=int).reshape(-1, 1)\n",
    "        else:\n",
    "            y_val_subset = \\\n",
    "                np.fromiter(map(lambda n: 1 if n == pos_class else -1, y_val_subset), dtype=int).reshape(-1, 1)\n",
    "        return X_train_subset, y_train_subset, X_val_subset, y_val_subset\n",
    "    \n",
    "    return X_train_subset, y_train_subset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3: sklearn.LinearSVC (one-vs-one)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a one-vs-one fashion, for each pair of classes, train a linear SVM classifier using scikit- learnâ€™s function LinearSVC, with the default value for the regularization parameter. Compute the multi-class misclassification error obtained using these classifiers trained in a one-vs-one fashion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model 0: (0,1) ...\n",
      "0.1550004569999146\n",
      "Training model 1: (0,2) ...\n",
      "0.161391889000015\n",
      "Training model 2: (0,3) ...\n",
      "0.13016138200009664\n",
      "Training model 3: (0,4) ...\n",
      "0.13331810799991217\n",
      "Training model 4: (0,5) ...\n",
      "0.14343435999990106\n",
      "Training model 5: (0,6) ...\n",
      "0.15298060099985378\n",
      "Training model 6: (0,7) ...\n",
      "0.13773807400002624\n",
      "Training model 7: (0,8) ...\n",
      "0.1286408250000477\n",
      "Training model 8: (0,9) ...\n",
      "0.10767872900009934\n",
      "Training model 9: (0,10) ...\n",
      "0.11759574300003806\n",
      "Training model 10: (0,11) ...\n",
      "0.10529112700010046\n",
      "Training model 11: (0,12) ...\n",
      "0.11072972600004505\n",
      "Training model 12: (0,13) ...\n",
      "0.11508835299991915\n",
      "Training model 13: (0,14) ...\n",
      "0.12418233000016698\n",
      "Training model 14: (0,15) ...\n",
      "0.12227917200016236\n",
      "Training model 15: (0,16) ...\n",
      "0.1018311159998575\n",
      "Training model 16: (0,17) ...\n",
      "0.12257742099995994\n",
      "Training model 17: (0,18) ...\n",
      "0.10624404300006063\n",
      "Training model 18: (0,19) ...\n",
      "0.10598082599994996\n",
      "Training model 19: (0,20) ...\n",
      "0.10610838000002332\n",
      "Training model 20: (0,21) ...\n",
      "0.10701725399985662\n",
      "Training model 21: (0,22) ...\n",
      "0.11365715299984913\n",
      "Training model 22: (0,23) ...\n",
      "0.12373098900002333\n",
      "Training model 23: (0,24) ...\n",
      "0.10296806699989247\n",
      "Training model 24: (0,25) ...\n",
      "0.11611443799984045\n",
      "Training model 25: (0,26) ...\n",
      "0.14581495099992026\n",
      "Training model 26: (0,27) ...\n",
      "0.1244836429998486\n",
      "Training model 27: (0,28) ...\n",
      "0.13092700999982299\n",
      "Training model 28: (0,29) ...\n",
      "0.16192972199996802\n",
      "Training model 29: (0,30) ...\n",
      "0.13004796799987162\n",
      "Training model 30: (0,31) ...\n",
      "0.12468909099993652\n",
      "Training model 31: (0,32) ...\n",
      "0.13695912799994403\n",
      "Training model 32: (0,33) ...\n",
      "0.14526565100004518\n",
      "Training model 33: (0,34) ...\n",
      "0.14794565800002601\n",
      "Training model 34: (0,35) ...\n",
      "0.13744272700000693\n",
      "Training model 35: (0,36) ...\n",
      "0.16400749899980838\n",
      "Training model 36: (0,37) ...\n",
      "0.1175757920000251\n",
      "Training model 37: (0,38) ...\n",
      "0.12571261600010075\n",
      "Training model 38: (0,39) ...\n",
      "0.15774703399983991\n",
      "Training model 39: (0,40) ...\n",
      "0.12338412999997672\n",
      "Training model 40: (0,41) ...\n",
      "0.12022558500007108\n",
      "Training model 41: (0,42) ...\n",
      "0.11952148199998192\n",
      "Training model 42: (0,43) ...\n",
      "0.13720773500017458\n",
      "Training model 43: (0,44) ...\n",
      "0.12872478799999953\n",
      "Training model 44: (0,45) ...\n",
      "0.11546408899994276\n",
      "Training model 45: (0,46) ...\n",
      "0.12191091999989112\n",
      "Training model 46: (0,47) ...\n",
      "0.13476736199982042\n",
      "Training model 47: (0,48) ...\n",
      "0.1197180589999789\n",
      "Training model 48: (0,49) ...\n",
      "0.12485402300012538\n",
      "Training model 49: (0,50) ...\n",
      "0.14340892699988217\n",
      "Training model 50: (0,51) ...\n",
      "0.1333377040000414\n",
      "Training model 51: (0,52) ...\n",
      "0.14047188599988658\n",
      "Training model 52: (0,53) ...\n",
      "0.14045358799990026\n",
      "Training model 53: (0,54) ...\n",
      "0.1253884359998665\n",
      "Training model 54: (0,55) ...\n",
      "0.12490965400002096\n",
      "Training model 55: (0,56) ...\n",
      "0.12783211800001482\n",
      "Training model 56: (0,57) ...\n",
      "0.12103667400015183\n",
      "Training model 57: (0,58) ...\n",
      "0.14667560199995933\n",
      "Training model 58: (0,59) ...\n",
      "0.11786136199998509\n",
      "Training model 59: (0,60) ...\n",
      "0.14852815299991562\n",
      "Training model 60: (0,61) ...\n",
      "0.15516099499996017\n",
      "Training model 61: (0,62) ...\n",
      "0.16646665700000085\n",
      "Training model 62: (0,63) ...\n",
      "0.14321431300004406\n",
      "Training model 63: (0,64) ...\n",
      "0.1333249940000769\n",
      "Training model 64: (0,65) ...\n",
      "0.13787904899982095\n",
      "Training model 65: (0,66) ...\n",
      "0.11130987199999254\n",
      "Training model 66: (0,67) ...\n",
      "0.11809836099996573\n",
      "Training model 67: (0,68) ...\n",
      "0.11358173799999349\n",
      "Training model 68: (0,69) ...\n",
      "0.11235097899998436\n",
      "Training model 69: (0,70) ...\n",
      "0.1015820889999759\n",
      "Training model 70: (0,71) ...\n",
      "0.13231456900007288\n",
      "Training model 71: (0,72) ...\n",
      "0.09832527300000038\n",
      "Training model 72: (0,73) ...\n",
      "0.10611642100002427\n",
      "Training model 73: (0,74) ...\n",
      "0.10004199099989819\n",
      "Training model 74: (0,75) ...\n",
      "0.10144471900002827\n",
      "Training model 75: (0,76) ...\n",
      "0.1321897909999734\n",
      "Training model 76: (0,77) ...\n",
      "0.11058614500007025\n",
      "Training model 77: (0,78) ...\n",
      "0.11610407200009831\n",
      "Training model 78: (0,79) ...\n",
      "0.1200933109998914\n",
      "Training model 79: (0,80) ...\n",
      "0.1070988420001413\n",
      "Training model 80: (0,81) ...\n",
      "0.10947071200007485\n",
      "Training model 81: (0,82) ...\n",
      "0.11602388899996186\n",
      "Training model 82: (0,83) ...\n",
      "0.10142837200010035\n",
      "Training model 83: (0,84) ...\n",
      "0.11559977599995364\n",
      "Training model 84: (0,85) ...\n",
      "0.11854033999998137\n",
      "Training model 85: (0,86) ...\n",
      "0.11523506000003181\n",
      "Training model 86: (0,87) ...\n",
      "0.12142551800002366\n",
      "Training model 87: (0,88) ...\n",
      "0.12785864700003913\n",
      "Training model 88: (0,89) ...\n",
      "0.12122912199993152\n",
      "Training model 89: (0,90) ...\n",
      "0.12011523799992574\n",
      "Training model 90: (0,91) ...\n",
      "0.11955459099999644\n",
      "Training model 91: (0,92) ...\n",
      "0.1037057169999116\n",
      "Training model 92: (0,93) ...\n",
      "0.12640862799980823\n",
      "Training model 93: (0,94) ...\n",
      "0.1122726920000332\n",
      "Training model 94: (0,95) ...\n",
      "0.1004925639999783\n",
      "Training model 95: (0,96) ...\n",
      "0.12274720899995373\n",
      "Training model 96: (0,97) ...\n",
      "0.12166104500010988\n",
      "Training model 97: (0,98) ...\n",
      "0.10613803299997926\n",
      "Training model 98: (0,99) ...\n",
      "0.12055394000003616\n",
      "Training model 99: (1,2) ...\n",
      "0.122352157000023\n",
      "Training model 100: (1,3) ...\n",
      "0.11296394499981943\n",
      "Training model 101: (1,4) ...\n",
      "0.13284851100002015\n",
      "Training model 102: (1,5) ...\n",
      "0.14168383400010498\n",
      "Training model 103: (1,6) ...\n",
      "0.12390500399988014\n",
      "Training model 104: (1,7) ...\n",
      "0.13636283599998933\n",
      "Training model 105: (1,8) ...\n",
      "0.13454158399986227\n",
      "Training model 106: (1,9) ...\n",
      "0.1090755430000172\n",
      "Training model 107: (1,10) ...\n",
      "0.12083953999990626\n",
      "Training model 108: (1,11) ...\n",
      "0.12003194499993697\n",
      "Training model 109: (1,12) ...\n",
      "0.12675699500005067\n",
      "Training model 110: (1,13) ...\n",
      "0.11167651599998862\n",
      "Training model 111: (1,14) ...\n",
      "0.11125571100001252\n",
      "Training model 112: (1,15) ...\n",
      "0.1221763959999862\n",
      "Training model 113: (1,16) ...\n",
      "0.11913222299995141\n",
      "Training model 114: (1,17) ...\n",
      "0.10604727700001604\n",
      "Training model 115: (1,18) ...\n",
      "0.10101136599996607\n",
      "Training model 116: (1,19) ...\n",
      "0.10611129800008712\n",
      "Training model 117: (1,20) ...\n",
      "0.10596521100001155\n",
      "Training model 118: (1,21) ...\n",
      "0.11125081800014414\n",
      "Training model 119: (1,22) ...\n",
      "0.11891578499989919\n",
      "Training model 120: (1,23) ...\n",
      "0.11552093999989665\n",
      "Training model 121: (1,24) ...\n",
      "0.09852474300009817\n",
      "Training model 122: (1,25) ...\n",
      "0.11883156799990502\n",
      "Training model 123: (1,26) ...\n",
      "0.14182717199992112\n",
      "Training model 124: (1,27) ...\n",
      "0.15139023599999746\n",
      "Training model 125: (1,28) ...\n",
      "0.119358241999862\n",
      "Training model 126: (1,29) ...\n",
      "0.18320900300000176\n",
      "Training model 127: (1,30) ...\n",
      "0.1142839560000084\n",
      "Training model 128: (1,31) ...\n",
      "0.13521229200000562\n",
      "Training model 129: (1,32) ...\n",
      "0.14147695299993757\n",
      "Training model 130: (1,33) ...\n",
      "0.13742596800011597\n",
      "Training model 131: (1,34) ...\n",
      "0.11375332900001922\n",
      "Training model 132: (1,35) ...\n",
      "0.11040299499995854\n",
      "Training model 133: (1,36) ...\n",
      "0.1357337730000836\n",
      "Training model 134: (1,37) ...\n",
      "0.10916214899998522\n",
      "Training model 135: (1,38) ...\n",
      "0.13975648800010276\n",
      "Training model 136: (1,39) ...\n",
      "0.13134087999992516\n",
      "Training model 137: (1,40) ...\n",
      "0.12204964700003984\n",
      "Training model 138: (1,41) ...\n",
      "0.10790522399997826\n",
      "Training model 139: (1,42) ...\n",
      "0.12354656399998021\n",
      "Training model 140: (1,43) ...\n",
      "0.1177469540000402\n",
      "Training model 141: (1,44) ...\n",
      "0.1067009800001415\n",
      "Training model 142: (1,45) ...\n",
      "0.09715983999990385\n",
      "Training model 143: (1,46) ...\n",
      "0.12242447900007392\n",
      "Training model 144: (1,47) ...\n",
      "0.12095650900005239\n",
      "Training model 145: (1,48) ...\n",
      "0.1016067349999048\n",
      "Training model 146: (1,49) ...\n",
      "0.10608830099999977\n",
      "Training model 147: (1,50) ...\n",
      "0.11603887100000065\n",
      "Training model 148: (1,51) ...\n",
      "0.1212069790001351\n",
      "Training model 149: (1,52) ...\n",
      "0.11838605399998414\n",
      "Training model 150: (1,53) ...\n",
      "0.14569459599988477\n",
      "Training model 151: (1,54) ...\n",
      "0.12123740899983204\n",
      "Training model 152: (1,55) ...\n",
      "0.11597325200000341\n",
      "Training model 153: (1,56) ...\n",
      "0.13496657400014556\n",
      "Training model 154: (1,57) ...\n",
      "0.10461648500017873\n",
      "Training model 155: (1,58) ...\n",
      "0.1335896269999921\n",
      "Training model 156: (1,59) ...\n",
      "0.12524347699991267\n",
      "Training model 157: (1,60) ...\n",
      "0.1430864010001187\n",
      "Training model 158: (1,61) ...\n",
      "0.11867058999996516\n",
      "Training model 159: (1,62) ...\n",
      "0.12569681299987678\n",
      "Training model 160: (1,63) ...\n",
      "0.13228747800008023\n",
      "Training model 161: (1,64) ...\n",
      "0.12179168600005141\n",
      "Training model 162: (1,65) ...\n",
      "0.1330281579998882\n",
      "Training model 163: (1,66) ...\n",
      "0.10493418000010024\n",
      "Training model 164: (1,67) ...\n",
      "0.1058035490000293\n",
      "Training model 165: (1,68) ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.10229126400008681\n",
      "Training model 166: (1,69) ...\n",
      "0.1007619459999205\n",
      "Training model 167: (1,70) ...\n",
      "0.10779715499984377\n",
      "Training model 168: (1,71) ...\n",
      "0.13737610499993025\n",
      "Training model 169: (1,72) ...\n",
      "0.1023004230000879\n",
      "Training model 170: (1,73) ...\n",
      "0.13307532499993613\n",
      "Training model 171: (1,74) ...\n",
      "0.11766815500004668\n",
      "Training model 172: (1,75) ...\n",
      "0.1058038360001774\n",
      "Training model 173: (1,76) ...\n",
      "0.1225933669998085\n",
      "Training model 174: (1,77) ...\n",
      "0.12014681200002997\n",
      "Training model 175: (1,78) ...\n",
      "0.1439022639999621\n",
      "Training model 176: (1,79) ...\n",
      "0.15276964199983922\n",
      "Training model 177: (1,80) ...\n",
      "0.10776988599991455\n",
      "Training model 178: (1,81) ...\n",
      "0.10665013800007728\n",
      "Training model 179: (1,82) ...\n",
      "0.10923120200004632\n",
      "Training model 180: (1,83) ...\n",
      "0.09951229500006775\n",
      "Training model 181: (1,84) ...\n",
      "0.11703332699994462\n",
      "Training model 182: (1,85) ...\n",
      "0.106294926000146\n",
      "Training model 183: (1,86) ...\n",
      "0.11196037400009118\n",
      "Training model 184: (1,87) ...\n",
      "0.10289267899997867\n",
      "Training model 185: (1,88) ...\n",
      "0.1648301589998482\n",
      "Training model 186: (1,89) ...\n",
      "0.11135562499998741\n",
      "Training model 187: (1,90) ...\n",
      "0.15504654400001527\n",
      "Training model 188: (1,91) ...\n",
      "0.11688604599999053\n",
      "Training model 189: (1,92) ...\n",
      "0.11848413799998525\n",
      "Training model 190: (1,93) ...\n",
      "0.13385738900001343\n",
      "Training model 191: (1,94) ...\n",
      "0.15438806699989982\n",
      "Training model 192: (1,95) ...\n",
      "0.10923416400009955\n",
      "Training model 193: (1,96) ...\n",
      "0.13089074100003018\n",
      "Training model 194: (1,97) ...\n",
      "0.11428666699998757\n",
      "Training model 195: (1,98) ...\n",
      "0.10094744899993202\n",
      "Training model 196: (1,99) ...\n",
      "0.11305190300004142\n",
      "Training model 197: (2,3) ...\n",
      "0.9821310810000341\n",
      "Training model 198: (2,4) ...\n",
      "0.6486067550001735\n",
      "Training model 199: (2,5) ...\n",
      "0.3273907989998861\n",
      "Training model 200: (2,6) ...\n",
      "0.4016320660000474\n",
      "Training model 201: (2,7) ...\n",
      "0.11649399999987509\n",
      "Training model 202: (2,8) ...\n",
      "0.12042402700012644\n",
      "Training model 203: (2,9) ...\n",
      "0.11051828500012562\n",
      "Training model 204: (2,10) ...\n",
      "0.10961172500014982\n",
      "Training model 205: (2,11) ...\n",
      "0.10743412700003319\n",
      "Training model 206: (2,12) ...\n",
      "0.11646200199993473\n",
      "Training model 207: (2,13) ...\n",
      "0.1390726929998891\n",
      "Training model 208: (2,14) ...\n",
      "0.1356301230000554\n",
      "Training model 209: (2,15) ...\n",
      "0.1090057890000935\n",
      "Training model 210: (2,16) ...\n",
      "0.10786234099987269\n",
      "Training model 211: (2,17) ...\n",
      "0.11951094599999124\n",
      "Training model 212: (2,18) ...\n",
      "0.11879248500008543\n",
      "Training model 213: (2,19) ...\n",
      "0.11705856000003223\n",
      "Training model 214: (2,20) ...\n",
      "0.13961135599993213\n",
      "Training model 215: (2,21) ...\n",
      "0.13396762399997897\n",
      "Training model 216: (2,22) ...\n",
      "0.13662753399989924\n",
      "Training model 217: (2,23) ...\n",
      "0.14300336399992375\n",
      "Training model 218: (2,24) ...\n",
      "0.10347971099986353\n",
      "Training model 219: (2,25) ...\n",
      "0.09961416400005874\n",
      "Training model 220: (2,26) ...\n",
      "0.12505570300004365\n",
      "Training model 221: (2,27) ...\n",
      "0.10780462999991869\n",
      "Training model 222: (2,28) ...\n",
      "0.11545922099980999\n",
      "Training model 223: (2,29) ...\n",
      "0.1549522469999829\n",
      "Training model 224: (2,30) ...\n",
      "0.11222335799993743\n",
      "Training model 225: (2,31) ...\n",
      "0.11191017099986311\n",
      "Training model 226: (2,32) ...\n",
      "0.12081007999995563\n",
      "Training model 227: (2,33) ...\n",
      "0.30975597399992694\n",
      "Training model 228: (2,34) ...\n",
      "0.26479541300000164\n",
      "Training model 229: (2,35) ...\n",
      "0.12019863599994096\n",
      "Training model 230: (2,36) ...\n",
      "0.1419214259999535\n",
      "Training model 231: (2,37) ...\n",
      "0.1052536230001806\n",
      "Training model 232: (2,38) ...\n",
      "0.12319112399995902\n",
      "Training model 233: (2,39) ...\n",
      "0.1319473769999604\n",
      "Training model 234: (2,40) ...\n",
      "0.1181078519998664\n",
      "Training model 235: (2,41) ...\n",
      "0.11599924400002237\n",
      "Training model 236: (2,42) ...\n",
      "0.1133471709999867\n",
      "Training model 237: (2,43) ...\n",
      "0.11377431300002172\n",
      "Training model 238: (2,44) ...\n",
      "0.1162481819999357\n",
      "Training model 239: (2,45) ...\n",
      "0.1123264630000449\n",
      "Training model 240: (2,46) ...\n",
      "0.11473489900004097\n",
      "Training model 241: (2,47) ...\n",
      "0.11781658900008551\n",
      "Training model 242: (2,48) ...\n",
      "0.1070116120001785\n",
      "Training model 243: (2,49) ...\n",
      "0.12487987700001213\n",
      "Training model 244: (2,50) ...\n",
      "0.15883732900010727\n",
      "Training model 245: (2,51) ...\n",
      "0.12161050999998224\n",
      "Training model 246: (2,52) ...\n",
      "0.11499891499988735\n",
      "Training model 247: (2,53) ...\n",
      "0.13388678100000106\n",
      "Training model 248: (2,54) ...\n",
      "0.1153752519999216\n",
      "Training model 249: (2,55) ...\n",
      "0.11226525000006404\n",
      "Training model 250: (2,56) ...\n",
      "0.11438628600012635\n",
      "Training model 251: (2,57) ...\n",
      "0.10748735099991791\n",
      "Training model 252: (2,58) ...\n",
      "0.2031978820000404\n",
      "Training model 253: (2,59) ...\n",
      "0.11727552199999991\n",
      "Training model 254: (2,60) ...\n",
      "0.12525902900006258\n",
      "Training model 255: (2,61) ...\n",
      "0.11843219000002136\n",
      "Training model 256: (2,62) ...\n",
      "0.11950566800010165\n",
      "Training model 257: (2,63) ...\n",
      "0.12261573299997508\n",
      "Training model 258: (2,64) ...\n",
      "0.11333736899996438\n",
      "Training model 259: (2,65) ...\n",
      "0.22335346399995615\n",
      "Training model 260: (2,66) ...\n",
      "0.11062852700001713\n",
      "Training model 261: (2,67) ...\n",
      "0.11114494499997818\n",
      "Training model 262: (2,68) ...\n",
      "0.10842696999998225\n",
      "Training model 263: (2,69) ...\n",
      "0.10381255799984501\n",
      "Training model 264: (2,70) ...\n",
      "0.10654514400016524\n",
      "Training model 265: (2,71) ...\n",
      "0.14455024599988064\n",
      "Training model 266: (2,72) ...\n",
      "0.1067119100000582\n",
      "Training model 267: (2,73) ...\n",
      "0.12311474099988118\n",
      "Training model 268: (2,74) ...\n",
      "0.10894795300009719\n",
      "Training model 269: (2,75) ...\n",
      "0.10660468000014589\n",
      "Training model 270: (2,76) ...\n",
      "0.12521769700015284\n",
      "Training model 271: (2,77) ...\n",
      "0.11584785100012596\n",
      "Training model 272: (2,78) ...\n",
      "0.1341700299999502\n",
      "Training model 273: (2,79) ...\n",
      "0.13149458999987473\n",
      "Training model 274: (2,80) ...\n",
      "0.12023837699985052\n",
      "Training model 275: (2,81) ...\n",
      "0.1373012750000271\n",
      "Training model 276: (2,82) ...\n",
      "0.11815701099999387\n",
      "Training model 277: (2,83) ...\n",
      "0.10516117599991048\n",
      "Training model 278: (2,84) ...\n",
      "0.11573957300015536\n",
      "Training model 279: (2,85) ...\n",
      "0.12689091999982338\n",
      "Training model 280: (2,86) ...\n",
      "0.1068818660000943\n",
      "Training model 281: (2,87) ...\n",
      "0.11068734700006644\n",
      "Training model 282: (2,88) ...\n",
      "0.11147569899981136\n",
      "Training model 283: (2,89) ...\n",
      "0.1295659610000257\n",
      "Training model 284: (2,90) ...\n",
      "0.10057628699996712\n",
      "Training model 285: (2,91) ...\n",
      "0.10880068100004792\n",
      "Training model 286: (2,92) ...\n",
      "0.11170298199999706\n",
      "Training model 287: (2,93) ...\n",
      "0.12007247399992593\n",
      "Training model 288: (2,94) ...\n",
      "0.12210111100012\n",
      "Training model 289: (2,95) ...\n",
      "0.1043359129998862\n",
      "Training model 290: (2,96) ...\n",
      "0.11867175300017152\n",
      "Training model 291: (2,97) ...\n",
      "0.13287191800009168\n",
      "Training model 292: (2,98) ...\n",
      "0.1412149610000597\n",
      "Training model 293: (2,99) ...\n",
      "0.1296459899999718\n",
      "Training model 294: (3,4) ...\n",
      "0.9482191199999761\n",
      "Training model 295: (3,5) ...\n",
      "0.39765390599995953\n",
      "Training model 296: (3,6) ...\n",
      "0.4997645949999878\n",
      "Training model 297: (3,7) ...\n",
      "0.1147050950000903\n",
      "Training model 298: (3,8) ...\n",
      "0.11343566799996552\n",
      "Training model 299: (3,9) ...\n",
      "0.11096924999992552\n",
      "Training model 300: (3,10) ...\n",
      "0.10818611200011219\n",
      "Training model 301: (3,11) ...\n",
      "0.1028645910000705\n",
      "Training model 302: (3,12) ...\n",
      "0.11141056899987234\n",
      "Training model 303: (3,13) ...\n",
      "0.12857124399988606\n",
      "Training model 304: (3,14) ...\n",
      "0.11607693899986771\n",
      "Training model 305: (3,15) ...\n",
      "0.11428225800000291\n",
      "Training model 306: (3,16) ...\n",
      "0.10753672500004541\n",
      "Training model 307: (3,17) ...\n",
      "0.12343907399986165\n",
      "Training model 308: (3,18) ...\n",
      "0.12323036600014348\n",
      "Training model 309: (3,19) ...\n",
      "0.11286906200007252\n",
      "Training model 310: (3,20) ...\n",
      "0.12410959599992566\n",
      "Training model 311: (3,21) ...\n",
      "0.12226990399994975\n",
      "Training model 312: (3,22) ...\n",
      "0.13013598400016235\n",
      "Training model 313: (3,23) ...\n",
      "0.13900165500012918\n",
      "Training model 314: (3,24) ...\n",
      "0.09653497399995103\n",
      "Training model 315: (3,25) ...\n",
      "0.10042510399989624\n",
      "Training model 316: (3,26) ...\n",
      "0.12362154100014777\n",
      "Training model 317: (3,27) ...\n",
      "0.10814657700007047\n",
      "Training model 318: (3,28) ...\n",
      "0.10670779699989907\n",
      "Training model 319: (3,29) ...\n",
      "0.15526870500002588\n",
      "Training model 320: (3,30) ...\n",
      "0.11752147699985471\n",
      "Training model 321: (3,31) ...\n",
      "0.130580966000025\n",
      "Training model 322: (3,32) ...\n",
      "0.11661734200015417\n",
      "Training model 323: (3,33) ...\n",
      "0.25354818899995735\n",
      "Training model 324: (3,34) ...\n",
      "0.21223521599995365\n",
      "Training model 325: (3,35) ...\n",
      "0.11270920800006934\n",
      "Training model 326: (3,36) ...\n",
      "0.14824771300004613\n",
      "Training model 327: (3,37) ...\n",
      "0.10053214700019453\n",
      "Training model 328: (3,38) ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.11894899599997188\n",
      "Training model 329: (3,39) ...\n",
      "0.13655072899996412\n",
      "Training model 330: (3,40) ...\n",
      "0.11719465700002729\n",
      "Training model 331: (3,41) ...\n",
      "0.11138319699989552\n",
      "Training model 332: (3,42) ...\n",
      "0.12861114499992254\n",
      "Training model 333: (3,43) ...\n",
      "0.11426472300013302\n",
      "Training model 334: (3,44) ...\n",
      "0.11596247300008145\n",
      "Training model 335: (3,45) ...\n",
      "0.10722582099992906\n",
      "Training model 336: (3,46) ...\n",
      "0.12459819200012134\n",
      "Training model 337: (3,47) ...\n",
      "0.11896432599996842\n",
      "Training model 338: (3,48) ...\n",
      "0.1078471629998603\n",
      "Training model 339: (3,49) ...\n",
      "0.1175715740000669\n",
      "Training model 340: (3,50) ...\n",
      "0.1535329969999566\n",
      "Training model 341: (3,51) ...\n",
      "0.11855243599984533\n",
      "Training model 342: (3,52) ...\n",
      "0.11646268399999826\n",
      "Training model 343: (3,53) ...\n",
      "0.1394791330001226\n",
      "Training model 344: (3,54) ...\n",
      "0.11795515100016019\n",
      "Training model 345: (3,55) ...\n",
      "0.11406737999982397\n",
      "Training model 346: (3,56) ...\n",
      "0.10963242799994077\n",
      "Training model 347: (3,57) ...\n",
      "0.10669608299986066\n",
      "Training model 348: (3,58) ...\n",
      "0.17109342300000208\n",
      "Training model 349: (3,59) ...\n",
      "0.11621551700000055\n",
      "Training model 350: (3,60) ...\n",
      "0.12578586600011477\n",
      "Training model 351: (3,61) ...\n",
      "0.12686212999983582\n",
      "Training model 352: (3,62) ...\n",
      "0.11763428199992632\n",
      "Training model 353: (3,63) ...\n",
      "0.12234898199994859\n",
      "Training model 354: (3,64) ...\n",
      "0.1217503459999989\n",
      "Training model 355: (3,65) ...\n",
      "0.23835375400017256\n",
      "Training model 356: (3,66) ...\n",
      "0.10805357399999593\n",
      "Training model 357: (3,67) ...\n",
      "0.11210129300002336\n",
      "Training model 358: (3,68) ...\n",
      "0.10377891000007367\n",
      "Training model 359: (3,69) ...\n",
      "0.10554012000011426\n",
      "Training model 360: (3,70) ...\n",
      "0.10387616699995306\n",
      "Training model 361: (3,71) ...\n",
      "0.13501465299987103\n",
      "Training model 362: (3,72) ...\n",
      "0.1015101450000202\n",
      "Training model 363: (3,73) ...\n",
      "0.11321210699998119\n",
      "Training model 364: (3,74) ...\n",
      "0.10258587599992097\n",
      "Training model 365: (3,75) ...\n",
      "0.11000541800012797\n",
      "Training model 366: (3,76) ...\n",
      "0.12072877200012044\n",
      "Training model 367: (3,77) ...\n",
      "0.12069695300010608\n",
      "Training model 368: (3,78) ...\n",
      "0.12049006500001269\n",
      "Training model 369: (3,79) ...\n",
      "0.12067882700011978\n",
      "Training model 370: (3,80) ...\n",
      "0.11575938700002553\n",
      "Training model 371: (3,81) ...\n",
      "0.12068684600012602\n",
      "Training model 372: (3,82) ...\n",
      "0.1150340460001189\n",
      "Training model 373: (3,83) ...\n",
      "0.11028593400010323\n",
      "Training model 374: (3,84) ...\n",
      "0.11406512300004579\n",
      "Training model 375: (3,85) ...\n",
      "0.13676463299998431\n",
      "Training model 376: (3,86) ...\n",
      "0.11445204799997555\n",
      "Training model 377: (3,87) ...\n",
      "0.11287904799996795\n",
      "Training model 378: (3,88) ...\n",
      "0.10840617300004851\n",
      "Training model 379: (3,89) ...\n",
      "0.12308774699999958\n",
      "Training model 380: (3,90) ...\n",
      "0.09996726200006378\n",
      "Training model 381: (3,91) ...\n",
      "0.115390029000082\n",
      "Training model 382: (3,92) ...\n",
      "0.10987328700002763\n",
      "Training model 383: (3,93) ...\n",
      "0.11572286099999474\n",
      "Training model 384: (3,94) ...\n",
      "0.1182816579998871\n",
      "Training model 385: (3,95) ...\n",
      "0.09818977500003712\n",
      "Training model 386: (3,96) ...\n",
      "0.10866488700003174\n",
      "Training model 387: (3,97) ...\n",
      "0.1159148050001022\n",
      "Training model 388: (3,98) ...\n",
      "0.11543281199988087\n",
      "Training model 389: (3,99) ...\n",
      "0.1274609669999336\n",
      "Training model 390: (4,5) ...\n",
      "0.4197179350001079\n",
      "Training model 391: (4,6) ...\n",
      "0.5151350700000421\n",
      "Training model 392: (4,7) ...\n",
      "0.11722000800000387\n",
      "Training model 393: (4,8) ...\n",
      "0.11439089899999999\n",
      "Training model 394: (4,9) ...\n",
      "0.10561157600000115\n",
      "Training model 395: (4,10) ...\n",
      "0.10560021900005268\n",
      "Training model 396: (4,11) ...\n",
      "0.10561955899993336\n",
      "Training model 397: (4,12) ...\n",
      "0.11312386600002355\n",
      "Training model 398: (4,13) ...\n",
      "0.12683472300000176\n",
      "Training model 399: (4,14) ...\n",
      "0.12075108299995918\n",
      "Training model 400: (4,15) ...\n",
      "0.11056164399997215\n",
      "Training model 401: (4,16) ...\n",
      "0.11308372199982841\n",
      "Training model 402: (4,17) ...\n",
      "0.12381282499995905\n",
      "Training model 403: (4,18) ...\n",
      "0.12256802799993238\n",
      "Training model 404: (4,19) ...\n",
      "0.11429734500006816\n",
      "Training model 405: (4,20) ...\n",
      "0.12113795499999469\n",
      "Training model 406: (4,21) ...\n",
      "0.12666213600004994\n",
      "Training model 407: (4,22) ...\n",
      "0.1238404979999359\n",
      "Training model 408: (4,23) ...\n",
      "0.15076109100004942\n",
      "Training model 409: (4,24) ...\n",
      "0.10140974399996594\n",
      "Training model 410: (4,25) ...\n",
      "0.10274958900004094\n",
      "Training model 411: (4,26) ...\n",
      "0.13464507799994863\n",
      "Training model 412: (4,27) ...\n",
      "0.108304692000047\n",
      "Training model 413: (4,28) ...\n",
      "0.11024686499990821\n",
      "Training model 414: (4,29) ...\n",
      "0.15994387499995355\n",
      "Training model 415: (4,30) ...\n",
      "0.1178515439999046\n",
      "Training model 416: (4,31) ...\n",
      "0.11500831100011055\n",
      "Training model 417: (4,32) ...\n",
      "0.11633275300005153\n",
      "Training model 418: (4,33) ...\n",
      "0.24831866399995306\n",
      "Training model 419: (4,34) ...\n",
      "0.1896187170000303\n",
      "Training model 420: (4,35) ...\n",
      "0.11687441499998386\n",
      "Training model 421: (4,36) ...\n",
      "0.1541968579999775\n",
      "Training model 422: (4,37) ...\n",
      "0.1036854429999039\n",
      "Training model 423: (4,38) ...\n",
      "0.12434500599988496\n",
      "Training model 424: (4,39) ...\n",
      "0.15251262599986148\n",
      "Training model 425: (4,40) ...\n",
      "0.12294987600012064\n",
      "Training model 426: (4,41) ...\n",
      "0.11405342900002324\n",
      "Training model 427: (4,42) ...\n",
      "0.11735318800015193\n",
      "Training model 428: (4,43) ...\n",
      "0.11860936900006891\n",
      "Training model 429: (4,44) ...\n",
      "0.11549219599987737\n",
      "Training model 430: (4,45) ...\n",
      "0.12176679999993212\n",
      "Training model 431: (4,46) ...\n",
      "0.12087076300008448\n",
      "Training model 432: (4,47) ...\n",
      "0.12607194399993205\n",
      "Training model 433: (4,48) ...\n",
      "0.11251894599990919\n",
      "Training model 434: (4,49) ...\n",
      "0.13443794399995568\n",
      "Training model 435: (4,50) ...\n",
      "0.1496129720001136\n",
      "Training model 436: (4,51) ...\n",
      "0.13127711399988584\n",
      "Training model 437: (4,52) ...\n",
      "0.11560176700004376\n",
      "Training model 438: (4,53) ...\n",
      "0.14848329899996315\n",
      "Training model 439: (4,54) ...\n",
      "0.122857551999914\n",
      "Training model 440: (4,55) ...\n",
      "0.11706415899993772\n",
      "Training model 441: (4,56) ...\n",
      "0.11257525399992119\n",
      "Training model 442: (4,57) ...\n",
      "0.11043208799992499\n",
      "Training model 443: (4,58) ...\n",
      "0.1950029709998944\n",
      "Training model 444: (4,59) ...\n",
      "0.11914161899994724\n",
      "Training model 445: (4,60) ...\n",
      "0.13525127100001555\n",
      "Training model 446: (4,61) ...\n",
      "0.124469672000032\n",
      "Training model 447: (4,62) ...\n",
      "0.1302895300000273\n",
      "Training model 448: (4,63) ...\n",
      "0.12829732299996977\n",
      "Training model 449: (4,64) ...\n",
      "0.12453097699994942\n",
      "Training model 450: (4,65) ...\n",
      "0.2538992689999304\n",
      "Training model 451: (4,66) ...\n",
      "0.10653114199999436\n",
      "Training model 452: (4,67) ...\n",
      "0.1155010059999313\n",
      "Training model 453: (4,68) ...\n",
      "0.11651057199992465\n",
      "Training model 454: (4,69) ...\n",
      "0.11784027899989269\n",
      "Training model 455: (4,70) ...\n",
      "0.10646532999999181\n",
      "Training model 456: (4,71) ...\n",
      "0.1418009770000026\n",
      "Training model 457: (4,72) ...\n",
      "0.1060163030001604\n",
      "Training model 458: (4,73) ...\n",
      "0.11498864800000774\n",
      "Training model 459: (4,74) ...\n",
      "0.10808359500015285\n",
      "Training model 460: (4,75) ...\n",
      "0.11157208999998147\n",
      "Training model 461: (4,76) ...\n",
      "0.12390543800006526\n",
      "Training model 462: (4,77) ...\n",
      "0.1274860409998837\n",
      "Training model 463: (4,78) ...\n",
      "0.14441040099995917\n",
      "Training model 464: (4,79) ...\n",
      "0.12660030200004257\n",
      "Training model 465: (4,80) ...\n",
      "0.11090992599997662\n",
      "Training model 466: (4,81) ...\n",
      "0.1192104389999713\n",
      "Training model 467: (4,82) ...\n",
      "0.12110285000017029\n",
      "Training model 468: (4,83) ...\n",
      "0.10601079899993238\n",
      "Training model 469: (4,84) ...\n",
      "0.12075966499992319\n",
      "Training model 470: (4,85) ...\n",
      "0.12685614199995143\n",
      "Training model 471: (4,86) ...\n",
      "0.1071197700000539\n",
      "Training model 472: (4,87) ...\n",
      "0.10972147899997253\n",
      "Training model 473: (4,88) ...\n",
      "0.11308568399999785\n",
      "Training model 474: (4,89) ...\n",
      "0.13084086600019873\n",
      "Training model 475: (4,90) ...\n",
      "0.1009686499999134\n",
      "Training model 476: (4,91) ...\n",
      "0.11183477700001276\n",
      "Training model 477: (4,92) ...\n",
      "0.10872027799996431\n",
      "Training model 478: (4,93) ...\n",
      "0.11696819100006906\n",
      "Training model 479: (4,94) ...\n",
      "0.12681588500004182\n",
      "Training model 480: (4,95) ...\n",
      "0.10073017200011236\n",
      "Training model 481: (4,96) ...\n",
      "0.11734386400007679\n",
      "Training model 482: (4,97) ...\n",
      "0.12389301000007436\n",
      "Training model 483: (4,98) ...\n",
      "0.118126668000059\n",
      "Training model 484: (4,99) ...\n",
      "0.1308153840000159\n",
      "Training model 485: (5,6) ...\n",
      "0.6270334810001259\n",
      "Training model 486: (5,7) ...\n",
      "0.12008895799999664\n",
      "Training model 487: (5,8) ...\n",
      "0.13652070600005572\n",
      "Training model 488: (5,9) ...\n",
      "0.11622479800007568\n",
      "Training model 489: (5,10) ...\n",
      "0.11450030300011349\n",
      "Training model 490: (5,11) ...\n",
      "0.10596893599995383\n",
      "Training model 491: (5,12) ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1119693630000711\n",
      "Training model 492: (5,13) ...\n",
      "0.13566931699983797\n",
      "Training model 493: (5,14) ...\n",
      "0.11973252699999648\n",
      "Training model 494: (5,15) ...\n",
      "0.11206780399993477\n",
      "Training model 495: (5,16) ...\n",
      "0.10348894300000211\n",
      "Training model 496: (5,17) ...\n",
      "0.11425291499995183\n",
      "Training model 497: (5,18) ...\n",
      "0.11051751300010437\n",
      "Training model 498: (5,19) ...\n",
      "0.10980408500017802\n",
      "Training model 499: (5,20) ...\n",
      "0.11947876299996096\n",
      "Training model 500: (5,21) ...\n",
      "0.12165337700002965\n",
      "Training model 501: (5,22) ...\n",
      "0.11679840600004354\n",
      "Training model 502: (5,23) ...\n",
      "0.12315191900006539\n",
      "Training model 503: (5,24) ...\n",
      "0.11415579799995612\n",
      "Training model 504: (5,25) ...\n",
      "0.12833379399990008\n",
      "Training model 505: (5,26) ...\n",
      "0.17703708199996981\n",
      "Training model 506: (5,27) ...\n",
      "0.12499246400011543\n",
      "Training model 507: (5,28) ...\n",
      "0.148286065000093\n",
      "Training model 508: (5,29) ...\n",
      "0.1942799300002207\n",
      "Training model 509: (5,30) ...\n",
      "0.14808940200009602\n",
      "Training model 510: (5,31) ...\n",
      "0.12847897900019234\n",
      "Training model 511: (5,32) ...\n",
      "0.1765423409997311\n",
      "Training model 512: (5,33) ...\n",
      "0.3178511749997597\n",
      "Training model 513: (5,34) ...\n",
      "0.21459550700001273\n",
      "Training model 514: (5,35) ...\n",
      "0.16508457400004772\n",
      "Training model 515: (5,36) ...\n",
      "0.19341087000020707\n",
      "Training model 516: (5,37) ...\n",
      "0.13180553299980602\n",
      "Training model 517: (5,38) ...\n",
      "0.19104583500029548\n",
      "Training model 518: (5,39) ...\n",
      "0.1513646440002958\n",
      "Training model 519: (5,40) ...\n",
      "0.12495020500000464\n",
      "Training model 520: (5,41) ...\n",
      "0.14984095299996625\n",
      "Training model 521: (5,42) ...\n",
      "0.1387090140001419\n",
      "Training model 522: (5,43) ...\n",
      "0.17047036700023455\n",
      "Training model 523: (5,44) ...\n",
      "0.15966315299965572\n",
      "Training model 524: (5,45) ...\n",
      "0.14800604100037162\n",
      "Training model 525: (5,46) ...\n",
      "0.13321642599976258\n",
      "Training model 526: (5,47) ...\n",
      "0.14969060400017042\n",
      "Training model 527: (5,48) ...\n",
      "0.1325739630001408\n",
      "Training model 528: (5,49) ...\n",
      "0.13319787899990843\n",
      "Training model 529: (5,50) ...\n",
      "0.17176664099997652\n",
      "Training model 530: (5,51) ...\n",
      "0.12943201999996745\n",
      "Training model 531: (5,52) ...\n",
      "0.14649496600031853\n",
      "Training model 532: (5,53) ...\n",
      "0.1581708419998904\n",
      "Training model 533: (5,54) ...\n",
      "0.18374842100001842\n",
      "Training model 534: (5,55) ...\n",
      "0.1295746659998258\n",
      "Training model 535: (5,56) ...\n",
      "0.14914913700022225\n",
      "Training model 536: (5,57) ...\n",
      "0.14514405199997782\n",
      "Training model 537: (5,58) ...\n",
      "0.22300002799966023\n",
      "Training model 538: (5,59) ...\n",
      "0.1304760369998803\n",
      "Training model 539: (5,60) ...\n",
      "0.20644495000033203\n",
      "Training model 540: (5,61) ...\n",
      "0.15273791000026904\n",
      "Training model 541: (5,62) ...\n",
      "0.19668234100026893\n",
      "Training model 542: (5,63) ...\n",
      "0.1856943239999964\n",
      "Training model 543: (5,64) ...\n",
      "0.13465302799977508\n",
      "Training model 544: (5,65) ...\n",
      "0.42186858100012614\n",
      "Training model 545: (5,66) ...\n",
      "0.18099208800003908\n",
      "Training model 546: (5,67) ...\n",
      "0.1695043239997176\n",
      "Training model 547: (5,68) ...\n",
      "0.1903557999999066\n",
      "Training model 548: (5,69) ...\n",
      "0.14652848400010043\n",
      "Training model 549: (5,70) ...\n",
      "0.11866872200016587\n",
      "Training model 550: (5,71) ...\n",
      "0.15816429999995307\n",
      "Training model 551: (5,72) ...\n",
      "0.11308896200034724\n",
      "Training model 552: (5,73) ...\n",
      "0.12969657299981918\n",
      "Training model 553: (5,74) ...\n",
      "0.11012147000019468\n",
      "Training model 554: (5,75) ...\n",
      "0.1208791049998581\n",
      "Training model 555: (5,76) ...\n",
      "0.14362186600010318\n",
      "Training model 556: (5,77) ...\n",
      "0.13051889000007577\n",
      "Training model 557: (5,78) ...\n",
      "0.15627745900019363\n",
      "Training model 558: (5,79) ...\n",
      "0.1471066939998309\n",
      "Training model 559: (5,80) ...\n",
      "0.1164174020000246\n",
      "Training model 560: (5,81) ...\n",
      "0.12046081600010439\n",
      "Training model 561: (5,82) ...\n",
      "0.12538254399987636\n",
      "Training model 562: (5,83) ...\n",
      "0.11593805400025303\n",
      "Training model 563: (5,84) ...\n",
      "0.13724632899993594\n",
      "Training model 564: (5,85) ...\n",
      "0.14342888900000617\n",
      "Training model 565: (5,86) ...\n",
      "0.12485530000003564\n",
      "Training model 566: (5,87) ...\n",
      "0.12206737199994677\n",
      "Training model 567: (5,88) ...\n",
      "0.1121002929999122\n",
      "Training model 568: (5,89) ...\n",
      "0.1116909599995779\n",
      "Training model 569: (5,90) ...\n",
      "0.10840379800038136\n",
      "Training model 570: (5,91) ...\n",
      "0.11050734099990223\n",
      "Training model 571: (5,92) ...\n",
      "0.10687460500002999\n",
      "Training model 572: (5,93) ...\n",
      "0.11927323800000522\n",
      "Training model 573: (5,94) ...\n",
      "0.12373226100044121\n",
      "Training model 574: (5,95) ...\n",
      "0.10600783800009594\n",
      "Training model 575: (5,96) ...\n",
      "0.11822675599978538\n",
      "Training model 576: (5,97) ...\n",
      "0.12078072299982523\n",
      "Training model 577: (5,98) ...\n",
      "0.1150223160002497\n",
      "Training model 578: (5,99) ...\n",
      "0.11885463399994478\n",
      "Training model 579: (6,7) ...\n",
      "0.11794748000011168\n",
      "Training model 580: (6,8) ...\n",
      "0.12545577299988508\n",
      "Training model 581: (6,9) ...\n",
      "0.11444753299974764\n",
      "Training model 582: (6,10) ...\n",
      "0.11678088500002559\n",
      "Training model 583: (6,11) ...\n",
      "0.1038376309998057\n",
      "Training model 584: (6,12) ...\n",
      "0.11350208500016379\n",
      "Training model 585: (6,13) ...\n",
      "0.13947019199986244\n",
      "Training model 586: (6,14) ...\n",
      "0.1233929499999249\n",
      "Training model 587: (6,15) ...\n",
      "0.11166821200004051\n",
      "Training model 588: (6,16) ...\n",
      "0.10663206899971556\n",
      "Training model 589: (6,17) ...\n",
      "0.1203305580002052\n",
      "Training model 590: (6,18) ...\n",
      "0.12974927799996294\n",
      "Training model 591: (6,19) ...\n",
      "0.11386685100023897\n",
      "Training model 592: (6,20) ...\n",
      "0.13587428699975135\n",
      "Training model 593: (6,21) ...\n",
      "0.11264934399969206\n",
      "Training model 594: (6,22) ...\n",
      "0.1268338620002396\n",
      "Training model 595: (6,23) ...\n",
      "0.12653538200038383\n",
      "Training model 596: (6,24) ...\n",
      "0.10360856799979956\n",
      "Training model 597: (6,25) ...\n",
      "0.11149667199970281\n",
      "Training model 598: (6,26) ...\n",
      "0.14677042699986487\n",
      "Training model 599: (6,27) ...\n",
      "0.11618857599978583\n",
      "Training model 600: (6,28) ...\n",
      "0.1465408839999327\n",
      "Training model 601: (6,29) ...\n",
      "0.17999591800025883\n",
      "Training model 602: (6,30) ...\n",
      "0.1417590050000399\n",
      "Training model 603: (6,31) ...\n",
      "0.12855890399987402\n",
      "Training model 604: (6,32) ...\n",
      "0.13882867099982832\n",
      "Training model 605: (6,33) ...\n",
      "0.3998737700003403\n",
      "Training model 606: (6,34) ...\n",
      "0.23358549400018092\n",
      "Training model 607: (6,35) ...\n",
      "0.14671389200020712\n",
      "Training model 608: (6,36) ...\n",
      "0.20825330299976486\n",
      "Training model 609: (6,37) ...\n",
      "0.11584752599992498\n",
      "Training model 610: (6,38) ...\n",
      "0.14092794500038508\n",
      "Training model 611: (6,39) ...\n",
      "0.14627428499989037\n",
      "Training model 612: (6,40) ...\n",
      "0.12562372399997912\n",
      "Training model 613: (6,41) ...\n",
      "0.13380874299991774\n",
      "Training model 614: (6,42) ...\n",
      "0.1277272079996692\n",
      "Training model 615: (6,43) ...\n",
      "0.12956780400008938\n",
      "Training model 616: (6,44) ...\n",
      "0.15405745099997148\n",
      "Training model 617: (6,45) ...\n",
      "0.12695883100013816\n",
      "Training model 618: (6,46) ...\n",
      "0.13069392699981108\n",
      "Training model 619: (6,47) ...\n",
      "0.1288391920002141\n",
      "Training model 620: (6,48) ...\n",
      "0.13586842800032173\n",
      "Training model 621: (6,49) ...\n",
      "0.15448132400024406\n",
      "Training model 622: (6,50) ...\n",
      "0.19322756899964588\n",
      "Training model 623: (6,51) ...\n",
      "0.12283734099992216\n",
      "Training model 624: (6,52) ...\n",
      "0.13121001599984083\n",
      "Training model 625: (6,53) ...\n",
      "0.15086622099988745\n",
      "Training model 626: (6,54) ...\n",
      "0.14502154100000553\n",
      "Training model 627: (6,55) ...\n",
      "0.12524715299969102\n",
      "Training model 628: (6,56) ...\n",
      "0.12805908599966642\n",
      "Training model 629: (6,57) ...\n",
      "0.12012134999986301\n",
      "Training model 630: (6,58) ...\n",
      "0.2775761650000277\n",
      "Training model 631: (6,59) ...\n",
      "0.12614150999979756\n",
      "Training model 632: (6,60) ...\n",
      "0.15683535900006973\n",
      "Training model 633: (6,61) ...\n",
      "0.13954880499977662\n",
      "Training model 634: (6,62) ...\n",
      "0.15063640900007158\n",
      "Training model 635: (6,63) ...\n",
      "0.1367789249998168\n",
      "Training model 636: (6,64) ...\n",
      "0.12955412099972818\n",
      "Training model 637: (6,65) ...\n",
      "0.4030096550000053\n",
      "Training model 638: (6,66) ...\n",
      "0.12763254499986942\n",
      "Training model 639: (6,67) ...\n",
      "0.13337087599984443\n",
      "Training model 640: (6,68) ...\n",
      "0.13587215699999433\n",
      "Training model 641: (6,69) ...\n",
      "0.12285388700001931\n",
      "Training model 642: (6,70) ...\n",
      "0.11341265500004738\n",
      "Training model 643: (6,71) ...\n",
      "0.1478041860000303\n",
      "Training model 644: (6,72) ...\n",
      "0.10851704200013046\n",
      "Training model 645: (6,73) ...\n",
      "0.12461805600014486\n",
      "Training model 646: (6,74) ...\n",
      "0.10567186900016168\n",
      "Training model 647: (6,75) ...\n",
      "0.12044423199995435\n",
      "Training model 648: (6,76) ...\n",
      "0.1429680799997186\n",
      "Training model 649: (6,77) ...\n",
      "0.12121782700023687\n",
      "Training model 650: (6,78) ...\n",
      "0.15861954000001788\n",
      "Training model 651: (6,79) ...\n",
      "0.14614798200000223\n",
      "Training model 652: (6,80) ...\n",
      "0.11885060800022984\n",
      "Training model 653: (6,81) ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1381965760001549\n",
      "Training model 654: (6,82) ...\n",
      "0.11633233600014137\n",
      "Training model 655: (6,83) ...\n",
      "0.10724502300035965\n",
      "Training model 656: (6,84) ...\n",
      "0.12146330500036129\n",
      "Training model 657: (6,85) ...\n",
      "0.12973145099977046\n",
      "Training model 658: (6,86) ...\n",
      "0.12085679299980256\n",
      "Training model 659: (6,87) ...\n",
      "0.11788059899981818\n",
      "Training model 660: (6,88) ...\n",
      "0.12052808699991147\n",
      "Training model 661: (6,89) ...\n",
      "0.11886322800000926\n",
      "Training model 662: (6,90) ...\n",
      "0.10656751799979247\n",
      "Training model 663: (6,91) ...\n",
      "0.11335072700012461\n",
      "Training model 664: (6,92) ...\n",
      "0.10994885300033275\n",
      "Training model 665: (6,93) ...\n",
      "0.12493931299968608\n",
      "Training model 666: (6,94) ...\n",
      "0.11763296599974638\n",
      "Training model 667: (6,95) ...\n",
      "0.10178090299996256\n",
      "Training model 668: (6,96) ...\n",
      "0.12059205600007772\n",
      "Training model 669: (6,97) ...\n",
      "0.1364439509998192\n",
      "Training model 670: (6,98) ...\n",
      "0.12858739500006777\n",
      "Training model 671: (6,99) ...\n",
      "0.1257251060001181\n",
      "Training model 672: (7,8) ...\n",
      "0.5565605340002548\n",
      "Training model 673: (7,9) ...\n",
      "0.1612478810002358\n",
      "Training model 674: (7,10) ...\n",
      "0.12511371299979146\n",
      "Training model 675: (7,11) ...\n",
      "0.11865270399994188\n",
      "Training model 676: (7,12) ...\n",
      "0.17225045099985437\n",
      "Training model 677: (7,13) ...\n",
      "0.12584672399998453\n",
      "Training model 678: (7,14) ...\n",
      "0.1187758030000623\n",
      "Training model 679: (7,15) ...\n",
      "0.15297079499987376\n",
      "Training model 680: (7,16) ...\n",
      "0.1250554169996576\n",
      "Training model 681: (7,17) ...\n",
      "0.12871925199988254\n",
      "Training model 682: (7,18) ...\n",
      "0.1276783740004248\n",
      "Training model 683: (7,19) ...\n",
      "0.12956867100001546\n",
      "Training model 684: (7,20) ...\n",
      "0.12806702699981543\n",
      "Training model 685: (7,21) ...\n",
      "0.14321125800006484\n",
      "Training model 686: (7,22) ...\n",
      "0.15137452099997972\n",
      "Training model 687: (7,23) ...\n",
      "0.19578753699988738\n",
      "Training model 688: (7,24) ...\n",
      "0.11809974800007694\n",
      "Training model 689: (7,25) ...\n",
      "0.11698623799975394\n",
      "Training model 690: (7,26) ...\n",
      "0.1233665340000698\n",
      "Training model 691: (7,27) ...\n",
      "0.12379560599993056\n",
      "Training model 692: (7,28) ...\n",
      "0.11701949100006459\n",
      "Training model 693: (7,29) ...\n",
      "0.12713103499982026\n",
      "Training model 694: (7,30) ...\n",
      "0.11606413299978158\n",
      "Training model 695: (7,31) ...\n",
      "0.12052868299997499\n",
      "Training model 696: (7,32) ...\n",
      "0.12422565899987603\n",
      "Training model 697: (7,33) ...\n",
      "0.12760613799991916\n",
      "Training model 698: (7,34) ...\n",
      "0.1314387990000796\n",
      "Training model 699: (7,35) ...\n",
      "0.12095682300014232\n",
      "Training model 700: (7,36) ...\n",
      "0.1445978510000714\n",
      "Training model 701: (7,37) ...\n",
      "0.1269770620001509\n",
      "Training model 702: (7,38) ...\n",
      "0.1176861829999325\n",
      "Training model 703: (7,39) ...\n",
      "0.15556388200002402\n",
      "Training model 704: (7,40) ...\n",
      "0.11525586700008716\n",
      "Training model 705: (7,41) ...\n",
      "0.11135903799959124\n",
      "Training model 706: (7,42) ...\n",
      "0.13450367399991592\n",
      "Training model 707: (7,43) ...\n",
      "0.140801435999947\n",
      "Training model 708: (7,44) ...\n",
      "0.1164469850000387\n",
      "Training model 709: (7,45) ...\n",
      "0.11615253700028916\n",
      "Training model 710: (7,46) ...\n",
      "0.11304440300000351\n",
      "Training model 711: (7,47) ...\n",
      "0.23624106999977812\n",
      "Training model 712: (7,48) ...\n",
      "0.1176145849999557\n",
      "Training model 713: (7,49) ...\n",
      "0.11713334000023679\n",
      "Training model 714: (7,50) ...\n",
      "0.12832719600010023\n",
      "Training model 715: (7,51) ...\n",
      "0.14012401300033162\n",
      "Training model 716: (7,52) ...\n",
      "0.11411102900001424\n",
      "Training model 717: (7,53) ...\n",
      "0.12762457700000596\n",
      "Training model 718: (7,54) ...\n",
      "0.13116872899990994\n",
      "Training model 719: (7,55) ...\n",
      "0.10474927999985084\n",
      "Training model 720: (7,56) ...\n",
      "0.12890184099978796\n",
      "Training model 721: (7,57) ...\n",
      "0.11306532199978392\n",
      "Training model 722: (7,58) ...\n",
      "0.13188424300005863\n",
      "Training model 723: (7,59) ...\n",
      "0.1080288829998608\n",
      "Training model 724: (7,60) ...\n",
      "0.14631169999984195\n",
      "Training model 725: (7,61) ...\n",
      "0.14370719999988069\n",
      "Training model 726: (7,62) ...\n",
      "0.13829129300029308\n",
      "Training model 727: (7,63) ...\n",
      "0.15660327700015841\n",
      "Training model 728: (7,64) ...\n",
      "0.12079821800034551\n",
      "Training model 729: (7,65) ...\n",
      "0.12080162800020844\n",
      "Training model 730: (7,66) ...\n",
      "0.10761753799988583\n",
      "Training model 731: (7,67) ...\n",
      "0.12381714699995428\n",
      "Training model 732: (7,68) ...\n",
      "0.10742866200007484\n",
      "Training model 733: (7,69) ...\n",
      "0.10568174200034264\n",
      "Training model 734: (7,70) ...\n",
      "0.10490288299979511\n",
      "Training model 735: (7,71) ...\n",
      "0.13007388200003334\n",
      "Training model 736: (7,72) ...\n",
      "0.1015587020001476\n",
      "Training model 737: (7,73) ...\n",
      "0.1178533810002591\n",
      "Training model 738: (7,74) ...\n",
      "0.10852687199985667\n",
      "Training model 739: (7,75) ...\n",
      "0.11204773999997997\n",
      "Training model 740: (7,76) ...\n",
      "0.15225018099999943\n",
      "Training model 741: (7,77) ...\n",
      "0.11394960699999501\n",
      "Training model 742: (7,78) ...\n",
      "0.12871832199971323\n",
      "Training model 743: (7,79) ...\n",
      "0.12899264699990454\n",
      "Training model 744: (7,80) ...\n",
      "0.15205097800026124\n",
      "Training model 745: (7,81) ...\n",
      "0.12685356100018907\n",
      "Training model 746: (7,82) ...\n",
      "0.15575931200010018\n",
      "Training model 747: (7,83) ...\n",
      "0.12925813200035918\n",
      "Training model 748: (7,84) ...\n",
      "0.14415562199974374\n",
      "Training model 749: (7,85) ...\n",
      "0.14989989999958198\n",
      "Training model 750: (7,86) ...\n",
      "0.18812374499975704\n",
      "Training model 751: (7,87) ...\n",
      "0.15218720599978042\n",
      "Training model 752: (7,88) ...\n",
      "0.20866436000005706\n",
      "Training model 753: (7,89) ...\n",
      "0.13183119800032728\n",
      "Training model 754: (7,90) ...\n",
      "0.2061301399999138\n",
      "Training model 755: (7,91) ...\n",
      "0.1765734259997771\n",
      "Training model 756: (7,92) ...\n",
      "0.11795669799994357\n",
      "Training model 757: (7,93) ...\n",
      "0.18324127500000031\n",
      "Training model 758: (7,94) ...\n",
      "0.15118478600015806\n",
      "Training model 759: (7,95) ...\n",
      "0.10931066200009809\n",
      "Training model 760: (7,96) ...\n",
      "0.1411176440001327\n",
      "Training model 761: (7,97) ...\n",
      "0.1438306330001069\n",
      "Training model 762: (7,98) ...\n",
      "0.1157747610000115\n",
      "Training model 763: (7,99) ...\n",
      "0.15744067500008896\n",
      "Training model 764: (8,9) ...\n",
      "0.18869783099989945\n",
      "Training model 765: (8,10) ...\n",
      "0.13661652299970228\n",
      "Training model 766: (8,11) ...\n",
      "0.11943810299999313\n",
      "Training model 767: (8,12) ...\n",
      "0.18676828499974363\n",
      "Training model 768: (8,13) ...\n",
      "0.14570329100024537\n",
      "Training model 769: (8,14) ...\n",
      "0.12616755400040347\n",
      "Training model 770: (8,15) ...\n",
      "0.15103078299989647\n",
      "Training model 771: (8,16) ...\n",
      "0.13173267899992425\n",
      "Training model 772: (8,17) ...\n",
      "0.1332634059999691\n",
      "Training model 773: (8,18) ...\n",
      "0.14498533500000121\n",
      "Training model 774: (8,19) ...\n",
      "0.13086071899988383\n",
      "Training model 775: (8,20) ...\n",
      "0.1355017979999502\n",
      "Training model 776: (8,21) ...\n",
      "0.15472670999997717\n",
      "Training model 777: (8,22) ...\n",
      "0.1573860749999767\n",
      "Training model 778: (8,23) ...\n",
      "0.23430938199999218\n",
      "Training model 779: (8,24) ...\n",
      "0.1322018300002128\n",
      "Training model 780: (8,25) ...\n",
      "0.11767999699986831\n",
      "Training model 781: (8,26) ...\n",
      "0.12642807700012781\n",
      "Training model 782: (8,27) ...\n",
      "0.12300243099980435\n",
      "Training model 783: (8,28) ...\n",
      "0.12043635300005917\n",
      "Training model 784: (8,29) ...\n",
      "0.15046819999997751\n",
      "Training model 785: (8,30) ...\n",
      "0.125663593000354\n",
      "Training model 786: (8,31) ...\n",
      "0.12667237900041073\n",
      "Training model 787: (8,32) ...\n",
      "0.14385298000024704\n",
      "Training model 788: (8,33) ...\n",
      "0.13787376400023277\n",
      "Training model 789: (8,34) ...\n",
      "0.14352426000004925\n",
      "Training model 790: (8,35) ...\n",
      "0.1306314570001632\n",
      "Training model 791: (8,36) ...\n",
      "0.1564663539998037\n",
      "Training model 792: (8,37) ...\n",
      "0.13276270500000464\n",
      "Training model 793: (8,38) ...\n",
      "0.12904875399999582\n",
      "Training model 794: (8,39) ...\n",
      "0.17812815699971907\n",
      "Training model 795: (8,40) ...\n",
      "0.13077730099985274\n",
      "Training model 796: (8,41) ...\n",
      "0.1259544790000291\n",
      "Training model 797: (8,42) ...\n",
      "0.1435363190003045\n",
      "Training model 798: (8,43) ...\n",
      "0.15281289300037315\n",
      "Training model 799: (8,44) ...\n",
      "0.12371983999992153\n",
      "Training model 800: (8,45) ...\n",
      "0.1362480000002506\n",
      "Training model 801: (8,46) ...\n",
      "0.12202486900014264\n",
      "Training model 802: (8,47) ...\n",
      "0.13571540900011314\n",
      "Training model 803: (8,48) ...\n",
      "0.14388581299999714\n",
      "Training model 804: (8,49) ...\n",
      "0.1372205220000069\n",
      "Training model 805: (8,50) ...\n",
      "0.14654271400013386\n",
      "Training model 806: (8,51) ...\n",
      "0.1422445590001189\n",
      "Training model 807: (8,52) ...\n",
      "0.1241058239997983\n",
      "Training model 808: (8,53) ...\n",
      "0.1297986779995881\n",
      "Training model 809: (8,54) ...\n",
      "0.1440573250001762\n",
      "Training model 810: (8,55) ...\n",
      "0.11058753099996466\n",
      "Training model 811: (8,56) ...\n",
      "0.142544141000144\n",
      "Training model 812: (8,57) ...\n",
      "0.11750030999974115\n",
      "Training model 813: (8,58) ...\n",
      "0.1434961279996969\n",
      "Training model 814: (8,59) ...\n",
      "0.10940049999999246\n",
      "Training model 815: (8,60) ...\n",
      "0.1523182910000287\n",
      "Training model 816: (8,61) ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.15703681600007258\n",
      "Training model 817: (8,62) ...\n",
      "0.146369310999944\n",
      "Training model 818: (8,63) ...\n",
      "0.1651311080004234\n",
      "Training model 819: (8,64) ...\n",
      "0.12043387500034441\n",
      "Training model 820: (8,65) ...\n",
      "0.12086096199982421\n",
      "Training model 821: (8,66) ...\n",
      "0.12992844000018522\n",
      "Training model 822: (8,67) ...\n",
      "0.14616243500040582\n",
      "Training model 823: (8,68) ...\n",
      "0.11961920900012046\n",
      "Training model 824: (8,69) ...\n",
      "0.12629770800003826\n",
      "Training model 825: (8,70) ...\n",
      "0.11975968300021123\n",
      "Training model 826: (8,71) ...\n",
      "0.14338228799988428\n",
      "Training model 827: (8,72) ...\n",
      "0.11503406500014535\n",
      "Training model 828: (8,73) ...\n",
      "0.12465759699989576\n",
      "Training model 829: (8,74) ...\n",
      "0.13004899899988231\n",
      "Training model 830: (8,75) ...\n",
      "0.11685621799961154\n",
      "Training model 831: (8,76) ...\n",
      "0.15802669000004244\n",
      "Training model 832: (8,77) ...\n",
      "0.13199890499981848\n",
      "Training model 833: (8,78) ...\n",
      "0.134327267000117\n",
      "Training model 834: (8,79) ...\n",
      "0.13872358400021767\n",
      "Training model 835: (8,80) ...\n",
      "0.17372237300014604\n",
      "Training model 836: (8,81) ...\n",
      "0.18532837600014318\n",
      "Training model 837: (8,82) ...\n",
      "0.20211730999972133\n",
      "Training model 838: (8,83) ...\n",
      "0.1512822849999793\n",
      "Training model 839: (8,84) ...\n",
      "0.15429025000003094\n",
      "Training model 840: (8,85) ...\n",
      "0.1792649789999814\n",
      "Training model 841: (8,86) ...\n",
      "0.22324145199991108\n",
      "Training model 842: (8,87) ...\n",
      "0.14216819000012038\n",
      "Training model 843: (8,88) ...\n",
      "0.20403634700005568\n",
      "Training model 844: (8,89) ...\n",
      "0.1506049949998669\n",
      "Training model 845: (8,90) ...\n",
      "0.14978888399991774\n",
      "Training model 846: (8,91) ...\n",
      "0.1739806129999124\n",
      "Training model 847: (8,92) ...\n",
      "0.12248191399976349\n",
      "Training model 848: (8,93) ...\n",
      "0.17150402000015674\n",
      "Training model 849: (8,94) ...\n",
      "0.1388802520000354\n",
      "Training model 850: (8,95) ...\n",
      "0.12311074499984898\n",
      "Training model 851: (8,96) ...\n",
      "0.1406594159998349\n",
      "Training model 852: (8,97) ...\n",
      "0.17924951799977862\n",
      "Training model 853: (8,98) ...\n",
      "0.12482280099993659\n",
      "Training model 854: (8,99) ...\n",
      "0.17994888599969272\n",
      "Training model 855: (9,10) ...\n",
      "0.12196271999982855\n",
      "Training model 856: (9,11) ...\n",
      "0.12437703199975658\n",
      "Training model 857: (9,12) ...\n",
      "0.14081687799989595\n",
      "Training model 858: (9,13) ...\n",
      "0.1474952309999935\n",
      "Training model 859: (9,14) ...\n",
      "0.11976030599998921\n",
      "Training model 860: (9,15) ...\n",
      "0.13403212000002895\n",
      "Training model 861: (9,16) ...\n",
      "0.12204182100003891\n",
      "Training model 862: (9,17) ...\n",
      "0.14503251499991165\n",
      "Training model 863: (9,18) ...\n",
      "0.16292420000036145\n",
      "Training model 864: (9,19) ...\n",
      "0.14514948999976696\n",
      "Training model 865: (9,20) ...\n",
      "0.13321735099998477\n",
      "Training model 866: (9,21) ...\n",
      "0.16310556300004464\n",
      "Training model 867: (9,22) ...\n",
      "0.1483776680001938\n",
      "Training model 868: (9,23) ...\n",
      "0.23135079500025313\n",
      "Training model 869: (9,24) ...\n",
      "0.15149264699994092\n",
      "Training model 870: (9,25) ...\n",
      "0.11104516899968075\n",
      "Training model 871: (9,26) ...\n",
      "0.12298577799992927\n",
      "Training model 872: (9,27) ...\n",
      "0.10969294799997442\n",
      "Training model 873: (9,28) ...\n",
      "0.10594203299979199\n",
      "Training model 874: (9,29) ...\n",
      "0.12013926500003436\n",
      "Training model 875: (9,30) ...\n",
      "0.11292204000028505\n",
      "Training model 876: (9,31) ...\n",
      "0.11695981900038532\n",
      "Training model 877: (9,32) ...\n",
      "0.12064043800000945\n",
      "Training model 878: (9,33) ...\n",
      "0.11426263199973619\n",
      "Training model 879: (9,34) ...\n",
      "0.1350066620002508\n",
      "Training model 880: (9,35) ...\n",
      "0.11943072700023549\n",
      "Training model 881: (9,36) ...\n",
      "0.14785253500031104\n",
      "Training model 882: (9,37) ...\n",
      "0.11219579399994473\n",
      "Training model 883: (9,38) ...\n",
      "0.11819738099984534\n",
      "Training model 884: (9,39) ...\n",
      "0.16146708099995521\n",
      "Training model 885: (9,40) ...\n",
      "0.11854450300006647\n",
      "Training model 886: (9,41) ...\n",
      "0.11967744499997934\n",
      "Training model 887: (9,42) ...\n",
      "0.1267015800003719\n",
      "Training model 888: (9,43) ...\n",
      "0.1330266620002476\n",
      "Training model 889: (9,44) ...\n",
      "0.12089686599983906\n",
      "Training model 890: (9,45) ...\n",
      "0.12675249799985977\n",
      "Training model 891: (9,46) ...\n",
      "0.11787664099983886\n",
      "Training model 892: (9,47) ...\n",
      "0.12540199499972005\n",
      "Training model 893: (9,48) ...\n",
      "0.13811223199991218\n",
      "Training model 894: (9,49) ...\n",
      "0.15212167199979376\n",
      "Training model 895: (9,50) ...\n",
      "0.15120444800004407\n",
      "Training model 896: (9,51) ...\n",
      "0.12943148499971358\n",
      "Training model 897: (9,52) ...\n",
      "0.11556034299974272\n",
      "Training model 898: (9,53) ...\n",
      "0.12674545600020792\n",
      "Training model 899: (9,54) ...\n",
      "0.13032373400028519\n",
      "Training model 900: (9,55) ...\n",
      "0.11052829500022199\n",
      "Training model 901: (9,56) ...\n",
      "0.11712192699997104\n",
      "Training model 902: (9,57) ...\n",
      "0.11226657699990028\n",
      "Training model 903: (9,58) ...\n",
      "0.13281895599993732\n",
      "Training model 904: (9,59) ...\n",
      "0.11822755600042001\n",
      "Training model 905: (9,60) ...\n",
      "0.1289624979999644\n",
      "Training model 906: (9,61) ...\n",
      "0.12513527600003727\n",
      "Training model 907: (9,62) ...\n",
      "0.13618534400029603\n",
      "Training model 908: (9,63) ...\n",
      "0.16793295100023897\n",
      "Training model 909: (9,64) ...\n",
      "0.12242828200032818\n",
      "Training model 910: (9,65) ...\n",
      "0.11635619700018651\n",
      "Training model 911: (9,66) ...\n",
      "0.1250113850001071\n",
      "Training model 912: (9,67) ...\n",
      "0.13507003099994108\n",
      "Training model 913: (9,68) ...\n",
      "0.12163172100008524\n",
      "Training model 914: (9,69) ...\n",
      "0.1135670079997908\n",
      "Training model 915: (9,70) ...\n",
      "0.11196771499999159\n",
      "Training model 916: (9,71) ...\n",
      "0.12185497099972054\n",
      "Training model 917: (9,72) ...\n",
      "0.10812032600006205\n",
      "Training model 918: (9,73) ...\n",
      "0.11855071800027872\n",
      "Training model 919: (9,74) ...\n",
      "0.10790476299962393\n",
      "Training model 920: (9,75) ...\n",
      "0.11099611800000275\n",
      "Training model 921: (9,76) ...\n",
      "0.13791033899997274\n",
      "Training model 922: (9,77) ...\n",
      "0.12815866899973116\n",
      "Training model 923: (9,78) ...\n",
      "0.1190670810001393\n",
      "Training model 924: (9,79) ...\n",
      "0.13191581099999894\n",
      "Training model 925: (9,80) ...\n",
      "0.18221836700013228\n",
      "Training model 926: (9,81) ...\n",
      "0.13897203600026842\n",
      "Training model 927: (9,82) ...\n",
      "0.1824871699996038\n",
      "Training model 928: (9,83) ...\n",
      "0.14363455400007297\n",
      "Training model 929: (9,84) ...\n",
      "0.1787550219996774\n",
      "Training model 930: (9,85) ...\n",
      "0.20506150699975478\n",
      "Training model 931: (9,86) ...\n",
      "0.1542537230002381\n",
      "Training model 932: (9,87) ...\n",
      "0.13371061600037137\n",
      "Training model 933: (9,88) ...\n",
      "0.13067885100008425\n",
      "Training model 934: (9,89) ...\n",
      "0.13091389200008052\n",
      "Training model 935: (9,90) ...\n",
      "0.1095599659997788\n",
      "Training model 936: (9,91) ...\n",
      "0.1357925699999214\n",
      "Training model 937: (9,92) ...\n",
      "0.12107485699971221\n",
      "Training model 938: (9,93) ...\n",
      "0.16853008699990824\n",
      "Training model 939: (9,94) ...\n",
      "0.1326386430000639\n",
      "Training model 940: (9,95) ...\n",
      "0.11557632299991383\n",
      "Training model 941: (9,96) ...\n",
      "0.13480176000030042\n",
      "Training model 942: (9,97) ...\n",
      "0.12866141800031983\n",
      "Training model 943: (9,98) ...\n",
      "0.12413984399972833\n",
      "Training model 944: (9,99) ...\n",
      "0.2203109580000273\n",
      "Training model 945: (10,11) ...\n",
      "0.19153054499975042\n",
      "Training model 946: (10,12) ...\n",
      "0.2602351760001511\n",
      "Training model 947: (10,13) ...\n",
      "0.24406554600000163\n",
      "Training model 948: (10,14) ...\n",
      "0.140848403000291\n",
      "Training model 949: (10,15) ...\n",
      "0.3377842680001777\n",
      "Training model 950: (10,16) ...\n",
      "0.19347439500006658\n",
      "Training model 951: (10,17) ...\n",
      "0.16740001300013319\n",
      "Training model 952: (10,18) ...\n",
      "0.16800138400003561\n",
      "Training model 953: (10,19) ...\n",
      "0.21487095399970713\n",
      "Training model 954: (10,20) ...\n",
      "0.14697268899999472\n",
      "Training model 955: (10,21) ...\n",
      "0.1861720269998841\n",
      "Training model 956: (10,22) ...\n",
      "0.18337807400030215\n",
      "Training model 957: (10,23) ...\n",
      "0.18347489300003872\n",
      "Training model 958: (10,24) ...\n",
      "0.14792525400025625\n",
      "Training model 959: (10,25) ...\n",
      "0.13649627100039652\n",
      "Training model 960: (10,26) ...\n",
      "0.15794092799978898\n",
      "Training model 961: (10,27) ...\n",
      "0.13158679400021356\n",
      "Training model 962: (10,28) ...\n",
      "0.126647002000027\n",
      "Training model 963: (10,29) ...\n",
      "0.1252698439998312\n",
      "Training model 964: (10,30) ...\n",
      "0.138508333000118\n",
      "Training model 965: (10,31) ...\n",
      "0.1230064169999423\n",
      "Training model 966: (10,32) ...\n",
      "0.1488947839998218\n",
      "Training model 967: (10,33) ...\n",
      "0.1238725160001195\n",
      "Training model 968: (10,34) ...\n",
      "0.12073918500027503\n",
      "Training model 969: (10,35) ...\n",
      "0.12259077399994567\n",
      "Training model 970: (10,36) ...\n",
      "0.15358377099983045\n",
      "Training model 971: (10,37) ...\n",
      "0.12833541200006948\n",
      "Training model 972: (10,38) ...\n",
      "0.15402292999988276\n",
      "Training model 973: (10,39) ...\n",
      "0.14693918900002245\n",
      "Training model 974: (10,40) ...\n",
      "0.1260685709999052\n",
      "Training model 975: (10,41) ...\n",
      "0.14244690099985746\n",
      "Training model 976: (10,42) ...\n",
      "0.16049904700003026\n",
      "Training model 977: (10,43) ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.15284594900003867\n",
      "Training model 978: (10,44) ...\n",
      "0.14904948899993542\n",
      "Training model 979: (10,45) ...\n",
      "0.12199121000003288\n",
      "Training model 980: (10,46) ...\n",
      "0.1261624369999481\n",
      "Training model 981: (10,47) ...\n",
      "0.13999429099976624\n",
      "Training model 982: (10,48) ...\n",
      "0.11241318800011868\n",
      "Training model 983: (10,49) ...\n",
      "0.12877243399998406\n",
      "Training model 984: (10,50) ...\n",
      "0.13465978599970185\n",
      "Training model 985: (10,51) ...\n",
      "0.12810052199984057\n",
      "Training model 986: (10,52) ...\n",
      "0.132907447999969\n",
      "Training model 987: (10,53) ...\n",
      "0.1477179389999037\n",
      "Training model 988: (10,54) ...\n",
      "0.15193634200022643\n",
      "Training model 989: (10,55) ...\n",
      "0.11180319999994026\n",
      "Training model 990: (10,56) ...\n",
      "0.12941897800010338\n",
      "Training model 991: (10,57) ...\n",
      "0.13953286199966897\n",
      "Training model 992: (10,58) ...\n",
      "0.15796331599995028\n",
      "Training model 993: (10,59) ...\n",
      "0.12470038700030273\n",
      "Training model 994: (10,60) ...\n",
      "0.1568581529995754\n",
      "Training model 995: (10,61) ...\n",
      "0.13655881600016073\n",
      "Training model 996: (10,62) ...\n",
      "0.1560658999997031\n",
      "Training model 997: (10,63) ...\n",
      "0.14968147299987322\n",
      "Training model 998: (10,64) ...\n",
      "0.12799181199989107\n",
      "Training model 999: (10,65) ...\n",
      "0.12552685899981952\n",
      "Training model 1000: (10,66) ...\n",
      "0.13649729999997362\n",
      "Training model 1001: (10,67) ...\n",
      "0.13175420300012775\n",
      "Training model 1002: (10,68) ...\n",
      "0.13221048500008692\n",
      "Training model 1003: (10,69) ...\n",
      "0.10336423900025693\n",
      "Training model 1004: (10,70) ...\n",
      "0.1370339420000164\n",
      "Training model 1005: (10,71) ...\n",
      "0.1521234540000478\n",
      "Training model 1006: (10,72) ...\n",
      "0.1372099570003229\n",
      "Training model 1007: (10,73) ...\n",
      "0.14699733299994477\n",
      "Training model 1008: (10,74) ...\n",
      "0.1447330050000346\n",
      "Training model 1009: (10,75) ...\n",
      "0.13062661000003573\n",
      "Training model 1010: (10,76) ...\n",
      "0.14252843899976142\n",
      "Training model 1011: (10,77) ...\n",
      "0.15119972399998005\n",
      "Training model 1012: (10,78) ...\n",
      "0.14157592499987004\n",
      "Training model 1013: (10,79) ...\n",
      "0.13829772899998716\n",
      "Training model 1014: (10,80) ...\n",
      "0.14547592899998563\n",
      "Training model 1015: (10,81) ...\n",
      "0.1746538209999926\n",
      "Training model 1016: (10,82) ...\n",
      "0.20928802400021596\n",
      "Training model 1017: (10,83) ...\n",
      "0.15540850000024875\n",
      "Training model 1018: (10,84) ...\n",
      "0.12299609999990935\n",
      "Training model 1019: (10,85) ...\n",
      "0.17683832300008362\n",
      "Training model 1020: (10,86) ...\n",
      "0.20699007300027006\n",
      "Training model 1021: (10,87) ...\n",
      "0.11964729500004978\n",
      "Training model 1022: (10,88) ...\n",
      "0.13581331800014596\n",
      "Training model 1023: (10,89) ...\n",
      "0.14691009299986035\n",
      "Training model 1024: (10,90) ...\n",
      "0.12992950599982578\n",
      "Training model 1025: (10,91) ...\n",
      "0.2218652340002336\n",
      "Training model 1026: (10,92) ...\n",
      "0.21414155299999038\n",
      "Training model 1027: (10,93) ...\n",
      "0.1960022640000716\n",
      "Training model 1028: (10,94) ...\n",
      "0.207334438000089\n",
      "Training model 1029: (10,95) ...\n",
      "0.18199983199974668\n",
      "Training model 1030: (10,96) ...\n",
      "0.14177901400034898\n",
      "Training model 1031: (10,97) ...\n",
      "0.13325199100017926\n",
      "Training model 1032: (10,98) ...\n",
      "0.13475112600008288\n",
      "Training model 1033: (10,99) ...\n",
      "0.14131463499961683\n",
      "Training model 1034: (11,12) ...\n",
      "0.1719219400001748\n",
      "Training model 1035: (11,13) ...\n",
      "0.1554746429997067\n",
      "Training model 1036: (11,14) ...\n",
      "0.1841483729999709\n",
      "Training model 1037: (11,15) ...\n",
      "0.18066984799997954\n",
      "Training model 1038: (11,16) ...\n",
      "0.22869270599994707\n",
      "Training model 1039: (11,17) ...\n",
      "0.15924767300020903\n",
      "Training model 1040: (11,18) ...\n",
      "0.1396915989998888\n",
      "Training model 1041: (11,19) ...\n",
      "0.16481817900012175\n",
      "Training model 1042: (11,20) ...\n",
      "0.12479732099973262\n",
      "Training model 1043: (11,21) ...\n",
      "0.13575607300026604\n",
      "Training model 1044: (11,22) ...\n",
      "0.14004027500004668\n",
      "Training model 1045: (11,23) ...\n",
      "0.14166641700012406\n",
      "Training model 1046: (11,24) ...\n",
      "0.11264826200022071\n",
      "Training model 1047: (11,25) ...\n",
      "0.12694594499998857\n",
      "Training model 1048: (11,26) ...\n",
      "0.12522780900008001\n",
      "Training model 1049: (11,27) ...\n",
      "0.10833133500000258\n",
      "Training model 1050: (11,28) ...\n",
      "0.12314817299966307\n",
      "Training model 1051: (11,29) ...\n",
      "0.12104913700022735\n",
      "Training model 1052: (11,30) ...\n",
      "0.12901009100005467\n",
      "Training model 1053: (11,31) ...\n",
      "0.15909901199984233\n",
      "Training model 1054: (11,32) ...\n",
      "0.12261500000022352\n",
      "Training model 1055: (11,33) ...\n",
      "0.11347230999990643\n",
      "Training model 1056: (11,34) ...\n",
      "0.10867665400019177\n",
      "Training model 1057: (11,35) ...\n",
      "0.10548039500008599\n",
      "Training model 1058: (11,36) ...\n",
      "0.13430276499957472\n",
      "Training model 1059: (11,37) ...\n",
      "0.11023741700000755\n",
      "Training model 1060: (11,38) ...\n",
      "0.11338984199983315\n",
      "Training model 1061: (11,39) ...\n",
      "0.13408645200024694\n",
      "Training model 1062: (11,40) ...\n",
      "0.1596433300001081\n",
      "Training model 1063: (11,41) ...\n",
      "0.10356011499970919\n",
      "Training model 1064: (11,42) ...\n",
      "0.13062514500006728\n",
      "Training model 1065: (11,43) ...\n",
      "0.12077008999995087\n",
      "Training model 1066: (11,44) ...\n",
      "0.11437047400022493\n",
      "Training model 1067: (11,45) ...\n",
      "0.09986469700015732\n",
      "Training model 1068: (11,46) ...\n",
      "0.14881207300004462\n",
      "Training model 1069: (11,47) ...\n",
      "0.14110684100023718\n",
      "Training model 1070: (11,48) ...\n",
      "0.10181705300010435\n",
      "Training model 1071: (11,49) ...\n",
      "0.11051019000024098\n",
      "Training model 1072: (11,50) ...\n",
      "0.1154748250000921\n",
      "Training model 1073: (11,51) ...\n",
      "0.11092713199968784\n",
      "Training model 1074: (11,52) ...\n",
      "0.11391196299973672\n",
      "Training model 1075: (11,53) ...\n",
      "0.13271917600013694\n",
      "Training model 1076: (11,54) ...\n",
      "0.11600004299998545\n",
      "Training model 1077: (11,55) ...\n",
      "0.14159618499979842\n",
      "Training model 1078: (11,56) ...\n",
      "0.1167268970002624\n",
      "Training model 1079: (11,57) ...\n",
      "0.10810105099972134\n",
      "Training model 1080: (11,58) ...\n",
      "0.13613838800029043\n",
      "Training model 1081: (11,59) ...\n",
      "0.15732536599989544\n",
      "Training model 1082: (11,60) ...\n",
      "0.12648184099998616\n",
      "Training model 1083: (11,61) ...\n",
      "0.11292911800001093\n",
      "Training model 1084: (11,62) ...\n",
      "0.11767616699989958\n",
      "Training model 1085: (11,63) ...\n",
      "0.12405177499977071\n",
      "Training model 1086: (11,64) ...\n",
      "0.14888468499975716\n",
      "Training model 1087: (11,65) ...\n",
      "0.11394014900042748\n",
      "Training model 1088: (11,66) ...\n",
      "0.10722177599973293\n",
      "Training model 1089: (11,67) ...\n",
      "0.10730960699993375\n",
      "Training model 1090: (11,68) ...\n",
      "0.10119985899973472\n",
      "Training model 1091: (11,69) ...\n",
      "0.09679700100014088\n",
      "Training model 1092: (11,70) ...\n",
      "0.12920636599983482\n",
      "Training model 1093: (11,71) ...\n",
      "0.1136813930002063\n",
      "Training model 1094: (11,72) ...\n",
      "0.16368713199972262\n",
      "Training model 1095: (11,73) ...\n",
      "0.13377578600011475\n",
      "Training model 1096: (11,74) ...\n",
      "0.1504976730002454\n",
      "Training model 1097: (11,75) ...\n",
      "0.11773456699984308\n",
      "Training model 1098: (11,76) ...\n",
      "0.11483778199999506\n",
      "Training model 1099: (11,77) ...\n",
      "0.12814728500006822\n",
      "Training model 1100: (11,78) ...\n",
      "0.11783687099978124\n",
      "Training model 1101: (11,79) ...\n",
      "0.11655063100033658\n",
      "Training model 1102: (11,80) ...\n",
      "0.11023206500021843\n",
      "Training model 1103: (11,81) ...\n",
      "0.11507819600001312\n",
      "Training model 1104: (11,82) ...\n",
      "0.12266965800017715\n",
      "Training model 1105: (11,83) ...\n",
      "0.11042718299995613\n",
      "Training model 1106: (11,84) ...\n",
      "0.14156121599990001\n",
      "Training model 1107: (11,85) ...\n",
      "0.13819539999985864\n",
      "Training model 1108: (11,86) ...\n",
      "0.13190339199991286\n",
      "Training model 1109: (11,87) ...\n",
      "0.1162862920000407\n",
      "Training model 1110: (11,88) ...\n",
      "0.17086242699997456\n",
      "Training model 1111: (11,89) ...\n",
      "0.13894795399983195\n",
      "Training model 1112: (11,90) ...\n",
      "0.14838141700010965\n",
      "Training model 1113: (11,91) ...\n",
      "0.1551573360002294\n",
      "Training model 1114: (11,92) ...\n",
      "0.2680298089999269\n",
      "Training model 1115: (11,93) ...\n",
      "0.1718854589998955\n",
      "Training model 1116: (11,94) ...\n",
      "0.21274115000005622\n",
      "Training model 1117: (11,95) ...\n",
      "0.15706077599998025\n",
      "Training model 1118: (11,96) ...\n",
      "0.17041308900024887\n",
      "Training model 1119: (11,97) ...\n",
      "0.12617993900039437\n",
      "Training model 1120: (11,98) ...\n",
      "0.11091219500031002\n",
      "Training model 1121: (11,99) ...\n",
      "0.12128755799994906\n",
      "Training model 1122: (12,13) ...\n",
      "0.22307578899972214\n",
      "Training model 1123: (12,14) ...\n",
      "0.17305276499973843\n",
      "Training model 1124: (12,15) ...\n",
      "0.2665299430000232\n",
      "Training model 1125: (12,16) ...\n",
      "0.26348372999973435\n",
      "Training model 1126: (12,17) ...\n",
      "0.16771403299981102\n",
      "Training model 1127: (12,18) ...\n",
      "0.1681470979997357\n",
      "Training model 1128: (12,19) ...\n",
      "0.17912435700009155\n",
      "Training model 1129: (12,20) ...\n",
      "0.13462916900016353\n",
      "Training model 1130: (12,21) ...\n",
      "0.21411249099992347\n",
      "Training model 1131: (12,22) ...\n",
      "0.1852817569997569\n",
      "Training model 1132: (12,23) ...\n",
      "0.20614230399996814\n",
      "Training model 1133: (12,24) ...\n",
      "0.13652745799981858\n",
      "Training model 1134: (12,25) ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.11504005100005088\n",
      "Training model 1135: (12,26) ...\n",
      "0.12966914300022836\n",
      "Training model 1136: (12,27) ...\n",
      "0.13403938500005097\n",
      "Training model 1137: (12,28) ...\n",
      "0.12051971300024888\n",
      "Training model 1138: (12,29) ...\n",
      "0.1256536240002788\n",
      "Training model 1139: (12,30) ...\n",
      "0.1277976370001852\n",
      "Training model 1140: (12,31) ...\n",
      "0.12172358699990582\n",
      "Training model 1141: (12,32) ...\n",
      "0.12840602699998271\n",
      "Training model 1142: (12,33) ...\n",
      "0.11661432100027014\n",
      "Training model 1143: (12,34) ...\n",
      "0.12014017999990756\n",
      "Training model 1144: (12,35) ...\n",
      "0.12754729900007078\n",
      "Training model 1145: (12,36) ...\n",
      "0.14596461700011787\n",
      "Training model 1146: (12,37) ...\n",
      "0.11983846299972356\n",
      "Training model 1147: (12,38) ...\n",
      "0.1238932979999845\n",
      "Training model 1148: (12,39) ...\n",
      "0.15388004499982344\n",
      "Training model 1149: (12,40) ...\n",
      "0.14374185199994827\n",
      "Training model 1150: (12,41) ...\n",
      "0.13197749500022837\n",
      "Training model 1151: (12,42) ...\n",
      "0.14021434400001453\n",
      "Training model 1152: (12,43) ...\n",
      "0.14590500699978293\n",
      "Training model 1153: (12,44) ...\n",
      "0.13022024299971235\n",
      "Training model 1154: (12,45) ...\n",
      "0.11751112299998567\n",
      "Training model 1155: (12,46) ...\n",
      "0.1326605260001088\n",
      "Training model 1156: (12,47) ...\n",
      "0.13236240400010502\n",
      "Training model 1157: (12,48) ...\n",
      "0.11900555600004736\n",
      "Training model 1158: (12,49) ...\n",
      "0.12166770800013182\n",
      "Training model 1159: (12,50) ...\n",
      "0.13321343899997373\n",
      "Training model 1160: (12,51) ...\n",
      "0.1265365770000244\n",
      "Training model 1161: (12,52) ...\n",
      "0.12363914499974271\n",
      "Training model 1162: (12,53) ...\n",
      "0.13305322499991235\n",
      "Training model 1163: (12,54) ...\n",
      "0.12159782799972163\n",
      "Training model 1164: (12,55) ...\n",
      "0.11973821499987025\n",
      "Training model 1165: (12,56) ...\n",
      "0.12249551400009295\n",
      "Training model 1166: (12,57) ...\n",
      "0.12947149699994043\n",
      "Training model 1167: (12,58) ...\n",
      "0.14464261200009787\n",
      "Training model 1168: (12,59) ...\n",
      "0.14136862700024722\n",
      "Training model 1169: (12,60) ...\n",
      "0.13857348500005173\n",
      "Training model 1170: (12,61) ...\n",
      "0.13556739600016954\n",
      "Training model 1171: (12,62) ...\n",
      "0.1291229230000681\n",
      "Training model 1172: (12,63) ...\n",
      "0.13951249999990978\n",
      "Training model 1173: (12,64) ...\n",
      "0.13617411599989282\n",
      "Training model 1174: (12,65) ...\n",
      "0.11773836399970605\n",
      "Training model 1175: (12,66) ...\n",
      "0.10914457799981392\n",
      "Training model 1176: (12,67) ...\n",
      "0.11960940499966455\n",
      "Training model 1177: (12,68) ...\n",
      "0.11043078100010462\n",
      "Training model 1178: (12,69) ...\n",
      "0.11030123000000458\n",
      "Training model 1179: (12,70) ...\n",
      "0.14041597100003855\n",
      "Training model 1180: (12,71) ...\n",
      "0.12843816499980676\n",
      "Training model 1181: (12,72) ...\n",
      "0.1356773309998971\n",
      "Training model 1182: (12,73) ...\n",
      "0.15397710199977155\n",
      "Training model 1183: (12,74) ...\n",
      "0.1409534649997113\n",
      "Training model 1184: (12,75) ...\n",
      "0.12958061200015436\n",
      "Training model 1185: (12,76) ...\n",
      "0.1361565629999859\n",
      "Training model 1186: (12,77) ...\n",
      "0.13265395099961097\n",
      "Training model 1187: (12,78) ...\n",
      "0.13177718799988725\n",
      "Training model 1188: (12,79) ...\n",
      "0.143732301\n",
      "Training model 1189: (12,80) ...\n",
      "0.1382141799999772\n",
      "Training model 1190: (12,81) ...\n",
      "0.15766242200015768\n",
      "Training model 1191: (12,82) ...\n",
      "0.23377925000022515\n",
      "Training model 1192: (12,83) ...\n",
      "0.12496400300005917\n",
      "Training model 1193: (12,84) ...\n",
      "0.13821658999995634\n",
      "Training model 1194: (12,85) ...\n",
      "0.17914051699972333\n",
      "Training model 1195: (12,86) ...\n",
      "0.18714502500006347\n",
      "Training model 1196: (12,87) ...\n",
      "0.13284966399987752\n",
      "Training model 1197: (12,88) ...\n",
      "0.16982682999969256\n",
      "Training model 1198: (12,89) ...\n",
      "0.14311636000002181\n",
      "Training model 1199: (12,90) ...\n",
      "0.16022918499993466\n",
      "Training model 1200: (12,91) ...\n",
      "0.2529179960001784\n",
      "Training model 1201: (12,92) ...\n",
      "0.27945991600017805\n",
      "Training model 1202: (12,93) ...\n",
      "0.21407717400006732\n",
      "Training model 1203: (12,94) ...\n",
      "0.2516372899999624\n",
      "Training model 1204: (12,95) ...\n",
      "0.17540937900002973\n",
      "Training model 1205: (12,96) ...\n",
      "0.15036816700012423\n",
      "Training model 1206: (12,97) ...\n",
      "0.12438302700002168\n",
      "Training model 1207: (12,98) ...\n",
      "0.13243356399971162\n",
      "Training model 1208: (12,99) ...\n",
      "0.13238177099992754\n",
      "Training model 1209: (13,14) ...\n",
      "0.18115879500010124\n",
      "Training model 1210: (13,15) ...\n",
      "0.23530124300032185\n",
      "Training model 1211: (13,16) ...\n",
      "0.3033760319999601\n",
      "Training model 1212: (13,17) ...\n",
      "0.26720776399997703\n",
      "Training model 1213: (13,18) ...\n",
      "0.25577424699986295\n",
      "Training model 1214: (13,19) ...\n",
      "0.34009108600002946\n",
      "Training model 1215: (13,20) ...\n",
      "0.24483860899999854\n",
      "Training model 1216: (13,21) ...\n",
      "0.20132725199982815\n",
      "Training model 1217: (13,22) ...\n",
      "0.18241701600027227\n",
      "Training model 1218: (13,23) ...\n",
      "0.20637787100031346\n",
      "Training model 1219: (13,24) ...\n",
      "0.14358447199992952\n",
      "Training model 1220: (13,25) ...\n",
      "0.12365726400003041\n",
      "Training model 1221: (13,26) ...\n",
      "0.14445768699988548\n",
      "Training model 1222: (13,27) ...\n",
      "0.143078577000324\n",
      "Training model 1223: (13,28) ...\n",
      "0.13324866899984045\n",
      "Training model 1224: (13,29) ...\n",
      "0.15663662999986627\n",
      "Training model 1225: (13,30) ...\n",
      "0.1537225590000162\n",
      "Training model 1226: (13,31) ...\n",
      "0.12442610600010084\n",
      "Training model 1227: (13,32) ...\n",
      "0.14490008800021315\n",
      "Training model 1228: (13,33) ...\n",
      "0.13528820300007283\n",
      "Training model 1229: (13,34) ...\n",
      "0.14227505000008023\n",
      "Training model 1230: (13,35) ...\n",
      "0.13680389799992554\n",
      "Training model 1231: (13,36) ...\n",
      "0.15613388200017653\n",
      "Training model 1232: (13,37) ...\n",
      "0.13064239599998473\n",
      "Training model 1233: (13,38) ...\n",
      "0.13547030200015797\n",
      "Training model 1234: (13,39) ...\n",
      "0.16357447900008992\n",
      "Training model 1235: (13,40) ...\n",
      "0.14160299199966175\n",
      "Training model 1236: (13,41) ...\n",
      "0.1534876579999036\n",
      "Training model 1237: (13,42) ...\n",
      "0.1502571490000264\n",
      "Training model 1238: (13,43) ...\n",
      "0.14072802600003342\n",
      "Training model 1239: (13,44) ...\n",
      "0.14206115700017108\n",
      "Training model 1240: (13,45) ...\n",
      "0.13587128700009998\n",
      "Training model 1241: (13,46) ...\n",
      "0.1461609570001201\n",
      "Training model 1242: (13,47) ...\n",
      "0.13838382899984936\n",
      "Training model 1243: (13,48) ...\n",
      "0.13953027200022916\n",
      "Training model 1244: (13,49) ...\n",
      "0.15236619899997095\n",
      "Training model 1245: (13,50) ...\n",
      "0.15806132399984563\n",
      "Training model 1246: (13,51) ...\n",
      "0.1273998000001484\n",
      "Training model 1247: (13,52) ...\n",
      "0.1390553969999928\n",
      "Training model 1248: (13,53) ...\n",
      "0.15028707600004054\n",
      "Training model 1249: (13,54) ...\n",
      "0.15138614999978017\n",
      "Training model 1250: (13,55) ...\n",
      "0.1299223850000999\n",
      "Training model 1251: (13,56) ...\n",
      "0.1305668719996902\n",
      "Training model 1252: (13,57) ...\n",
      "0.13448828500031595\n",
      "Training model 1253: (13,58) ...\n",
      "0.1722514240000237\n",
      "Training model 1254: (13,59) ...\n",
      "0.13895448100038266\n",
      "Training model 1255: (13,60) ...\n",
      "0.16289858399977675\n",
      "Training model 1256: (13,61) ...\n",
      "0.13641923200020756\n",
      "Training model 1257: (13,62) ...\n",
      "0.15056317200014746\n",
      "Training model 1258: (13,63) ...\n",
      "0.14466180199997325\n",
      "Training model 1259: (13,64) ...\n",
      "0.13175570699968375\n",
      "Training model 1260: (13,65) ...\n",
      "0.13007820499979061\n",
      "Training model 1261: (13,66) ...\n",
      "0.13370761199985282\n",
      "Training model 1262: (13,67) ...\n",
      "0.14677549100042597\n",
      "Training model 1263: (13,68) ...\n",
      "0.13421931300035794\n",
      "Training model 1264: (13,69) ...\n",
      "0.11595772100008617\n",
      "Training model 1265: (13,70) ...\n",
      "0.15117881399964972\n",
      "Training model 1266: (13,71) ...\n",
      "0.13703765399986878\n",
      "Training model 1267: (13,72) ...\n",
      "0.13825313300003472\n",
      "Training model 1268: (13,73) ...\n",
      "0.1416850189998513\n",
      "Training model 1269: (13,74) ...\n",
      "0.13964030099987212\n",
      "Training model 1270: (13,75) ...\n",
      "0.1328161999999793\n",
      "Training model 1271: (13,76) ...\n",
      "0.14314747499975056\n",
      "Training model 1272: (13,77) ...\n",
      "0.14889229499976864\n",
      "Training model 1273: (13,78) ...\n",
      "0.13566513199975816\n",
      "Training model 1274: (13,79) ...\n",
      "0.1304309199999807\n",
      "Training model 1275: (13,80) ...\n",
      "0.16789138700005424\n",
      "Training model 1276: (13,81) ...\n",
      "0.18739025000013498\n",
      "Training model 1277: (13,82) ...\n",
      "0.21198628500042105\n",
      "Training model 1278: (13,83) ...\n",
      "0.14137494099986725\n",
      "Training model 1279: (13,84) ...\n",
      "0.1383955680003055\n",
      "Training model 1280: (13,85) ...\n",
      "0.23216216699984216\n",
      "Training model 1281: (13,86) ...\n",
      "0.1907563019999543\n",
      "Training model 1282: (13,87) ...\n",
      "0.14321788000006563\n",
      "Training model 1283: (13,88) ...\n",
      "0.13529803099982018\n",
      "Training model 1284: (13,89) ...\n",
      "0.15586401400014438\n",
      "Training model 1285: (13,90) ...\n",
      "0.12727393600016512\n",
      "Training model 1286: (13,91) ...\n",
      "0.22130649600012475\n",
      "Training model 1287: (13,92) ...\n",
      "0.18328754899994237\n",
      "Training model 1288: (13,93) ...\n",
      "0.1874346970002989\n",
      "Training model 1289: (13,94) ...\n",
      "0.21858135999991646\n",
      "Training model 1290: (13,95) ...\n",
      "0.17917297599979065\n",
      "Training model 1291: (13,96) ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.14713135900001362\n",
      "Training model 1292: (13,97) ...\n",
      "0.147761287999856\n",
      "Training model 1293: (13,98) ...\n",
      "0.15609635500004515\n",
      "Training model 1294: (13,99) ...\n",
      "0.1856759620000048\n",
      "Training model 1295: (14,15) ...\n",
      "0.1710553580001033\n",
      "Training model 1296: (14,16) ...\n",
      "0.18269245900000897\n",
      "Training model 1297: (14,17) ...\n",
      "0.32329544000003807\n",
      "Training model 1298: (14,18) ...\n",
      "0.193470914000045\n",
      "Training model 1299: (14,19) ...\n",
      "0.1620784960000492\n",
      "Training model 1300: (14,20) ...\n",
      "0.1381734060000781\n",
      "Training model 1301: (14,21) ...\n",
      "0.1568400119999751\n",
      "Training model 1302: (14,22) ...\n",
      "0.14168019199996706\n",
      "Training model 1303: (14,23) ...\n",
      "0.15741067099997963\n",
      "Training model 1304: (14,24) ...\n",
      "0.12510357900009694\n",
      "Training model 1305: (14,25) ...\n",
      "0.11915105300022333\n",
      "Training model 1306: (14,26) ...\n",
      "0.13122025900020162\n",
      "Training model 1307: (14,27) ...\n",
      "0.12670811799989679\n",
      "Training model 1308: (14,28) ...\n",
      "0.11956182399990212\n",
      "Training model 1309: (14,29) ...\n",
      "0.12498610400007237\n",
      "Training model 1310: (14,30) ...\n",
      "0.13309593500025585\n",
      "Training model 1311: (14,31) ...\n",
      "0.13832111099964095\n",
      "Training model 1312: (14,32) ...\n",
      "0.1243229789997713\n",
      "Training model 1313: (14,33) ...\n",
      "0.12473814699978902\n",
      "Training model 1314: (14,34) ...\n",
      "0.12383675000000949\n",
      "Training model 1315: (14,35) ...\n",
      "0.12161071399987122\n",
      "Training model 1316: (14,36) ...\n",
      "0.1427081649999309\n",
      "Training model 1317: (14,37) ...\n",
      "0.12074079200010601\n",
      "Training model 1318: (14,38) ...\n",
      "0.11858732300015618\n",
      "Training model 1319: (14,39) ...\n",
      "0.1526908519999779\n",
      "Training model 1320: (14,40) ...\n",
      "0.15984297200020592\n",
      "Training model 1321: (14,41) ...\n",
      "0.11868877200004135\n",
      "Training model 1322: (14,42) ...\n",
      "0.14968858299971544\n",
      "Training model 1323: (14,43) ...\n",
      "0.13372060299980149\n",
      "Training model 1324: (14,44) ...\n",
      "0.13308304600013798\n",
      "Training model 1325: (14,45) ...\n",
      "0.11230196299993622\n",
      "Training model 1326: (14,46) ...\n",
      "0.16994939799997155\n",
      "Training model 1327: (14,47) ...\n",
      "0.14988495599982343\n",
      "Training model 1328: (14,48) ...\n",
      "0.11180652900020505\n",
      "Training model 1329: (14,49) ...\n",
      "0.11768672400012292\n",
      "Training model 1330: (14,50) ...\n",
      "0.1358310820000952\n",
      "Training model 1331: (14,51) ...\n",
      "0.11427981199994974\n",
      "Training model 1332: (14,52) ...\n",
      "0.12603444500018668\n",
      "Training model 1333: (14,53) ...\n",
      "0.13835356099980345\n",
      "Training model 1334: (14,54) ...\n",
      "0.12347646899979736\n",
      "Training model 1335: (14,55) ...\n",
      "0.14488405100019008\n",
      "Training model 1336: (14,56) ...\n",
      "0.11889262600016082\n",
      "Training model 1337: (14,57) ...\n",
      "0.1250880480001797\n",
      "Training model 1338: (14,58) ...\n",
      "0.14996012100027656\n",
      "Training model 1339: (14,59) ...\n",
      "0.16384213599985742\n",
      "Training model 1340: (14,60) ...\n",
      "0.1336788250000609\n",
      "Training model 1341: (14,61) ...\n",
      "0.12035488100036673\n",
      "Training model 1342: (14,62) ...\n",
      "0.12523499000008087\n",
      "Training model 1343: (14,63) ...\n",
      "0.13135658100009096\n",
      "Training model 1344: (14,64) ...\n",
      "0.1610084049998477\n",
      "Training model 1345: (14,65) ...\n",
      "0.14610577499979627\n",
      "Training model 1346: (14,66) ...\n",
      "0.11376165399997262\n",
      "Training model 1347: (14,67) ...\n",
      "0.11858462299960593\n",
      "Training model 1348: (14,68) ...\n",
      "0.11570373300037318\n",
      "Training model 1349: (14,69) ...\n",
      "0.10575633500002368\n",
      "Training model 1350: (14,70) ...\n",
      "0.13610446700022294\n",
      "Training model 1351: (14,71) ...\n",
      "0.13104831400005423\n",
      "Training model 1352: (14,72) ...\n",
      "0.1617060290000154\n",
      "Training model 1353: (14,73) ...\n",
      "0.13151722200018412\n",
      "Training model 1354: (14,74) ...\n",
      "0.1465675760000522\n",
      "Training model 1355: (14,75) ...\n",
      "0.1230786830001307\n",
      "Training model 1356: (14,76) ...\n",
      "0.1247041899996475\n",
      "Training model 1357: (14,77) ...\n",
      "0.1308001190000141\n",
      "Training model 1358: (14,78) ...\n",
      "0.11767710300000545\n",
      "Training model 1359: (14,79) ...\n",
      "0.1246807729999091\n",
      "Training model 1360: (14,80) ...\n",
      "0.13271676000022126\n",
      "Training model 1361: (14,81) ...\n",
      "0.12325328499991883\n",
      "Training model 1362: (14,82) ...\n",
      "0.14661035299968717\n",
      "Training model 1363: (14,83) ...\n",
      "0.1176955480000288\n",
      "Training model 1364: (14,84) ...\n",
      "0.21653730600019117\n",
      "Training model 1365: (14,85) ...\n",
      "0.15847285400013789\n",
      "Training model 1366: (14,86) ...\n",
      "0.13848442900007285\n",
      "Training model 1367: (14,87) ...\n",
      "0.12990921300024638\n",
      "Training model 1368: (14,88) ...\n",
      "0.19436126199980208\n",
      "Training model 1369: (14,89) ...\n",
      "0.13662859999976718\n",
      "Training model 1370: (14,90) ...\n",
      "0.15690744199991968\n",
      "Training model 1371: (14,91) ...\n",
      "0.18542901899991193\n",
      "Training model 1372: (14,92) ...\n",
      "0.2286490030001005\n",
      "Training model 1373: (14,93) ...\n",
      "0.1884634959997129\n",
      "Training model 1374: (14,94) ...\n",
      "0.2349694790000285\n",
      "Training model 1375: (14,95) ...\n",
      "0.18136887500031662\n",
      "Training model 1376: (14,96) ...\n",
      "0.17189895999990767\n",
      "Training model 1377: (14,97) ...\n",
      "0.132577240000046\n",
      "Training model 1378: (14,98) ...\n",
      "0.11297709000018585\n",
      "Training model 1379: (14,99) ...\n",
      "0.1278845869996985\n",
      "Training model 1380: (15,16) ...\n",
      "0.24948810600017168\n",
      "Training model 1381: (15,17) ...\n",
      "0.18318702899978234\n",
      "Training model 1382: (15,18) ...\n",
      "0.1970592590000706\n",
      "Training model 1383: (15,19) ...\n",
      "0.1874113160001798\n",
      "Training model 1384: (15,20) ...\n",
      "0.15431046300000162\n",
      "Training model 1385: (15,21) ...\n",
      "0.22756761400023606\n",
      "Training model 1386: (15,22) ...\n",
      "0.211135970000214\n",
      "Training model 1387: (15,23) ...\n",
      "0.19232822100002522\n",
      "Training model 1388: (15,24) ...\n",
      "0.14210927299973264\n",
      "Training model 1389: (15,25) ...\n",
      "0.14062337099994693\n",
      "Training model 1390: (15,26) ...\n",
      "0.15644079100002273\n",
      "Training model 1391: (15,27) ...\n",
      "0.1698137029998179\n",
      "Training model 1392: (15,28) ...\n",
      "0.15062376600008065\n",
      "Training model 1393: (15,29) ...\n",
      "0.12706147199969564\n",
      "Training model 1394: (15,30) ...\n",
      "0.1459208020000915\n",
      "Training model 1395: (15,31) ...\n",
      "0.1249082249996718\n",
      "Training model 1396: (15,32) ...\n",
      "0.1496751919999042\n",
      "Training model 1397: (15,33) ...\n",
      "0.13195414699976027\n",
      "Training model 1398: (15,34) ...\n",
      "0.11906926299980114\n",
      "Training model 1399: (15,35) ...\n",
      "0.14375548099997104\n",
      "Training model 1400: (15,36) ...\n",
      "0.15353187600021556\n",
      "Training model 1401: (15,37) ...\n",
      "0.14330014500001198\n",
      "Training model 1402: (15,38) ...\n",
      "0.12349457700020139\n",
      "Training model 1403: (15,39) ...\n",
      "0.16944325699978435\n",
      "Training model 1404: (15,40) ...\n",
      "0.1376152899997578\n",
      "Training model 1405: (15,41) ...\n",
      "0.13866134299996702\n",
      "Training model 1406: (15,42) ...\n",
      "0.15559367500009103\n",
      "Training model 1407: (15,43) ...\n",
      "0.14512217499986946\n",
      "Training model 1408: (15,44) ...\n",
      "0.14676923000024544\n",
      "Training model 1409: (15,45) ...\n",
      "0.11804092200009109\n",
      "Training model 1410: (15,46) ...\n",
      "0.1516613009998764\n",
      "Training model 1411: (15,47) ...\n",
      "0.1466540569999779\n",
      "Training model 1412: (15,48) ...\n",
      "0.12200541499987594\n",
      "Training model 1413: (15,49) ...\n",
      "0.1405161290003889\n",
      "Training model 1414: (15,50) ...\n",
      "0.15445575400008238\n",
      "Training model 1415: (15,51) ...\n",
      "0.12759463100019275\n",
      "Training model 1416: (15,52) ...\n",
      "0.13443654899992907\n",
      "Training model 1417: (15,53) ...\n",
      "0.14312327400011782\n",
      "Training model 1418: (15,54) ...\n",
      "0.14691559099992446\n",
      "Training model 1419: (15,55) ...\n",
      "0.1293070669998997\n",
      "Training model 1420: (15,56) ...\n",
      "0.13403503800009275\n",
      "Training model 1421: (15,57) ...\n",
      "0.14043191299970204\n",
      "Training model 1422: (15,58) ...\n",
      "0.1649168330000066\n",
      "Training model 1423: (15,59) ...\n",
      "0.1388745399999607\n",
      "Training model 1424: (15,60) ...\n",
      "0.14525814199987508\n",
      "Training model 1425: (15,61) ...\n",
      "0.13426715999958105\n",
      "Training model 1426: (15,62) ...\n",
      "0.1414445729997169\n",
      "Training model 1427: (15,63) ...\n",
      "0.14025607099983972\n",
      "Training model 1428: (15,64) ...\n",
      "0.13719504999971832\n",
      "Training model 1429: (15,65) ...\n",
      "0.1204861510000228\n",
      "Training model 1430: (15,66) ...\n",
      "0.11743646000013541\n",
      "Training model 1431: (15,67) ...\n",
      "0.13409934200035423\n",
      "Training model 1432: (15,68) ...\n",
      "0.1161659790000158\n",
      "Training model 1433: (15,69) ...\n",
      "0.10743055600005391\n",
      "Training model 1434: (15,70) ...\n",
      "0.1504569740000079\n",
      "Training model 1435: (15,71) ...\n",
      "0.13952861899997515\n",
      "Training model 1436: (15,72) ...\n",
      "0.15381466799999544\n",
      "Training model 1437: (15,73) ...\n",
      "0.1470923329998186\n",
      "Training model 1438: (15,74) ...\n",
      "0.16033980000020165\n",
      "Training model 1439: (15,75) ...\n",
      "0.1362427219996789\n",
      "Training model 1440: (15,76) ...\n",
      "0.14950255000030666\n",
      "Training model 1441: (15,77) ...\n",
      "0.14350269600026877\n",
      "Training model 1442: (15,78) ...\n",
      "0.13007283100023415\n",
      "Training model 1443: (15,79) ...\n",
      "0.14581837100013217\n",
      "Training model 1444: (15,80) ...\n",
      "0.14283950899971387\n",
      "Training model 1445: (15,81) ...\n",
      "0.16438390400026037\n",
      "Training model 1446: (15,82) ...\n",
      "0.2478312809998897\n",
      "Training model 1447: (15,83) ...\n",
      "0.15791497700001855\n",
      "Training model 1448: (15,84) ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.14281691199994384\n",
      "Training model 1449: (15,85) ...\n",
      "0.20658285200033788\n",
      "Training model 1450: (15,86) ...\n",
      "0.19396097299977555\n",
      "Training model 1451: (15,87) ...\n",
      "0.12796123699990858\n",
      "Training model 1452: (15,88) ...\n",
      "0.1808744800000568\n",
      "Training model 1453: (15,89) ...\n",
      "0.15348287599999821\n",
      "Training model 1454: (15,90) ...\n",
      "0.1789997279997806\n",
      "Training model 1455: (15,91) ...\n",
      "0.3590237209996303\n",
      "Training model 1456: (15,92) ...\n",
      "0.2797264810001252\n",
      "Training model 1457: (15,93) ...\n",
      "0.23063138900033664\n",
      "Training model 1458: (15,94) ...\n",
      "0.22611268199989354\n",
      "Training model 1459: (15,95) ...\n",
      "0.21550041400041664\n",
      "Training model 1460: (15,96) ...\n",
      "0.18391447600015454\n",
      "Training model 1461: (15,97) ...\n",
      "0.14047271100025682\n",
      "Training model 1462: (15,98) ...\n",
      "0.1279765229996883\n",
      "Training model 1463: (15,99) ...\n",
      "0.14137370600019494\n",
      "Training model 1464: (16,17) ...\n",
      "0.2104894740000418\n",
      "Training model 1465: (16,18) ...\n",
      "0.22950079300017023\n",
      "Training model 1466: (16,19) ...\n",
      "0.30343305999986114\n",
      "Training model 1467: (16,20) ...\n",
      "0.1669492529999843\n",
      "Training model 1468: (16,21) ...\n",
      "0.2632902169998488\n",
      "Training model 1469: (16,22) ...\n",
      "0.180671134000022\n",
      "Training model 1470: (16,23) ...\n",
      "0.2122847699997692\n",
      "Training model 1471: (16,24) ...\n",
      "0.1224306730000535\n",
      "Training model 1472: (16,25) ...\n",
      "0.11076445499975307\n",
      "Training model 1473: (16,26) ...\n",
      "0.12719710200008194\n",
      "Training model 1474: (16,27) ...\n",
      "0.11282871100002012\n",
      "Training model 1475: (16,28) ...\n",
      "0.11100264300011986\n",
      "Training model 1476: (16,29) ...\n",
      "0.11915753299990683\n",
      "Training model 1477: (16,30) ...\n",
      "0.12245438400032072\n",
      "Training model 1478: (16,31) ...\n",
      "0.12433540400024867\n",
      "Training model 1479: (16,32) ...\n",
      "0.11892375900015395\n",
      "Training model 1480: (16,33) ...\n",
      "0.12422827699992922\n",
      "Training model 1481: (16,34) ...\n",
      "0.11129406500003824\n",
      "Training model 1482: (16,35) ...\n",
      "0.10955964000004315\n",
      "Training model 1483: (16,36) ...\n",
      "0.12764464200017756\n",
      "Training model 1484: (16,37) ...\n",
      "0.11297773300020708\n",
      "Training model 1485: (16,38) ...\n",
      "0.11708050900006128\n",
      "Training model 1486: (16,39) ...\n",
      "0.14339885799972762\n",
      "Training model 1487: (16,40) ...\n",
      "0.1494392230001722\n",
      "Training model 1488: (16,41) ...\n",
      "0.11860678099992583\n",
      "Training model 1489: (16,42) ...\n",
      "0.13827659500020673\n",
      "Training model 1490: (16,43) ...\n",
      "0.13384811500009164\n",
      "Training model 1491: (16,44) ...\n",
      "0.12409473500019885\n",
      "Training model 1492: (16,45) ...\n",
      "0.10801603699974294\n",
      "Training model 1493: (16,46) ...\n",
      "0.15208544100005383\n",
      "Training model 1494: (16,47) ...\n",
      "0.1369574499999544\n",
      "Training model 1495: (16,48) ...\n",
      "0.10891784299974461\n",
      "Training model 1496: (16,49) ...\n",
      "0.10816809400012062\n",
      "Training model 1497: (16,50) ...\n",
      "0.11920342700022957\n",
      "Training model 1498: (16,51) ...\n",
      "0.11434882300000027\n",
      "Training model 1499: (16,52) ...\n",
      "0.11864712899978258\n",
      "Training model 1500: (16,53) ...\n",
      "0.12737900899992383\n",
      "Training model 1501: (16,54) ...\n",
      "0.12274950799974249\n",
      "Training model 1502: (16,55) ...\n",
      "0.12851351500012242\n",
      "Training model 1503: (16,56) ...\n",
      "0.11477692600010414\n",
      "Training model 1504: (16,57) ...\n",
      "0.12134654000010414\n",
      "Training model 1505: (16,58) ...\n",
      "0.1381657990000349\n",
      "Training model 1506: (16,59) ...\n",
      "0.14755772099988462\n",
      "Training model 1507: (16,60) ...\n",
      "0.13681646699978955\n",
      "Training model 1508: (16,61) ...\n",
      "0.12103353700013031\n",
      "Training model 1509: (16,62) ...\n",
      "0.12193529599971953\n",
      "Training model 1510: (16,63) ...\n",
      "0.12350317900018126\n",
      "Training model 1511: (16,64) ...\n",
      "0.13421974199991382\n",
      "Training model 1512: (16,65) ...\n",
      "0.10892686499983029\n",
      "Training model 1513: (16,66) ...\n",
      "0.10643219599978693\n",
      "Training model 1514: (16,67) ...\n",
      "0.11737987400010752\n",
      "Training model 1515: (16,68) ...\n",
      "0.10683606399970813\n",
      "Training model 1516: (16,69) ...\n",
      "0.10213957299993126\n",
      "Training model 1517: (16,70) ...\n",
      "0.12933893599984003\n",
      "Training model 1518: (16,71) ...\n",
      "0.12322991199971511\n",
      "Training model 1519: (16,72) ...\n",
      "0.14786538199996357\n",
      "Training model 1520: (16,73) ...\n",
      "0.13753375199985385\n",
      "Training model 1521: (16,74) ...\n",
      "0.14087702400001945\n",
      "Training model 1522: (16,75) ...\n",
      "0.12321221299998797\n",
      "Training model 1523: (16,76) ...\n",
      "0.11717960100031632\n",
      "Training model 1524: (16,77) ...\n",
      "0.13289083000017854\n",
      "Training model 1525: (16,78) ...\n",
      "0.12262173200042525\n",
      "Training model 1526: (16,79) ...\n",
      "0.1245024640002157\n",
      "Training model 1527: (16,80) ...\n",
      "0.1494223869999587\n",
      "Training model 1528: (16,81) ...\n",
      "0.13014747999977772\n",
      "Training model 1529: (16,82) ...\n",
      "0.17008149100001901\n",
      "Training model 1530: (16,83) ...\n",
      "0.12073209799973483\n",
      "Training model 1531: (16,84) ...\n",
      "0.12622818799991364\n",
      "Training model 1532: (16,85) ...\n",
      "0.1701545350001652\n",
      "Training model 1533: (16,86) ...\n",
      "0.15572693900003287\n",
      "Training model 1534: (16,87) ...\n",
      "0.11762879699972473\n",
      "Training model 1535: (16,88) ...\n",
      "0.1591311330003009\n",
      "Training model 1536: (16,89) ...\n",
      "0.15267908499981786\n",
      "Training model 1537: (16,90) ...\n",
      "0.16310013900010745\n",
      "Training model 1538: (16,91) ...\n",
      "0.2498839400000179\n",
      "Training model 1539: (16,92) ...\n",
      "0.2965172619997247\n",
      "Training model 1540: (16,93) ...\n",
      "0.22731126500002574\n",
      "Training model 1541: (16,94) ...\n",
      "0.3292599960000189\n",
      "Training model 1542: (16,95) ...\n",
      "0.23197247600000992\n",
      "Training model 1543: (16,96) ...\n",
      "0.17443031900029382\n",
      "Training model 1544: (16,97) ...\n",
      "0.1340473740001471\n",
      "Training model 1545: (16,98) ...\n",
      "0.12873539900010655\n",
      "Training model 1546: (16,99) ...\n",
      "0.14639775100022234\n",
      "Training model 1547: (17,18) ...\n",
      "0.2771133229998668\n",
      "Training model 1548: (17,19) ...\n",
      "0.3056828769999811\n",
      "Training model 1549: (17,20) ...\n",
      "0.16271408500006146\n",
      "Training model 1550: (17,21) ...\n",
      "0.1831469419998939\n",
      "Training model 1551: (17,22) ...\n",
      "0.16388183299977754\n",
      "Training model 1552: (17,23) ...\n",
      "0.18712945699962802\n",
      "Training model 1553: (17,24) ...\n",
      "0.13323599500017735\n",
      "Training model 1554: (17,25) ...\n",
      "0.12539707199994155\n",
      "Training model 1555: (17,26) ...\n",
      "0.130139323000094\n",
      "Training model 1556: (17,27) ...\n",
      "0.11142020399984176\n",
      "Training model 1557: (17,28) ...\n",
      "0.12641299400002026\n",
      "Training model 1558: (17,29) ...\n",
      "0.12531904600018606\n",
      "Training model 1559: (17,30) ...\n",
      "0.12796445300000414\n",
      "Training model 1560: (17,31) ...\n",
      "0.1284860010000557\n",
      "Training model 1561: (17,32) ...\n",
      "0.12110976399981155\n",
      "Training model 1562: (17,33) ...\n",
      "0.12076894800020455\n",
      "Training model 1563: (17,34) ...\n",
      "0.13010031000021627\n",
      "Training model 1564: (17,35) ...\n",
      "0.12653551900029925\n",
      "Training model 1565: (17,36) ...\n",
      "0.1510080400003062\n",
      "Training model 1566: (17,37) ...\n",
      "0.11744935300021098\n",
      "Training model 1567: (17,38) ...\n",
      "0.1265230120002343\n",
      "Training model 1568: (17,39) ...\n",
      "0.14831254399996396\n",
      "Training model 1569: (17,40) ...\n",
      "0.14062720599986278\n",
      "Training model 1570: (17,41) ...\n",
      "0.1258390490002057\n",
      "Training model 1571: (17,42) ...\n",
      "0.14991285399992194\n",
      "Training model 1572: (17,43) ...\n",
      "0.1341356480002105\n",
      "Training model 1573: (17,44) ...\n",
      "0.12573291299986522\n",
      "Training model 1574: (17,45) ...\n",
      "0.11536628000021665\n",
      "Training model 1575: (17,46) ...\n",
      "0.1428308399999878\n",
      "Training model 1576: (17,47) ...\n",
      "0.13808642700041673\n",
      "Training model 1577: (17,48) ...\n",
      "0.12516386900006182\n",
      "Training model 1578: (17,49) ...\n",
      "0.1253230249999433\n",
      "Training model 1579: (17,50) ...\n",
      "0.15500566499986235\n",
      "Training model 1580: (17,51) ...\n",
      "0.13439996699980838\n",
      "Training model 1581: (17,52) ...\n",
      "0.1259267790001104\n",
      "Training model 1582: (17,53) ...\n",
      "0.13823014399986278\n",
      "Training model 1583: (17,54) ...\n",
      "0.12412216900020212\n",
      "Training model 1584: (17,55) ...\n",
      "0.12573782199979178\n",
      "Training model 1585: (17,56) ...\n",
      "0.12622983700020995\n",
      "Training model 1586: (17,57) ...\n",
      "0.13151115399978153\n",
      "Training model 1587: (17,58) ...\n",
      "0.15629120299990973\n",
      "Training model 1588: (17,59) ...\n",
      "0.1361034340002334\n",
      "Training model 1589: (17,60) ...\n",
      "0.12733400900015113\n",
      "Training model 1590: (17,61) ...\n",
      "0.13376400999959515\n",
      "Training model 1591: (17,62) ...\n",
      "0.12919573999988643\n",
      "Training model 1592: (17,63) ...\n",
      "0.13969687200005865\n",
      "Training model 1593: (17,64) ...\n",
      "0.13549617699982264\n",
      "Training model 1594: (17,65) ...\n",
      "0.12603806000015538\n",
      "Training model 1595: (17,66) ...\n",
      "0.11489820800034067\n",
      "Training model 1596: (17,67) ...\n",
      "0.12407439999969938\n",
      "Training model 1597: (17,68) ...\n",
      "0.11187895400007619\n",
      "Training model 1598: (17,69) ...\n",
      "0.11041753200015592\n",
      "Training model 1599: (17,70) ...\n",
      "0.12441548500009958\n",
      "Training model 1600: (17,71) ...\n",
      "0.1286955300001864\n",
      "Training model 1601: (17,72) ...\n",
      "0.15443562900009056\n",
      "Training model 1602: (17,73) ...\n",
      "0.1292494889999034\n",
      "Training model 1603: (17,74) ...\n",
      "0.14094407500033412\n",
      "Training model 1604: (17,75) ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1288894409999557\n",
      "Training model 1605: (17,76) ...\n",
      "0.1268047309999929\n",
      "Training model 1606: (17,77) ...\n",
      "0.12719997399972272\n",
      "Training model 1607: (17,78) ...\n",
      "0.11600557100018705\n",
      "Training model 1608: (17,79) ...\n",
      "0.13023913200004245\n",
      "Training model 1609: (17,80) ...\n",
      "0.15088987099989026\n",
      "Training model 1610: (17,81) ...\n",
      "0.158428486000048\n",
      "Training model 1611: (17,82) ...\n",
      "0.1563494920001176\n",
      "Training model 1612: (17,83) ...\n",
      "0.12119651600005454\n",
      "Training model 1613: (17,84) ...\n",
      "0.20539325499976258\n",
      "Training model 1614: (17,85) ...\n",
      "0.1988219330000902\n",
      "Training model 1615: (17,86) ...\n",
      "0.15144575600015742\n",
      "Training model 1616: (17,87) ...\n",
      "0.15789233699979377\n",
      "Training model 1617: (17,88) ...\n",
      "0.16642771200031348\n",
      "Training model 1618: (17,89) ...\n",
      "0.1573264360004032\n",
      "Training model 1619: (17,90) ...\n",
      "0.1350652619998982\n",
      "Training model 1620: (17,91) ...\n",
      "0.18317842000033124\n",
      "Training model 1621: (17,92) ...\n",
      "0.2001260590000129\n",
      "Training model 1622: (17,93) ...\n",
      "0.2135884519998399\n",
      "Training model 1623: (17,94) ...\n",
      "0.189245425000081\n",
      "Training model 1624: (17,95) ...\n",
      "0.15797978099999455\n",
      "Training model 1625: (17,96) ...\n",
      "0.15749633099994753\n",
      "Training model 1626: (17,97) ...\n",
      "0.16583289999971385\n",
      "Training model 1627: (17,98) ...\n",
      "0.13069838499995967\n",
      "Training model 1628: (17,99) ...\n",
      "0.1708554480001112\n",
      "Training model 1629: (18,19) ...\n",
      "0.3028394840002875\n",
      "Training model 1630: (18,20) ...\n",
      "0.22083631999976205\n",
      "Training model 1631: (18,21) ...\n",
      "0.25410420999969574\n",
      "Training model 1632: (18,22) ...\n",
      "0.24796897200030799\n",
      "Training model 1633: (18,23) ...\n",
      "0.32644645199980005\n",
      "Training model 1634: (18,24) ...\n",
      "0.13203460600016115\n",
      "Training model 1635: (18,25) ...\n",
      "0.12400095299972236\n",
      "Training model 1636: (18,26) ...\n",
      "0.12576086699982625\n",
      "Training model 1637: (18,27) ...\n",
      "0.11132446700003129\n",
      "Training model 1638: (18,28) ...\n",
      "0.13099026800000502\n",
      "Training model 1639: (18,29) ...\n",
      "0.12100146200009476\n",
      "Training model 1640: (18,30) ...\n",
      "0.1220504460002303\n",
      "Training model 1641: (18,31) ...\n",
      "0.11553363499979241\n",
      "Training model 1642: (18,32) ...\n",
      "0.1166112770001746\n",
      "Training model 1643: (18,33) ...\n",
      "0.12785717800034035\n",
      "Training model 1644: (18,34) ...\n",
      "0.13670580999996673\n",
      "Training model 1645: (18,35) ...\n",
      "0.11935531800008903\n",
      "Training model 1646: (18,36) ...\n",
      "0.1435500669999783\n",
      "Training model 1647: (18,37) ...\n",
      "0.11863013200036221\n",
      "Training model 1648: (18,38) ...\n",
      "0.12383406499975536\n",
      "Training model 1649: (18,39) ...\n",
      "0.15323327800024344\n",
      "Training model 1650: (18,40) ...\n",
      "0.1277822849997392\n",
      "Training model 1651: (18,41) ...\n",
      "0.12402453799995783\n",
      "Training model 1652: (18,42) ...\n",
      "0.132890008999766\n",
      "Training model 1653: (18,43) ...\n",
      "0.12653754899974956\n",
      "Training model 1654: (18,44) ...\n",
      "0.11972496099997443\n",
      "Training model 1655: (18,45) ...\n",
      "0.11586115399995833\n",
      "Training model 1656: (18,46) ...\n",
      "0.13370462099965152\n",
      "Training model 1657: (18,47) ...\n",
      "0.1268005169999924\n",
      "Training model 1658: (18,48) ...\n",
      "0.12281392500017319\n",
      "Training model 1659: (18,49) ...\n",
      "0.12244341900031941\n",
      "Training model 1660: (18,50) ...\n",
      "0.1395152350000899\n",
      "Training model 1661: (18,51) ...\n",
      "0.1287770199996885\n",
      "Training model 1662: (18,52) ...\n",
      "0.12333451299991793\n",
      "Training model 1663: (18,53) ...\n",
      "0.14868806200001927\n",
      "Training model 1664: (18,54) ...\n",
      "0.1300490640001044\n",
      "Training model 1665: (18,55) ...\n",
      "0.11932372499995836\n",
      "Training model 1666: (18,56) ...\n",
      "0.12842662299999574\n",
      "Training model 1667: (18,57) ...\n",
      "0.12000344700027199\n",
      "Training model 1668: (18,58) ...\n",
      "0.14740878900011012\n",
      "Training model 1669: (18,59) ...\n",
      "0.1280067009997765\n",
      "Training model 1670: (18,60) ...\n",
      "0.13707291399987298\n",
      "Training model 1671: (18,61) ...\n",
      "0.13056379900035608\n",
      "Training model 1672: (18,62) ...\n",
      "0.14085272000011173\n",
      "Training model 1673: (18,63) ...\n",
      "0.1418570539999564\n",
      "Training model 1674: (18,64) ...\n",
      "0.1324672260002444\n",
      "Training model 1675: (18,65) ...\n",
      "0.12813645400001406\n",
      "Training model 1676: (18,66) ...\n",
      "0.1131425210000998\n",
      "Training model 1677: (18,67) ...\n",
      "0.1226075879999371\n",
      "Training model 1678: (18,68) ...\n",
      "0.11361187900001823\n",
      "Training model 1679: (18,69) ...\n",
      "0.10521100800042404\n",
      "Training model 1680: (18,70) ...\n",
      "0.12640129000010347\n",
      "Training model 1681: (18,71) ...\n",
      "0.12914231600007042\n",
      "Training model 1682: (18,72) ...\n",
      "0.134690961999695\n",
      "Training model 1683: (18,73) ...\n",
      "0.1259438259999115\n",
      "Training model 1684: (18,74) ...\n",
      "0.13359687100000883\n",
      "Training model 1685: (18,75) ...\n",
      "0.13087220899979002\n",
      "Training model 1686: (18,76) ...\n",
      "0.12896299899966834\n",
      "Training model 1687: (18,77) ...\n",
      "0.12875114600001325\n",
      "Training model 1688: (18,78) ...\n",
      "0.12517539500004204\n",
      "Training model 1689: (18,79) ...\n",
      "0.12621103900028174\n",
      "Training model 1690: (18,80) ...\n",
      "0.20644390999996176\n",
      "Training model 1691: (18,81) ...\n",
      "0.1400146049995783\n",
      "Training model 1692: (18,82) ...\n",
      "0.18927883400010614\n",
      "Training model 1693: (18,83) ...\n",
      "0.1234006730001056\n",
      "Training model 1694: (18,84) ...\n",
      "0.15642553999987285\n",
      "Training model 1695: (18,85) ...\n",
      "0.20758270799979073\n",
      "Training model 1696: (18,86) ...\n",
      "0.16266803999997137\n",
      "Training model 1697: (18,87) ...\n",
      "0.12795787700042638\n",
      "Training model 1698: (18,88) ...\n",
      "0.14707766499986974\n",
      "Training model 1699: (18,89) ...\n",
      "0.17006718899983753\n",
      "Training model 1700: (18,90) ...\n",
      "0.1260302440000487\n",
      "Training model 1701: (18,91) ...\n",
      "0.1876862579997578\n",
      "Training model 1702: (18,92) ...\n",
      "0.17710931500005245\n",
      "Training model 1703: (18,93) ...\n",
      "0.2863227670000015\n",
      "Training model 1704: (18,94) ...\n",
      "0.18828277200009325\n",
      "Training model 1705: (18,95) ...\n",
      "0.15036455400013438\n",
      "Training model 1706: (18,96) ...\n",
      "0.19042460099990421\n",
      "Training model 1707: (18,97) ...\n",
      "0.18438935199992557\n",
      "Training model 1708: (18,98) ...\n",
      "0.16507262499999342\n",
      "Training model 1709: (18,99) ...\n",
      "0.2309983350000948\n",
      "Training model 1710: (19,20) ...\n",
      "0.16561390000015308\n",
      "Training model 1711: (19,21) ...\n",
      "0.1938353199998346\n",
      "Training model 1712: (19,22) ...\n",
      "0.17582717300001605\n",
      "Training model 1713: (19,23) ...\n",
      "0.19111740900007135\n",
      "Training model 1714: (19,24) ...\n",
      "0.1242085130002124\n",
      "Training model 1715: (19,25) ...\n",
      "0.11101500700033284\n",
      "Training model 1716: (19,26) ...\n",
      "0.12895958499984772\n",
      "Training model 1717: (19,27) ...\n",
      "0.11140332700006184\n",
      "Training model 1718: (19,28) ...\n",
      "0.11779718599973421\n",
      "Training model 1719: (19,29) ...\n",
      "0.13002057200037598\n",
      "Training model 1720: (19,30) ...\n",
      "0.12104347100012092\n",
      "Training model 1721: (19,31) ...\n",
      "0.12238724400003775\n",
      "Training model 1722: (19,32) ...\n",
      "0.12269415699984165\n",
      "Training model 1723: (19,33) ...\n",
      "0.11792907599965474\n",
      "Training model 1724: (19,34) ...\n",
      "0.13176677499996003\n",
      "Training model 1725: (19,35) ...\n",
      "0.11741561099961473\n",
      "Training model 1726: (19,36) ...\n",
      "0.14283691199989335\n",
      "Training model 1727: (19,37) ...\n",
      "0.1110976350000783\n",
      "Training model 1728: (19,38) ...\n",
      "0.12169445000017731\n",
      "Training model 1729: (19,39) ...\n",
      "0.13757179899994298\n",
      "Training model 1730: (19,40) ...\n",
      "0.1355614870003592\n",
      "Training model 1731: (19,41) ...\n",
      "0.12605439000026308\n",
      "Training model 1732: (19,42) ...\n",
      "0.1346663350000199\n",
      "Training model 1733: (19,43) ...\n",
      "0.12888084299993352\n",
      "Training model 1734: (19,44) ...\n",
      "0.12738310300028388\n",
      "Training model 1735: (19,45) ...\n",
      "0.10918493600001966\n",
      "Training model 1736: (19,46) ...\n",
      "0.13104706199965221\n",
      "Training model 1737: (19,47) ...\n",
      "0.1372731470000872\n",
      "Training model 1738: (19,48) ...\n",
      "0.1105107569997017\n",
      "Training model 1739: (19,49) ...\n",
      "0.11717950999991444\n",
      "Training model 1740: (19,50) ...\n",
      "0.12260385999979917\n",
      "Training model 1741: (19,51) ...\n",
      "0.11769834300002913\n",
      "Training model 1742: (19,52) ...\n",
      "0.12781982100023015\n",
      "Training model 1743: (19,53) ...\n",
      "0.1511543429996891\n",
      "Training model 1744: (19,54) ...\n",
      "0.12380811200000608\n",
      "Training model 1745: (19,55) ...\n",
      "0.11931623300006322\n",
      "Training model 1746: (19,56) ...\n",
      "0.12044461200002843\n",
      "Training model 1747: (19,57) ...\n",
      "0.1315831580000122\n",
      "Training model 1748: (19,58) ...\n",
      "0.13597396000022854\n",
      "Training model 1749: (19,59) ...\n",
      "0.12723758399988583\n",
      "Training model 1750: (19,60) ...\n",
      "0.13234416500017687\n",
      "Training model 1751: (19,61) ...\n",
      "0.12719334899975365\n",
      "Training model 1752: (19,62) ...\n",
      "0.1347341629998482\n",
      "Training model 1753: (19,63) ...\n",
      "0.13326383499997974\n",
      "Training model 1754: (19,64) ...\n",
      "0.12563265500011767\n",
      "Training model 1755: (19,65) ...\n",
      "0.11665199500021117\n",
      "Training model 1756: (19,66) ...\n",
      "0.11406783899974471\n",
      "Training model 1757: (19,67) ...\n",
      "0.11905690799994773\n",
      "Training model 1758: (19,68) ...\n",
      "0.11280507499986925\n",
      "Training model 1759: (19,69) ...\n",
      "0.10921296500009703\n",
      "Training model 1760: (19,70) ...\n",
      "0.13095519400030753\n",
      "Training model 1761: (19,71) ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.13156002599998828\n",
      "Training model 1762: (19,72) ...\n",
      "0.140653458000088\n",
      "Training model 1763: (19,73) ...\n",
      "0.12745494199998575\n",
      "Training model 1764: (19,74) ...\n",
      "0.1329281989997071\n",
      "Training model 1765: (19,75) ...\n",
      "0.12793682300025466\n",
      "Training model 1766: (19,76) ...\n",
      "0.1308692899997368\n",
      "Training model 1767: (19,77) ...\n",
      "0.13403382300020894\n",
      "Training model 1768: (19,78) ...\n",
      "0.1323117730003105\n",
      "Training model 1769: (19,79) ...\n",
      "0.13013667299992449\n",
      "Training model 1770: (19,80) ...\n",
      "0.13410205199988923\n",
      "Training model 1771: (19,81) ...\n",
      "0.14884114699998463\n",
      "Training model 1772: (19,82) ...\n",
      "0.15148333200022535\n",
      "Training model 1773: (19,83) ...\n",
      "0.11220966599967142\n",
      "Training model 1774: (19,84) ...\n",
      "0.13733764700009488\n",
      "Training model 1775: (19,85) ...\n",
      "0.1784159990002081\n",
      "Training model 1776: (19,86) ...\n",
      "0.13372707200005607\n",
      "Training model 1777: (19,87) ...\n",
      "0.1338736349998726\n",
      "Training model 1778: (19,88) ...\n",
      "0.14228810699978567\n",
      "Training model 1779: (19,89) ...\n",
      "0.15388792499970805\n",
      "Training model 1780: (19,90) ...\n",
      "0.11711028199988505\n",
      "Training model 1781: (19,91) ...\n",
      "0.17215149799994833\n",
      "Training model 1782: (19,92) ...\n",
      "0.17850990600027217\n",
      "Training model 1783: (19,93) ...\n",
      "0.2066670660001364\n",
      "Training model 1784: (19,94) ...\n",
      "0.21034843999996156\n",
      "Training model 1785: (19,95) ...\n",
      "0.16197807399976227\n",
      "Training model 1786: (19,96) ...\n",
      "0.14579230699973778\n",
      "Training model 1787: (19,97) ...\n",
      "0.1370474700001978\n",
      "Training model 1788: (19,98) ...\n",
      "0.12534435199995642\n",
      "Training model 1789: (19,99) ...\n",
      "0.16848852600014652\n",
      "Training model 1790: (20,21) ...\n",
      "0.16501555600007123\n",
      "Training model 1791: (20,22) ...\n",
      "0.1870616829996834\n",
      "Training model 1792: (20,23) ...\n",
      "0.2025451049998992\n",
      "Training model 1793: (20,24) ...\n",
      "0.12235184900009699\n",
      "Training model 1794: (20,25) ...\n",
      "0.1119880840001315\n",
      "Training model 1795: (20,26) ...\n",
      "0.1299107559998447\n",
      "Training model 1796: (20,27) ...\n",
      "0.11024922399974457\n",
      "Training model 1797: (20,28) ...\n",
      "0.12190531099986401\n",
      "Training model 1798: (20,29) ...\n",
      "0.12417565400028252\n",
      "Training model 1799: (20,30) ...\n",
      "0.13802838600031464\n",
      "Training model 1800: (20,31) ...\n",
      "0.11730532599995058\n",
      "Training model 1801: (20,32) ...\n",
      "0.1281804430000193\n",
      "Training model 1802: (20,33) ...\n",
      "0.14050673500014454\n",
      "Training model 1803: (20,34) ...\n",
      "0.16595032199984416\n",
      "Training model 1804: (20,35) ...\n",
      "0.13486751199980063\n",
      "Training model 1805: (20,36) ...\n",
      "0.18603109599962409\n",
      "Training model 1806: (20,37) ...\n",
      "0.11154574600004707\n",
      "Training model 1807: (20,38) ...\n",
      "0.122976681000182\n",
      "Training model 1808: (20,39) ...\n",
      "0.16427894899970852\n",
      "Training model 1809: (20,40) ...\n",
      "0.12374125399992408\n",
      "Training model 1810: (20,41) ...\n",
      "0.13554038200027207\n",
      "Training model 1811: (20,42) ...\n",
      "0.15054761300007158\n",
      "Training model 1812: (20,43) ...\n",
      "0.12539178399993034\n",
      "Training model 1813: (20,44) ...\n",
      "0.1322146590000557\n",
      "Training model 1814: (20,45) ...\n",
      "0.1251346329995613\n",
      "Training model 1815: (20,46) ...\n",
      "0.12363869999990129\n",
      "Training model 1816: (20,47) ...\n",
      "0.12668419800002084\n",
      "Training model 1817: (20,48) ...\n",
      "0.14135090699983266\n",
      "Training model 1818: (20,49) ...\n",
      "0.19429708200004825\n",
      "Training model 1819: (20,50) ...\n",
      "0.22252686999991056\n",
      "Training model 1820: (20,51) ...\n",
      "0.11278519500001494\n",
      "Training model 1821: (20,52) ...\n",
      "0.13009863399975075\n",
      "Training model 1822: (20,53) ...\n",
      "0.1322045319998324\n",
      "Training model 1823: (20,54) ...\n",
      "0.13485289799973543\n",
      "Training model 1824: (20,55) ...\n",
      "0.11282960699963951\n",
      "Training model 1825: (20,56) ...\n",
      "0.11647863500002131\n",
      "Training model 1826: (20,57) ...\n",
      "0.12263545200039516\n",
      "Training model 1827: (20,58) ...\n",
      "0.21783354599983795\n",
      "Training model 1828: (20,59) ...\n",
      "0.11755051599993749\n",
      "Training model 1829: (20,60) ...\n",
      "0.13332877999982884\n",
      "Training model 1830: (20,61) ...\n",
      "0.12681153199991968\n",
      "Training model 1831: (20,62) ...\n",
      "0.13721236200035491\n",
      "Training model 1832: (20,63) ...\n",
      "0.1399090739996609\n",
      "Training model 1833: (20,64) ...\n",
      "0.12044736799998645\n",
      "Training model 1834: (20,65) ...\n",
      "0.1297743850000188\n",
      "Training model 1835: (20,66) ...\n",
      "0.12824642600025982\n",
      "Training model 1836: (20,67) ...\n",
      "0.13427716200021678\n",
      "Training model 1837: (20,68) ...\n",
      "0.13002499099957276\n",
      "Training model 1838: (20,69) ...\n",
      "0.11431082199987941\n",
      "Training model 1839: (20,70) ...\n",
      "0.11898854399987613\n",
      "Training model 1840: (20,71) ...\n",
      "0.12407836200009115\n",
      "Training model 1841: (20,72) ...\n",
      "0.12246295199975066\n",
      "Training model 1842: (20,73) ...\n",
      "0.11815725799988286\n",
      "Training model 1843: (20,74) ...\n",
      "0.11558325299984062\n",
      "Training model 1844: (20,75) ...\n",
      "0.11043818799998917\n",
      "Training model 1845: (20,76) ...\n",
      "0.12216784600013852\n",
      "Training model 1846: (20,77) ...\n",
      "0.1260789569996632\n",
      "Training model 1847: (20,78) ...\n",
      "0.12193413400018471\n",
      "Training model 1848: (20,79) ...\n",
      "0.1253357400000823\n",
      "Training model 1849: (20,80) ...\n",
      "0.18612347399994178\n",
      "Training model 1850: (20,81) ...\n",
      "0.19775024000000485\n",
      "Training model 1851: (20,82) ...\n",
      "0.17653285500000493\n",
      "Training model 1852: (20,83) ...\n",
      "0.12773927999978696\n",
      "Training model 1853: (20,84) ...\n",
      "0.13075395299983938\n",
      "Training model 1854: (20,85) ...\n",
      "0.20887295900001845\n",
      "Training model 1855: (20,86) ...\n",
      "0.17654230200014354\n",
      "Training model 1856: (20,87) ...\n",
      "0.12850309500026924\n",
      "Training model 1857: (20,88) ...\n",
      "0.11622103700028674\n",
      "Training model 1858: (20,89) ...\n",
      "0.12771966799982692\n",
      "Training model 1859: (20,90) ...\n",
      "0.11218068400012271\n",
      "Training model 1860: (20,91) ...\n",
      "0.16380158899983144\n",
      "Training model 1861: (20,92) ...\n",
      "0.1319101280000723\n",
      "Training model 1862: (20,93) ...\n",
      "0.14842636699995637\n",
      "Training model 1863: (20,94) ...\n",
      "0.1523454800003492\n",
      "Training model 1864: (20,95) ...\n",
      "0.12220983499992144\n",
      "Training model 1865: (20,96) ...\n",
      "0.12770402200021636\n",
      "Training model 1866: (20,97) ...\n",
      "0.20785053000008702\n",
      "Training model 1867: (20,98) ...\n",
      "0.24574987500000134\n",
      "Training model 1868: (20,99) ...\n",
      "0.22793809399991005\n",
      "Training model 1869: (21,22) ...\n",
      "0.6783746740002243\n",
      "Training model 1870: (21,23) ...\n",
      "0.6991657079997822\n",
      "Training model 1871: (21,24) ...\n",
      "0.1701625129999229\n",
      "Training model 1872: (21,25) ...\n",
      "0.11017995899965172\n",
      "Training model 1873: (21,26) ...\n",
      "0.134157119000065\n",
      "Training model 1874: (21,27) ...\n",
      "0.1105114360002517\n",
      "Training model 1875: (21,28) ...\n",
      "0.11337134299992613\n",
      "Training model 1876: (21,29) ...\n",
      "0.11095893299989257\n",
      "Training model 1877: (21,30) ...\n",
      "0.12350555800003349\n",
      "Training model 1878: (21,31) ...\n",
      "0.12126029000000926\n",
      "Training model 1879: (21,32) ...\n",
      "0.11690998199992464\n",
      "Training model 1880: (21,33) ...\n",
      "0.1326807719997305\n",
      "Training model 1881: (21,34) ...\n",
      "0.12712068099972385\n",
      "Training model 1882: (21,35) ...\n",
      "0.11552288199982286\n",
      "Training model 1883: (21,36) ...\n",
      "0.14044304300023214\n",
      "Training model 1884: (21,37) ...\n",
      "0.11064333700005591\n",
      "Training model 1885: (21,38) ...\n",
      "0.1253825409999081\n",
      "Training model 1886: (21,39) ...\n",
      "0.14953679699965505\n",
      "Training model 1887: (21,40) ...\n",
      "0.12413948199991864\n",
      "Training model 1888: (21,41) ...\n",
      "0.12264752300006876\n",
      "Training model 1889: (21,42) ...\n",
      "0.1297953769999367\n",
      "Training model 1890: (21,43) ...\n",
      "0.1496219820000988\n",
      "Training model 1891: (21,44) ...\n",
      "0.12242390700021133\n",
      "Training model 1892: (21,45) ...\n",
      "0.1103294829999868\n",
      "Training model 1893: (21,46) ...\n",
      "0.12140997899996364\n",
      "Training model 1894: (21,47) ...\n",
      "0.12362469399977272\n",
      "Training model 1895: (21,48) ...\n",
      "0.1198119420000694\n",
      "Training model 1896: (21,49) ...\n",
      "0.16154701100003876\n",
      "Training model 1897: (21,50) ...\n",
      "0.14075620100038577\n",
      "Training model 1898: (21,51) ...\n",
      "0.1303003829998488\n",
      "Training model 1899: (21,52) ...\n",
      "0.11398025200014672\n",
      "Training model 1900: (21,53) ...\n",
      "0.12590009299992744\n",
      "Training model 1901: (21,54) ...\n",
      "0.12283301300021776\n",
      "Training model 1902: (21,55) ...\n",
      "0.11175661900006162\n",
      "Training model 1903: (21,56) ...\n",
      "0.1147313229998872\n",
      "Training model 1904: (21,57) ...\n",
      "0.11863552300019364\n",
      "Training model 1905: (21,58) ...\n",
      "0.1522384670001884\n",
      "Training model 1906: (21,59) ...\n",
      "0.11981140799980494\n",
      "Training model 1907: (21,60) ...\n",
      "0.12938519899989842\n",
      "Training model 1908: (21,61) ...\n",
      "0.12858853799980352\n",
      "Training model 1909: (21,62) ...\n",
      "0.13085447000003114\n",
      "Training model 1910: (21,63) ...\n",
      "0.14520022600027005\n",
      "Training model 1911: (21,64) ...\n",
      "0.1254567539999698\n",
      "Training model 1912: (21,65) ...\n",
      "0.12275438500000746\n",
      "Training model 1913: (21,66) ...\n",
      "0.1128722469998138\n",
      "Training model 1914: (21,67) ...\n",
      "0.11615788300014174\n",
      "Training model 1915: (21,68) ...\n",
      "0.1066587499999514\n",
      "Training model 1916: (21,69) ...\n",
      "0.11606311800005642\n",
      "Training model 1917: (21,70) ...\n",
      "0.13241552499994214\n",
      "Training model 1918: (21,71) ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.14670724899997367\n",
      "Training model 1919: (21,72) ...\n",
      "0.12687222799968367\n",
      "Training model 1920: (21,73) ...\n",
      "0.1346974709999813\n",
      "Training model 1921: (21,74) ...\n",
      "0.14334254499999588\n",
      "Training model 1922: (21,75) ...\n",
      "0.12758701700022357\n",
      "Training model 1923: (21,76) ...\n",
      "0.12817700599998716\n",
      "Training model 1924: (21,77) ...\n",
      "0.1359149919999254\n",
      "Training model 1925: (21,78) ...\n",
      "0.14543032199981099\n",
      "Training model 1926: (21,79) ...\n",
      "0.12439013300036095\n",
      "Training model 1927: (21,80) ...\n",
      "0.17148349999979473\n",
      "Training model 1928: (21,81) ...\n",
      "0.16536011400012285\n",
      "Training model 1929: (21,82) ...\n",
      "0.2405163220000759\n",
      "Training model 1930: (21,83) ...\n",
      "0.15588076899985026\n",
      "Training model 1931: (21,84) ...\n",
      "0.13386045899960664\n",
      "Training model 1932: (21,85) ...\n",
      "0.2052901369997926\n",
      "Training model 1933: (21,86) ...\n",
      "0.1775291539997852\n",
      "Training model 1934: (21,87) ...\n",
      "0.1272296029997051\n",
      "Training model 1935: (21,88) ...\n",
      "0.15414875899978142\n",
      "Training model 1936: (21,89) ...\n",
      "0.20111088299972835\n",
      "Training model 1937: (21,90) ...\n",
      "0.1241834249999556\n",
      "Training model 1938: (21,91) ...\n",
      "0.23565429900008894\n",
      "Training model 1939: (21,92) ...\n",
      "0.27584580000029746\n",
      "Training model 1940: (21,93) ...\n",
      "0.2699459260002186\n",
      "Training model 1941: (21,94) ...\n",
      "0.27923973399992974\n",
      "Training model 1942: (21,95) ...\n",
      "0.15643134600031772\n",
      "Training model 1943: (21,96) ...\n",
      "0.15582568600029845\n",
      "Training model 1944: (21,97) ...\n",
      "0.1329296100002466\n",
      "Training model 1945: (21,98) ...\n",
      "0.15739911900027437\n",
      "Training model 1946: (21,99) ...\n",
      "0.2449741460000041\n",
      "Training model 1947: (22,23) ...\n",
      "0.659036118000131\n",
      "Training model 1948: (22,24) ...\n",
      "0.17739475200005472\n",
      "Training model 1949: (22,25) ...\n",
      "0.11168548999967243\n",
      "Training model 1950: (22,26) ...\n",
      "0.13895819700019274\n",
      "Training model 1951: (22,27) ...\n",
      "0.11019181100027708\n",
      "Training model 1952: (22,28) ...\n",
      "0.1240999209999245\n",
      "Training model 1953: (22,29) ...\n",
      "0.1219278469998244\n",
      "Training model 1954: (22,30) ...\n",
      "0.12642329799973595\n",
      "Training model 1955: (22,31) ...\n",
      "0.11084885799982658\n",
      "Training model 1956: (22,32) ...\n",
      "0.11638283299998875\n",
      "Training model 1957: (22,33) ...\n",
      "0.1364558059999581\n",
      "Training model 1958: (22,34) ...\n",
      "0.13326440499986347\n",
      "Training model 1959: (22,35) ...\n",
      "0.12452936399995451\n",
      "Training model 1960: (22,36) ...\n",
      "0.14353282399997624\n",
      "Training model 1961: (22,37) ...\n",
      "0.10992474400018182\n",
      "Training model 1962: (22,38) ...\n",
      "0.1149507709997124\n",
      "Training model 1963: (22,39) ...\n",
      "0.15300612499959243\n",
      "Training model 1964: (22,40) ...\n",
      "0.11408342799995808\n",
      "Training model 1965: (22,41) ...\n",
      "0.11845577399981266\n",
      "Training model 1966: (22,42) ...\n",
      "0.14757566699972813\n",
      "Training model 1967: (22,43) ...\n",
      "0.13678782999977557\n",
      "Training model 1968: (22,44) ...\n",
      "0.11477131099991311\n",
      "Training model 1969: (22,45) ...\n",
      "0.12039999199987506\n",
      "Training model 1970: (22,46) ...\n",
      "0.11769624699991255\n",
      "Training model 1971: (22,47) ...\n",
      "0.1252556250001362\n",
      "Training model 1972: (22,48) ...\n",
      "0.11905778499976805\n",
      "Training model 1973: (22,49) ...\n",
      "0.17019878599967342\n",
      "Training model 1974: (22,50) ...\n",
      "0.15613143899963688\n",
      "Training model 1975: (22,51) ...\n",
      "0.1305319220000456\n",
      "Training model 1976: (22,52) ...\n",
      "0.12236996599995109\n",
      "Training model 1977: (22,53) ...\n",
      "0.13041377799982\n",
      "Training model 1978: (22,54) ...\n",
      "0.12476091400003497\n",
      "Training model 1979: (22,55) ...\n",
      "0.11250924700016185\n",
      "Training model 1980: (22,56) ...\n",
      "0.12523006299988992\n",
      "Training model 1981: (22,57) ...\n",
      "0.10887615899991943\n",
      "Training model 1982: (22,58) ...\n",
      "0.16283554299980096\n",
      "Training model 1983: (22,59) ...\n",
      "0.11469836900005248\n",
      "Training model 1984: (22,60) ...\n",
      "0.12561577599990414\n",
      "Training model 1985: (22,61) ...\n",
      "0.11920813999995516\n",
      "Training model 1986: (22,62) ...\n",
      "0.12780936799981646\n",
      "Training model 1987: (22,63) ...\n",
      "0.13026895500024693\n",
      "Training model 1988: (22,64) ...\n",
      "0.12153193499989356\n",
      "Training model 1989: (22,65) ...\n",
      "0.12902725300000384\n",
      "Training model 1990: (22,66) ...\n",
      "0.11794083500035413\n",
      "Training model 1991: (22,67) ...\n",
      "0.12899217400035923\n",
      "Training model 1992: (22,68) ...\n",
      "0.1091911359999358\n",
      "Training model 1993: (22,69) ...\n",
      "0.10945825399994646\n",
      "Training model 1994: (22,70) ...\n",
      "0.11172482399979344\n",
      "Training model 1995: (22,71) ...\n",
      "0.13237238200008505\n",
      "Training model 1996: (22,72) ...\n",
      "0.1208501559999604\n",
      "Training model 1997: (22,73) ...\n",
      "0.13000875199986694\n",
      "Training model 1998: (22,74) ...\n",
      "0.1301913219999733\n",
      "Training model 1999: (22,75) ...\n",
      "0.12906619499972294\n",
      "Training model 2000: (22,76) ...\n",
      "0.1319446610000341\n",
      "Training model 2001: (22,77) ...\n",
      "0.12788688699993145\n",
      "Training model 2002: (22,78) ...\n",
      "0.13227086799997778\n",
      "Training model 2003: (22,79) ...\n",
      "0.14325010299990026\n",
      "Training model 2004: (22,80) ...\n",
      "0.1951204880001569\n",
      "Training model 2005: (22,81) ...\n",
      "0.166535248999935\n",
      "Training model 2006: (22,82) ...\n",
      "0.2076595889998316\n",
      "Training model 2007: (22,83) ...\n",
      "0.131663534999916\n",
      "Training model 2008: (22,84) ...\n",
      "0.15965339300009873\n",
      "Training model 2009: (22,85) ...\n",
      "0.18173278999984177\n",
      "Training model 2010: (22,86) ...\n",
      "0.1742683699999361\n",
      "Training model 2011: (22,87) ...\n",
      "0.12815381699965656\n",
      "Training model 2012: (22,88) ...\n",
      "0.16332966499976465\n",
      "Training model 2013: (22,89) ...\n",
      "0.18882029900032649\n",
      "Training model 2014: (22,90) ...\n",
      "0.12881191199994646\n",
      "Training model 2015: (22,91) ...\n",
      "0.22519228800001656\n",
      "Training model 2016: (22,92) ...\n",
      "0.21643723600027442\n",
      "Training model 2017: (22,93) ...\n",
      "0.2867931119999412\n",
      "Training model 2018: (22,94) ...\n",
      "0.19006849900006273\n",
      "Training model 2019: (22,95) ...\n",
      "0.13526178499978414\n",
      "Training model 2020: (22,96) ...\n",
      "0.16152017900003557\n",
      "Training model 2021: (22,97) ...\n",
      "0.16337203300008696\n",
      "Training model 2022: (22,98) ...\n",
      "0.19736070900034974\n",
      "Training model 2023: (22,99) ...\n",
      "0.25513520399999834\n",
      "Training model 2024: (23,24) ...\n",
      "0.19055173800006742\n",
      "Training model 2025: (23,25) ...\n",
      "0.11740863600016382\n",
      "Training model 2026: (23,26) ...\n",
      "0.13349665200030358\n",
      "Training model 2027: (23,27) ...\n",
      "0.11250773300025685\n",
      "Training model 2028: (23,28) ...\n",
      "0.11787512199998673\n",
      "Training model 2029: (23,29) ...\n",
      "0.13650091100043937\n",
      "Training model 2030: (23,30) ...\n",
      "0.12122550699996282\n",
      "Training model 2031: (23,31) ...\n",
      "0.11765818800040506\n",
      "Training model 2032: (23,32) ...\n",
      "0.12485754500039548\n",
      "Training model 2033: (23,33) ...\n",
      "0.1362223860000995\n",
      "Training model 2034: (23,34) ...\n",
      "0.15483953100010694\n",
      "Training model 2035: (23,35) ...\n",
      "0.126211217999753\n",
      "Training model 2036: (23,36) ...\n",
      "0.16296524600011253\n",
      "Training model 2037: (23,37) ...\n",
      "0.12272754300011002\n",
      "Training model 2038: (23,38) ...\n",
      "0.12830551900015053\n",
      "Training model 2039: (23,39) ...\n",
      "0.20438187000036123\n",
      "Training model 2040: (23,40) ...\n",
      "0.12294143500002974\n",
      "Training model 2041: (23,41) ...\n",
      "0.1355546529998719\n",
      "Training model 2042: (23,42) ...\n",
      "0.14261799499990957\n",
      "Training model 2043: (23,43) ...\n",
      "0.15303809699980775\n",
      "Training model 2044: (23,44) ...\n",
      "0.13608113000009325\n",
      "Training model 2045: (23,45) ...\n",
      "0.13064488999998503\n",
      "Training model 2046: (23,46) ...\n",
      "0.13513791400009723\n",
      "Training model 2047: (23,47) ...\n",
      "0.12896977199989124\n",
      "Training model 2048: (23,48) ...\n",
      "0.15274695800007976\n",
      "Training model 2049: (23,49) ...\n",
      "0.15926305299990418\n",
      "Training model 2050: (23,50) ...\n",
      "0.17193096699975285\n",
      "Training model 2051: (23,51) ...\n",
      "0.14508534900005543\n",
      "Training model 2052: (23,52) ...\n",
      "0.12053402399988045\n",
      "Training model 2053: (23,53) ...\n",
      "0.13291927399995984\n",
      "Training model 2054: (23,54) ...\n",
      "0.1307730939997782\n",
      "Training model 2055: (23,55) ...\n",
      "0.11562097099977109\n",
      "Training model 2056: (23,56) ...\n",
      "0.12558454199961488\n",
      "Training model 2057: (23,57) ...\n",
      "0.1231011629997738\n",
      "Training model 2058: (23,58) ...\n",
      "0.15307104900011836\n",
      "Training model 2059: (23,59) ...\n",
      "0.11706496399983735\n",
      "Training model 2060: (23,60) ...\n",
      "0.13825403200007713\n",
      "Training model 2061: (23,61) ...\n",
      "0.14200073700021676\n",
      "Training model 2062: (23,62) ...\n",
      "0.1431890209996709\n",
      "Training model 2063: (23,63) ...\n",
      "0.14774356299994906\n",
      "Training model 2064: (23,64) ...\n",
      "0.12724310400017202\n",
      "Training model 2065: (23,65) ...\n",
      "0.1328895569999986\n",
      "Training model 2066: (23,66) ...\n",
      "0.12715045300001293\n",
      "Training model 2067: (23,67) ...\n",
      "0.1382463749996532\n",
      "Training model 2068: (23,68) ...\n",
      "0.11550607600020157\n",
      "Training model 2069: (23,69) ...\n",
      "0.12933968600009393\n",
      "Training model 2070: (23,70) ...\n",
      "0.12336753099998532\n",
      "Training model 2071: (23,71) ...\n",
      "0.14165470099987942\n",
      "Training model 2072: (23,72) ...\n",
      "0.12671364199968593\n",
      "Training model 2073: (23,73) ...\n",
      "0.1304402159998972\n",
      "Training model 2074: (23,74) ...\n",
      "0.14136384099992938\n",
      "Training model 2075: (23,75) ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12198882299981051\n",
      "Training model 2076: (23,76) ...\n",
      "0.14043407500003013\n",
      "Training model 2077: (23,77) ...\n",
      "0.13987165100024868\n",
      "Training model 2078: (23,78) ...\n",
      "0.14391972099974737\n",
      "Training model 2079: (23,79) ...\n",
      "0.14413130299999466\n",
      "Training model 2080: (23,80) ...\n",
      "0.247846890999881\n",
      "Training model 2081: (23,81) ...\n",
      "0.18152130399994348\n",
      "Training model 2082: (23,82) ...\n",
      "0.2547472769997512\n",
      "Training model 2083: (23,83) ...\n",
      "0.16793177099998502\n",
      "Training model 2084: (23,84) ...\n",
      "0.18101938900008463\n",
      "Training model 2085: (23,85) ...\n",
      "0.2584121380000397\n",
      "Training model 2086: (23,86) ...\n",
      "0.20745503699981782\n",
      "Training model 2087: (23,87) ...\n",
      "0.1713291770001888\n",
      "Training model 2088: (23,88) ...\n",
      "0.16622534599991923\n",
      "Training model 2089: (23,89) ...\n",
      "0.18715328100006445\n",
      "Training model 2090: (23,90) ...\n",
      "0.14632185699974798\n",
      "Training model 2091: (23,91) ...\n",
      "0.2340504929998133\n",
      "Training model 2092: (23,92) ...\n",
      "0.2051161280000997\n",
      "Training model 2093: (23,93) ...\n",
      "0.3124923939999462\n",
      "Training model 2094: (23,94) ...\n",
      "0.23187902000017857\n",
      "Training model 2095: (23,95) ...\n",
      "0.1438646560000052\n",
      "Training model 2096: (23,96) ...\n",
      "0.17842117600002894\n",
      "Training model 2097: (23,97) ...\n",
      "0.166041406000204\n",
      "Training model 2098: (23,98) ...\n",
      "0.16447122199997466\n",
      "Training model 2099: (23,99) ...\n",
      "0.30198483599997417\n",
      "Training model 2100: (24,25) ...\n",
      "0.10931671300022572\n",
      "Training model 2101: (24,26) ...\n",
      "0.12671809699986625\n",
      "Training model 2102: (24,27) ...\n",
      "0.10599886899990452\n",
      "Training model 2103: (24,28) ...\n",
      "0.1072632089999388\n",
      "Training model 2104: (24,29) ...\n",
      "0.10852197800022623\n",
      "Training model 2105: (24,30) ...\n",
      "0.12343533300008858\n",
      "Training model 2106: (24,31) ...\n",
      "0.11455187999990812\n",
      "Training model 2107: (24,32) ...\n",
      "0.12869584000009127\n",
      "Training model 2108: (24,33) ...\n",
      "0.10636451399977886\n",
      "Training model 2109: (24,34) ...\n",
      "0.11714671900017493\n",
      "Training model 2110: (24,35) ...\n",
      "0.12034958100002768\n",
      "Training model 2111: (24,36) ...\n",
      "0.15159800499986886\n",
      "Training model 2112: (24,37) ...\n",
      "0.11253791799981627\n",
      "Training model 2113: (24,38) ...\n",
      "0.11613337200014939\n",
      "Training model 2114: (24,39) ...\n",
      "0.17410950799967395\n",
      "Training model 2115: (24,40) ...\n",
      "0.11131827799999883\n",
      "Training model 2116: (24,41) ...\n",
      "0.12911274499992942\n",
      "Training model 2117: (24,42) ...\n",
      "0.1406302800000958\n",
      "Training model 2118: (24,43) ...\n",
      "0.1675037540003359\n",
      "Training model 2119: (24,44) ...\n",
      "0.13656049700011863\n",
      "Training model 2120: (24,45) ...\n",
      "0.11703377500043644\n",
      "Training model 2121: (24,46) ...\n",
      "0.12663493800027936\n",
      "Training model 2122: (24,47) ...\n",
      "0.1292947449996973\n",
      "Training model 2123: (24,48) ...\n",
      "0.12763371200026086\n",
      "Training model 2124: (24,49) ...\n",
      "0.12609499599966512\n",
      "Training model 2125: (24,50) ...\n",
      "0.15905675200019687\n",
      "Training model 2126: (24,51) ...\n",
      "0.12050596200015207\n",
      "Training model 2127: (24,52) ...\n",
      "0.10894229300038205\n",
      "Training model 2128: (24,53) ...\n",
      "0.1329148099998747\n",
      "Training model 2129: (24,54) ...\n",
      "0.13984120399982203\n",
      "Training model 2130: (24,55) ...\n",
      "0.1088721109999824\n",
      "Training model 2131: (24,56) ...\n",
      "0.12122647900014272\n",
      "Training model 2132: (24,57) ...\n",
      "0.12394674799998029\n",
      "Training model 2133: (24,58) ...\n",
      "0.14233392699998149\n",
      "Training model 2134: (24,59) ...\n",
      "0.11192929099979665\n",
      "Training model 2135: (24,60) ...\n",
      "0.14183010200031276\n",
      "Training model 2136: (24,61) ...\n",
      "0.13442401700012852\n",
      "Training model 2137: (24,62) ...\n",
      "0.1352000520000729\n",
      "Training model 2138: (24,63) ...\n",
      "0.1504250499997397\n",
      "Training model 2139: (24,64) ...\n",
      "0.11713051400010954\n",
      "Training model 2140: (24,65) ...\n",
      "0.10934243900010188\n",
      "Training model 2141: (24,66) ...\n",
      "0.1242298249999294\n",
      "Training model 2142: (24,67) ...\n",
      "0.14046355499976926\n",
      "Training model 2143: (24,68) ...\n",
      "0.12698657400005686\n",
      "Training model 2144: (24,69) ...\n",
      "0.12767240999983187\n",
      "Training model 2145: (24,70) ...\n",
      "0.10838103300011426\n",
      "Training model 2146: (24,71) ...\n",
      "0.114365357999759\n",
      "Training model 2147: (24,72) ...\n",
      "0.10799590199985687\n",
      "Training model 2148: (24,73) ...\n",
      "0.12360815099964384\n",
      "Training model 2149: (24,74) ...\n",
      "0.11323511699993105\n",
      "Training model 2150: (24,75) ...\n",
      "0.10478366799998184\n",
      "Training model 2151: (24,76) ...\n",
      "0.12592461099984575\n",
      "Training model 2152: (24,77) ...\n",
      "0.12679555000022447\n",
      "Training model 2153: (24,78) ...\n",
      "0.11785800699999527\n",
      "Training model 2154: (24,79) ...\n",
      "0.1183730579996336\n",
      "Training model 2155: (24,80) ...\n",
      "0.14491629699978148\n",
      "Training model 2156: (24,81) ...\n",
      "0.14218543700008013\n",
      "Training model 2157: (24,82) ...\n",
      "0.2054118890000609\n",
      "Training model 2158: (24,83) ...\n",
      "0.1316819899998336\n",
      "Training model 2159: (24,84) ...\n",
      "0.13330391199997393\n",
      "Training model 2160: (24,85) ...\n",
      "0.16334085899961792\n",
      "Training model 2161: (24,86) ...\n",
      "0.17770294199999626\n",
      "Training model 2162: (24,87) ...\n",
      "0.14062419999982012\n",
      "Training model 2163: (24,88) ...\n",
      "0.126246589999937\n",
      "Training model 2164: (24,89) ...\n",
      "0.12021897599970544\n",
      "Training model 2165: (24,90) ...\n",
      "0.10822290499982046\n",
      "Training model 2166: (24,91) ...\n",
      "0.12995954600000914\n",
      "Training model 2167: (24,92) ...\n",
      "0.12227118700002393\n",
      "Training model 2168: (24,93) ...\n",
      "0.15299402699974962\n",
      "Training model 2169: (24,94) ...\n",
      "0.12710459499976423\n",
      "Training model 2170: (24,95) ...\n",
      "0.10330673799990109\n",
      "Training model 2171: (24,96) ...\n",
      "0.11540518499987229\n",
      "Training model 2172: (24,97) ...\n",
      "0.11492677800015372\n",
      "Training model 2173: (24,98) ...\n",
      "0.10796036900001127\n",
      "Training model 2174: (24,99) ...\n",
      "0.13604579299999386\n",
      "Training model 2175: (25,26) ...\n",
      "0.2669969100002163\n",
      "Training model 2176: (25,27) ...\n",
      "0.15928331999975853\n",
      "Training model 2177: (25,28) ...\n",
      "0.5520814510000491\n",
      "Training model 2178: (25,29) ...\n",
      "0.11984951900012675\n",
      "Training model 2179: (25,30) ...\n",
      "0.15241548099993452\n",
      "Training model 2180: (25,31) ...\n",
      "0.12842203800028074\n",
      "Training model 2181: (25,32) ...\n",
      "0.17830084000024726\n",
      "Training model 2182: (25,33) ...\n",
      "0.11924442500003352\n",
      "Training model 2183: (25,34) ...\n",
      "0.12655286200015325\n",
      "Training model 2184: (25,35) ...\n",
      "0.1543143769999915\n",
      "Training model 2185: (25,36) ...\n",
      "0.174668014999952\n",
      "Training model 2186: (25,37) ...\n",
      "0.1538151800000378\n",
      "Training model 2187: (25,38) ...\n",
      "0.15951653999991322\n",
      "Training model 2188: (25,39) ...\n",
      "0.14355674199987334\n",
      "Training model 2189: (25,40) ...\n",
      "0.11886723899988283\n",
      "Training model 2190: (25,41) ...\n",
      "0.1546223350001128\n",
      "Training model 2191: (25,42) ...\n",
      "0.14997563199995056\n",
      "Training model 2192: (25,43) ...\n",
      "0.12712572700002056\n",
      "Training model 2193: (25,44) ...\n",
      "0.15534969700001966\n",
      "Training model 2194: (25,45) ...\n",
      "0.14960595600041415\n",
      "Training model 2195: (25,46) ...\n",
      "0.12834389299996474\n",
      "Training model 2196: (25,47) ...\n",
      "0.14179374400009692\n",
      "Training model 2197: (25,48) ...\n",
      "0.11099852899997131\n",
      "Training model 2198: (25,49) ...\n",
      "0.12836041099990325\n",
      "Training model 2199: (25,50) ...\n",
      "0.14169444400022257\n",
      "Training model 2200: (25,51) ...\n",
      "0.11415242800012493\n",
      "Training model 2201: (25,52) ...\n",
      "0.14781156900016867\n",
      "Training model 2202: (25,53) ...\n",
      "0.16524543700006689\n",
      "Training model 2203: (25,54) ...\n",
      "0.1744867349998458\n",
      "Training model 2204: (25,55) ...\n",
      "0.1191420229997675\n",
      "Training model 2205: (25,56) ...\n",
      "0.16749043499976324\n",
      "Training model 2206: (25,57) ...\n",
      "0.1565180520001377\n",
      "Training model 2207: (25,58) ...\n",
      "0.1727209670002594\n",
      "Training model 2208: (25,59) ...\n",
      "0.14076411900032326\n",
      "Training model 2209: (25,60) ...\n",
      "0.18671248700002252\n",
      "Training model 2210: (25,61) ...\n",
      "0.15010533200029386\n",
      "Training model 2211: (25,62) ...\n",
      "0.16633401700028116\n",
      "Training model 2212: (25,63) ...\n",
      "0.13577361099987684\n",
      "Training model 2213: (25,64) ...\n",
      "0.14496475299984013\n",
      "Training model 2214: (25,65) ...\n",
      "0.17225061199997072\n",
      "Training model 2215: (25,66) ...\n",
      "0.12871455399999832\n",
      "Training model 2216: (25,67) ...\n",
      "0.13326883299987458\n",
      "Training model 2217: (25,68) ...\n",
      "0.1423360200001298\n",
      "Training model 2218: (25,69) ...\n",
      "0.10629823699991903\n",
      "Training model 2219: (25,70) ...\n",
      "0.11209617400027128\n",
      "Training model 2220: (25,71) ...\n",
      "0.1905622580002273\n",
      "Training model 2221: (25,72) ...\n",
      "0.12069191399996271\n",
      "Training model 2222: (25,73) ...\n",
      "0.12078038699974059\n",
      "Training model 2223: (25,74) ...\n",
      "0.12512361400013106\n",
      "Training model 2224: (25,75) ...\n",
      "0.12793648599972585\n",
      "Training model 2225: (25,76) ...\n",
      "0.1667873840001448\n",
      "Training model 2226: (25,77) ...\n",
      "0.13979199200002768\n",
      "Training model 2227: (25,78) ...\n",
      "0.11906829899999138\n",
      "Training model 2228: (25,79) ...\n",
      "0.18998662200010585\n",
      "Training model 2229: (25,80) ...\n",
      "0.12127263399997901\n",
      "Training model 2230: (25,81) ...\n",
      "0.11443367599986232\n",
      "Training model 2231: (25,82) ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12364922699998715\n",
      "Training model 2232: (25,83) ...\n",
      "0.11146862900022825\n",
      "Training model 2233: (25,84) ...\n",
      "0.11572578100003739\n",
      "Training model 2234: (25,85) ...\n",
      "0.13891181300004973\n",
      "Training model 2235: (25,86) ...\n",
      "0.12608796499989694\n",
      "Training model 2236: (25,87) ...\n",
      "0.10476570299988452\n",
      "Training model 2237: (25,88) ...\n",
      "0.1273066009998729\n",
      "Training model 2238: (25,89) ...\n",
      "0.10646086499991725\n",
      "Training model 2239: (25,90) ...\n",
      "0.11844585300013932\n",
      "Training model 2240: (25,91) ...\n",
      "0.1190949830001955\n",
      "Training model 2241: (25,92) ...\n",
      "0.11400394599968422\n",
      "Training model 2242: (25,93) ...\n",
      "0.13539341100022284\n",
      "Training model 2243: (25,94) ...\n",
      "0.11508362099993974\n",
      "Training model 2244: (25,95) ...\n",
      "0.10358199700021942\n",
      "Training model 2245: (25,96) ...\n",
      "0.12428894599997875\n",
      "Training model 2246: (25,97) ...\n",
      "0.11697509499981606\n",
      "Training model 2247: (25,98) ...\n",
      "0.10938464800028669\n",
      "Training model 2248: (25,99) ...\n",
      "0.11186331400040217\n",
      "Training model 2249: (26,27) ...\n",
      "0.44754009600001154\n",
      "Training model 2250: (26,28) ...\n",
      "0.3348459960002401\n",
      "Training model 2251: (26,29) ...\n",
      "0.21434870500024772\n",
      "Training model 2252: (26,30) ...\n",
      "0.19522939799981032\n",
      "Training model 2253: (26,31) ...\n",
      "0.16843574799986527\n",
      "Training model 2254: (26,32) ...\n",
      "0.3442662859997654\n",
      "Training model 2255: (26,33) ...\n",
      "0.1743363440000394\n",
      "Training model 2256: (26,34) ...\n",
      "0.17618413300033353\n",
      "Training model 2257: (26,35) ...\n",
      "0.20275279999987106\n",
      "Training model 2258: (26,36) ...\n",
      "0.2053610729999491\n",
      "Training model 2259: (26,37) ...\n",
      "0.17540349399996558\n",
      "Training model 2260: (26,38) ...\n",
      "0.3043033569997533\n",
      "Training model 2261: (26,39) ...\n",
      "0.19419928300021638\n",
      "Training model 2262: (26,40) ...\n",
      "0.1941260720000173\n",
      "Training model 2263: (26,41) ...\n",
      "0.3182451909997326\n",
      "Training model 2264: (26,42) ...\n",
      "0.2383422259999861\n",
      "Training model 2265: (26,43) ...\n",
      "0.19825836799964236\n",
      "Training model 2266: (26,44) ...\n",
      "0.3517342920004012\n",
      "Training model 2267: (26,45) ...\n",
      "0.18795693899983235\n",
      "Training model 2268: (26,46) ...\n",
      "0.20058757000015248\n",
      "Training model 2269: (26,47) ...\n",
      "0.24533457899997302\n",
      "Training model 2270: (26,48) ...\n",
      "0.1453440039999805\n",
      "Training model 2271: (26,49) ...\n",
      "0.18829453599983026\n",
      "Training model 2272: (26,50) ...\n",
      "0.19003245000021707\n",
      "Training model 2273: (26,51) ...\n",
      "0.13583988599975783\n",
      "Training model 2274: (26,52) ...\n",
      "0.36875524900005985\n",
      "Training model 2275: (26,53) ...\n",
      "0.2847636080000484\n",
      "Training model 2276: (26,54) ...\n",
      "0.29354875500030175\n",
      "Training model 2277: (26,55) ...\n",
      "0.17747415400026512\n",
      "Training model 2278: (26,56) ...\n",
      "0.20815408299995397\n",
      "Training model 2279: (26,57) ...\n",
      "0.2953083490001518\n",
      "Training model 2280: (26,58) ...\n",
      "0.3371028810001917\n",
      "Training model 2281: (26,59) ...\n",
      "0.20381759699967006\n",
      "Training model 2282: (26,60) ...\n",
      "0.34532162799996513\n",
      "Training model 2283: (26,61) ...\n",
      "0.21050580600012836\n",
      "Training model 2284: (26,62) ...\n",
      "0.27496872000028816\n",
      "Training model 2285: (26,63) ...\n",
      "0.20280956199985667\n",
      "Training model 2286: (26,64) ...\n",
      "0.18875676400011798\n",
      "Training model 2287: (26,65) ...\n",
      "0.22548773200014693\n",
      "Training model 2288: (26,66) ...\n",
      "0.2185579830002098\n",
      "Training model 2289: (26,67) ...\n",
      "0.21530215299981137\n",
      "Training model 2290: (26,68) ...\n",
      "0.23758165599974745\n",
      "Training model 2291: (26,69) ...\n",
      "0.1530350590001035\n",
      "Training model 2292: (26,70) ...\n",
      "0.14895997800022087\n",
      "Training model 2293: (26,71) ...\n",
      "0.2557963140002357\n",
      "Training model 2294: (26,72) ...\n",
      "0.1294983179996052\n",
      "Training model 2295: (26,73) ...\n",
      "0.16780708399983268\n",
      "Training model 2296: (26,74) ...\n",
      "0.1420859200002269\n",
      "Training model 2297: (26,75) ...\n",
      "0.13599916500015752\n",
      "Training model 2298: (26,76) ...\n",
      "0.19546333399966898\n",
      "Training model 2299: (26,77) ...\n",
      "0.20052977099976488\n",
      "Training model 2300: (26,78) ...\n",
      "0.21078474900014044\n",
      "Training model 2301: (26,79) ...\n",
      "0.24792139600003793\n",
      "Training model 2302: (26,80) ...\n",
      "0.13476034799987247\n",
      "Training model 2303: (26,81) ...\n",
      "0.13522274600018136\n",
      "Training model 2304: (26,82) ...\n",
      "0.14650481599983323\n",
      "Training model 2305: (26,83) ...\n",
      "0.13576643599981253\n",
      "Training model 2306: (26,84) ...\n",
      "0.12858136600016223\n",
      "Training model 2307: (26,85) ...\n",
      "0.15118259900009434\n",
      "Training model 2308: (26,86) ...\n",
      "0.15597766400014734\n",
      "Training model 2309: (26,87) ...\n",
      "0.11771777600006317\n",
      "Training model 2310: (26,88) ...\n",
      "0.11948554599985073\n",
      "Training model 2311: (26,89) ...\n",
      "0.11883714099985809\n",
      "Training model 2312: (26,90) ...\n",
      "0.11606067200000325\n",
      "Training model 2313: (26,91) ...\n",
      "0.15485906699996121\n",
      "Training model 2314: (26,92) ...\n",
      "0.1306083919998855\n",
      "Training model 2315: (26,93) ...\n",
      "0.14095088099975328\n",
      "Training model 2316: (26,94) ...\n",
      "0.1418349880000278\n",
      "Training model 2317: (26,95) ...\n",
      "0.13539902999991682\n",
      "Training model 2318: (26,96) ...\n",
      "0.12525386499964952\n",
      "Training model 2319: (26,97) ...\n",
      "0.11970886400013114\n",
      "Training model 2320: (26,98) ...\n",
      "0.1352852250001888\n",
      "Training model 2321: (26,99) ...\n",
      "0.11944377999998324\n",
      "Training model 2322: (27,28) ...\n",
      "0.1683463680001296\n",
      "Training model 2323: (27,29) ...\n",
      "0.17445898300002227\n",
      "Training model 2324: (27,30) ...\n",
      "0.14251787500006685\n",
      "Training model 2325: (27,31) ...\n",
      "0.1471631729996261\n",
      "Training model 2326: (27,32) ...\n",
      "0.1955394729998261\n",
      "Training model 2327: (27,33) ...\n",
      "0.1339463760000399\n",
      "Training model 2328: (27,34) ...\n",
      "0.12877420299992082\n",
      "Training model 2329: (27,35) ...\n",
      "0.14355364799985182\n",
      "Training model 2330: (27,36) ...\n",
      "0.15512945599994055\n",
      "Training model 2331: (27,37) ...\n",
      "0.14284153000016886\n",
      "Training model 2332: (27,38) ...\n",
      "0.20584897299977456\n",
      "Training model 2333: (27,39) ...\n",
      "0.17570510099994863\n",
      "Training model 2334: (27,40) ...\n",
      "0.17077271300013308\n",
      "Training model 2335: (27,41) ...\n",
      "0.1651652569998987\n",
      "Training model 2336: (27,42) ...\n",
      "0.20976760499979719\n",
      "Training model 2337: (27,43) ...\n",
      "0.14390261700009432\n",
      "Training model 2338: (27,44) ...\n",
      "0.18244012000013754\n",
      "Training model 2339: (27,45) ...\n",
      "0.13199678000000858\n",
      "Training model 2340: (27,46) ...\n",
      "0.14837593099991864\n",
      "Training model 2341: (27,47) ...\n",
      "0.1540986449999764\n",
      "Training model 2342: (27,48) ...\n",
      "0.11712039300027755\n",
      "Training model 2343: (27,49) ...\n",
      "0.13714881499981857\n",
      "Training model 2344: (27,50) ...\n",
      "0.14964843200004907\n",
      "Training model 2345: (27,51) ...\n",
      "0.11826487500002258\n",
      "Training model 2346: (27,52) ...\n",
      "0.2682594810003138\n",
      "Training model 2347: (27,53) ...\n",
      "0.2330088380003872\n",
      "Training model 2348: (27,54) ...\n",
      "0.18057192900005248\n",
      "Training model 2349: (27,55) ...\n",
      "0.14110927699994136\n",
      "Training model 2350: (27,56) ...\n",
      "0.174177335999957\n",
      "Training model 2351: (27,57) ...\n",
      "0.18633209500012526\n",
      "Training model 2352: (27,58) ...\n",
      "0.17971927999997206\n",
      "Training model 2353: (27,59) ...\n",
      "0.14258803500024442\n",
      "Training model 2354: (27,60) ...\n",
      "0.19220254899983047\n",
      "Training model 2355: (27,61) ...\n",
      "0.16911977600011596\n",
      "Training model 2356: (27,62) ...\n",
      "0.17698436199998469\n",
      "Training model 2357: (27,63) ...\n",
      "0.15381928300030268\n",
      "Training model 2358: (27,64) ...\n",
      "0.14257952799971463\n",
      "Training model 2359: (27,65) ...\n",
      "0.13211486199998035\n",
      "Training model 2360: (27,66) ...\n",
      "0.13488872400012042\n",
      "Training model 2361: (27,67) ...\n",
      "0.14412009900024714\n",
      "Training model 2362: (27,68) ...\n",
      "0.13724956699979884\n",
      "Training model 2363: (27,69) ...\n",
      "0.11992477499961751\n",
      "Training model 2364: (27,70) ...\n",
      "0.13131699599989588\n",
      "Training model 2365: (27,71) ...\n",
      "0.2029832900002475\n",
      "Training model 2366: (27,72) ...\n",
      "0.10771492000003491\n",
      "Training model 2367: (27,73) ...\n",
      "0.12901863900015087\n",
      "Training model 2368: (27,74) ...\n",
      "0.11464934600007837\n",
      "Training model 2369: (27,75) ...\n",
      "0.11946906000002855\n",
      "Training model 2370: (27,76) ...\n",
      "0.1624748780000118\n",
      "Training model 2371: (27,77) ...\n",
      "0.14788002500017683\n",
      "Training model 2372: (27,78) ...\n",
      "0.20495794699991166\n",
      "Training model 2373: (27,79) ...\n",
      "0.20078882600000725\n",
      "Training model 2374: (27,80) ...\n",
      "0.11008672700017996\n",
      "Training model 2375: (27,81) ...\n",
      "0.12215288000015789\n",
      "Training model 2376: (27,82) ...\n",
      "0.1401252000000568\n",
      "Training model 2377: (27,83) ...\n",
      "0.11016899399965041\n",
      "Training model 2378: (27,84) ...\n",
      "0.11564387599992187\n",
      "Training model 2379: (27,85) ...\n",
      "0.14689241999985825\n",
      "Training model 2380: (27,86) ...\n",
      "0.13289837299998908\n",
      "Training model 2381: (27,87) ...\n",
      "0.10500895099994523\n",
      "Training model 2382: (27,88) ...\n",
      "0.12738501000012548\n",
      "Training model 2383: (27,89) ...\n",
      "0.10715061799965042\n",
      "Training model 2384: (27,90) ...\n",
      "0.1296391760001825\n",
      "Training model 2385: (27,91) ...\n",
      "0.13242339799990077\n",
      "Training model 2386: (27,92) ...\n",
      "0.12238804500020706\n",
      "Training model 2387: (27,93) ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12142902599998706\n",
      "Training model 2388: (27,94) ...\n",
      "0.14868801300008272\n",
      "Training model 2389: (27,95) ...\n",
      "0.12398324200012212\n",
      "Training model 2390: (27,96) ...\n",
      "0.12221374699993248\n",
      "Training model 2391: (27,97) ...\n",
      "0.11105084800010445\n",
      "Training model 2392: (27,98) ...\n",
      "0.10704374200031452\n",
      "Training model 2393: (27,99) ...\n",
      "0.11194353000018964\n",
      "Training model 2394: (28,29) ...\n",
      "0.14347631500004354\n",
      "Training model 2395: (28,30) ...\n",
      "0.18026818799989996\n",
      "Training model 2396: (28,31) ...\n",
      "0.1341011099998468\n",
      "Training model 2397: (28,32) ...\n",
      "0.20864707200007615\n",
      "Training model 2398: (28,33) ...\n",
      "0.14490223099983268\n",
      "Training model 2399: (28,34) ...\n",
      "0.15668892899975617\n",
      "Training model 2400: (28,35) ...\n",
      "0.1937537329999941\n",
      "Training model 2401: (28,36) ...\n",
      "0.2093311150001682\n",
      "Training model 2402: (28,37) ...\n",
      "0.1774134409997714\n",
      "Training model 2403: (28,38) ...\n",
      "0.1865078050000193\n",
      "Training model 2404: (28,39) ...\n",
      "0.15338168000016594\n",
      "Training model 2405: (28,40) ...\n",
      "0.12410875000023225\n",
      "Training model 2406: (28,41) ...\n",
      "0.1839811899999404\n",
      "Training model 2407: (28,42) ...\n",
      "0.14736200600009397\n",
      "Training model 2408: (28,43) ...\n",
      "0.14241637099985383\n",
      "Training model 2409: (28,44) ...\n",
      "0.19507949700027893\n",
      "Training model 2410: (28,45) ...\n",
      "0.1628587560003325\n",
      "Training model 2411: (28,46) ...\n",
      "0.13513718499962124\n",
      "Training model 2412: (28,47) ...\n",
      "0.14638498199974492\n",
      "Training model 2413: (28,48) ...\n",
      "0.11941731399974742\n",
      "Training model 2414: (28,49) ...\n",
      "0.14877151100017727\n",
      "Training model 2415: (28,50) ...\n",
      "0.1763781630002086\n",
      "Training model 2416: (28,51) ...\n",
      "0.13469986000018253\n",
      "Training model 2417: (28,52) ...\n",
      "0.1772036739998839\n",
      "Training model 2418: (28,53) ...\n",
      "0.20157847900009074\n",
      "Training model 2419: (28,54) ...\n",
      "0.21040846300002158\n",
      "Training model 2420: (28,55) ...\n",
      "0.13253288899977633\n",
      "Training model 2421: (28,56) ...\n",
      "0.20409284799961824\n",
      "Training model 2422: (28,57) ...\n",
      "0.18470985499970993\n",
      "Training model 2423: (28,58) ...\n",
      "0.20112318799965578\n",
      "Training model 2424: (28,59) ...\n",
      "0.13357781800004886\n",
      "Training model 2425: (28,60) ...\n",
      "0.23023409600000377\n",
      "Training model 2426: (28,61) ...\n",
      "0.17764851800029646\n",
      "Training model 2427: (28,62) ...\n",
      "0.2029561859999376\n",
      "Training model 2428: (28,63) ...\n",
      "0.15398876799963546\n",
      "Training model 2429: (28,64) ...\n",
      "0.14146729300000516\n",
      "Training model 2430: (28,65) ...\n",
      "0.18041442599997026\n",
      "Training model 2431: (28,66) ...\n",
      "0.14183031199991092\n",
      "Training model 2432: (28,67) ...\n",
      "0.1729251359997761\n",
      "Training model 2433: (28,68) ...\n",
      "0.16133648899995023\n",
      "Training model 2434: (28,69) ...\n",
      "0.12096472799976254\n",
      "Training model 2435: (28,70) ...\n",
      "0.11673274099985065\n",
      "Training model 2436: (28,71) ...\n",
      "0.25642455600018366\n",
      "Training model 2437: (28,72) ...\n",
      "0.1257557559997622\n",
      "Training model 2438: (28,73) ...\n",
      "0.13934532500024943\n",
      "Training model 2439: (28,74) ...\n",
      "0.12283966700033488\n",
      "Training model 2440: (28,75) ...\n",
      "0.14333882999972047\n",
      "Training model 2441: (28,76) ...\n",
      "0.1946763490000194\n",
      "Training model 2442: (28,77) ...\n",
      "0.15716775700002472\n",
      "Training model 2443: (28,78) ...\n",
      "0.1454392519999601\n",
      "Training model 2444: (28,79) ...\n",
      "0.21366826099983882\n",
      "Training model 2445: (28,80) ...\n",
      "0.12204572000018743\n",
      "Training model 2446: (28,81) ...\n",
      "0.12308415699999387\n",
      "Training model 2447: (28,82) ...\n",
      "0.13519705899989276\n",
      "Training model 2448: (28,83) ...\n",
      "0.11175908300037918\n",
      "Training model 2449: (28,84) ...\n",
      "0.11608239499992123\n",
      "Training model 2450: (28,85) ...\n",
      "0.14191466200009017\n",
      "Training model 2451: (28,86) ...\n",
      "0.13463945000012245\n",
      "Training model 2452: (28,87) ...\n",
      "0.11658774900024582\n",
      "Training model 2453: (28,88) ...\n",
      "0.12027848200023072\n",
      "Training model 2454: (28,89) ...\n",
      "0.10657278200005749\n",
      "Training model 2455: (28,90) ...\n",
      "0.11389993600005255\n",
      "Training model 2456: (28,91) ...\n",
      "0.1325306619996809\n",
      "Training model 2457: (28,92) ...\n",
      "0.11226583600000595\n",
      "Training model 2458: (28,93) ...\n",
      "0.1317324409997127\n",
      "Training model 2459: (28,94) ...\n",
      "0.118733119999888\n",
      "Training model 2460: (28,95) ...\n",
      "0.1078045409999504\n",
      "Training model 2461: (28,96) ...\n",
      "0.12394964299983258\n",
      "Training model 2462: (28,97) ...\n",
      "0.11677250999991884\n",
      "Training model 2463: (28,98) ...\n",
      "0.12348436300044341\n",
      "Training model 2464: (28,99) ...\n",
      "0.11302610299981097\n",
      "Training model 2465: (29,30) ...\n",
      "0.15224476899993533\n",
      "Training model 2466: (29,31) ...\n",
      "0.1564771380003549\n",
      "Training model 2467: (29,32) ...\n",
      "0.16337827799998195\n",
      "Training model 2468: (29,33) ...\n",
      "0.17916736100005437\n",
      "Training model 2469: (29,34) ...\n",
      "0.14973339500011207\n",
      "Training model 2470: (29,35) ...\n",
      "0.14635018899980423\n",
      "Training model 2471: (29,36) ...\n",
      "0.18489222700009122\n",
      "Training model 2472: (29,37) ...\n",
      "0.12895252499993148\n",
      "Training model 2473: (29,38) ...\n",
      "0.17662225800040687\n",
      "Training model 2474: (29,39) ...\n",
      "0.16086438699994687\n",
      "Training model 2475: (29,40) ...\n",
      "0.1453401210001175\n",
      "Training model 2476: (29,41) ...\n",
      "0.13638256099966384\n",
      "Training model 2477: (29,42) ...\n",
      "0.13237704099992698\n",
      "Training model 2478: (29,43) ...\n",
      "0.15094999300026757\n",
      "Training model 2479: (29,44) ...\n",
      "0.15920373400012977\n",
      "Training model 2480: (29,45) ...\n",
      "0.12293974899966997\n",
      "Training model 2481: (29,46) ...\n",
      "0.1474112400001104\n",
      "Training model 2482: (29,47) ...\n",
      "0.1539381319998938\n",
      "Training model 2483: (29,48) ...\n",
      "0.13668179900014366\n",
      "Training model 2484: (29,49) ...\n",
      "0.12074234099964087\n",
      "Training model 2485: (29,50) ...\n",
      "0.13920559400003185\n",
      "Training model 2486: (29,51) ...\n",
      "0.14300751100017806\n",
      "Training model 2487: (29,52) ...\n",
      "0.16439219800031424\n",
      "Training model 2488: (29,53) ...\n",
      "0.16258376399991903\n",
      "Training model 2489: (29,54) ...\n",
      "0.14523507100011557\n",
      "Training model 2490: (29,55) ...\n",
      "0.1373124779997852\n",
      "Training model 2491: (29,56) ...\n",
      "0.13265915400006634\n",
      "Training model 2492: (29,57) ...\n",
      "0.12961099900030604\n",
      "Training model 2493: (29,58) ...\n",
      "0.15947578200029966\n",
      "Training model 2494: (29,59) ...\n",
      "0.1425425490001544\n",
      "Training model 2495: (29,60) ...\n",
      "0.16191993399979765\n",
      "Training model 2496: (29,61) ...\n",
      "0.14528743599976224\n",
      "Training model 2497: (29,62) ...\n",
      "0.14936845100010032\n",
      "Training model 2498: (29,63) ...\n",
      "0.1555401539999366\n",
      "Training model 2499: (29,64) ...\n",
      "0.14869208300024184\n",
      "Training model 2500: (29,65) ...\n",
      "0.15909037400024317\n",
      "Training model 2501: (29,66) ...\n",
      "0.14474702200004685\n",
      "Training model 2502: (29,67) ...\n",
      "0.1346098220001295\n",
      "Training model 2503: (29,68) ...\n",
      "0.1313762830000087\n",
      "Training model 2504: (29,69) ...\n",
      "0.12335042700033227\n",
      "Training model 2505: (29,70) ...\n",
      "0.11823805099993479\n",
      "Training model 2506: (29,71) ...\n",
      "0.14861896000002162\n",
      "Training model 2507: (29,72) ...\n",
      "0.10658354999986841\n",
      "Training model 2508: (29,73) ...\n",
      "0.11963828800026022\n",
      "Training model 2509: (29,74) ...\n",
      "0.11603236900009506\n",
      "Training model 2510: (29,75) ...\n",
      "0.12024136799982443\n",
      "Training model 2511: (29,76) ...\n",
      "0.14826540300009583\n",
      "Training model 2512: (29,77) ...\n",
      "0.12683469000012337\n",
      "Training model 2513: (29,78) ...\n",
      "0.17419780599993828\n",
      "Training model 2514: (29,79) ...\n",
      "0.15009031299996423\n",
      "Training model 2515: (29,80) ...\n",
      "0.12242085499974564\n",
      "Training model 2516: (29,81) ...\n",
      "0.12624575500012725\n",
      "Training model 2517: (29,82) ...\n",
      "0.12848596599997109\n",
      "Training model 2518: (29,83) ...\n",
      "0.11022062800020649\n",
      "Training model 2519: (29,84) ...\n",
      "0.11974609300023076\n",
      "Training model 2520: (29,85) ...\n",
      "0.12901471100030903\n",
      "Training model 2521: (29,86) ...\n",
      "0.12868124900023759\n",
      "Training model 2522: (29,87) ...\n",
      "0.13793519799992282\n",
      "Training model 2523: (29,88) ...\n",
      "0.1336650009998266\n",
      "Training model 2524: (29,89) ...\n",
      "0.14020543999959045\n",
      "Training model 2525: (29,90) ...\n",
      "0.1267954519998966\n",
      "Training model 2526: (29,91) ...\n",
      "0.11775032400009877\n",
      "Training model 2527: (29,92) ...\n",
      "0.11916793099999268\n",
      "Training model 2528: (29,93) ...\n",
      "0.1313664700001027\n",
      "Training model 2529: (29,94) ...\n",
      "0.13446336299966788\n",
      "Training model 2530: (29,95) ...\n",
      "0.11882493599978261\n",
      "Training model 2531: (29,96) ...\n",
      "0.13014208100003088\n",
      "Training model 2532: (29,97) ...\n",
      "0.13559324500010916\n",
      "Training model 2533: (29,98) ...\n",
      "0.12858015500023612\n",
      "Training model 2534: (29,99) ...\n",
      "0.12809636199972374\n",
      "Training model 2535: (30,31) ...\n",
      "0.22988515500037465\n",
      "Training model 2536: (30,32) ...\n",
      "0.43671516499989593\n",
      "Training model 2537: (30,33) ...\n",
      "0.181784547999996\n",
      "Training model 2538: (30,34) ...\n",
      "0.1474108300003536\n",
      "Training model 2539: (30,35) ...\n",
      "0.2176680560000932\n",
      "Training model 2540: (30,36) ...\n",
      "0.2705477899999096\n",
      "Training model 2541: (30,37) ...\n",
      "0.1916820389997156\n",
      "Training model 2542: (30,38) ...\n",
      "0.1524515020000763\n",
      "Training model 2543: (30,39) ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2404946070000733\n",
      "Training model 2544: (30,40) ...\n",
      "0.15819449799982976\n",
      "Training model 2545: (30,41) ...\n",
      "0.16943722399992112\n",
      "Training model 2546: (30,42) ...\n",
      "0.15417474099967876\n",
      "Training model 2547: (30,43) ...\n",
      "0.15972628700001223\n",
      "Training model 2548: (30,44) ...\n",
      "0.19469942900013848\n",
      "Training model 2549: (30,45) ...\n",
      "0.13329461399962383\n",
      "Training model 2550: (30,46) ...\n",
      "0.19710625799962145\n",
      "Training model 2551: (30,47) ...\n",
      "0.19842398199989475\n",
      "Training model 2552: (30,48) ...\n",
      "0.15698410400000284\n",
      "Training model 2553: (30,49) ...\n",
      "0.15896444200006954\n",
      "Training model 2554: (30,50) ...\n",
      "0.18884960200011847\n",
      "Training model 2555: (30,51) ...\n",
      "0.12347828699967067\n",
      "Training model 2556: (30,52) ...\n",
      "0.15563097899985223\n",
      "Training model 2557: (30,53) ...\n",
      "0.19726616800016927\n",
      "Training model 2558: (30,54) ...\n",
      "0.19854089099999328\n",
      "Training model 2559: (30,55) ...\n",
      "0.1725850980001269\n",
      "Training model 2560: (30,56) ...\n",
      "0.1467366110000512\n",
      "Training model 2561: (30,57) ...\n",
      "0.22482463200003622\n",
      "Training model 2562: (30,58) ...\n",
      "0.2755983900001411\n",
      "Training model 2563: (30,59) ...\n",
      "0.16220725099992706\n",
      "Training model 2564: (30,60) ...\n",
      "0.19305735999978424\n",
      "Training model 2565: (30,61) ...\n",
      "0.1747013619997233\n",
      "Training model 2566: (30,62) ...\n",
      "0.20545667299984416\n",
      "Training model 2567: (30,63) ...\n",
      "0.15539126700014094\n",
      "Training model 2568: (30,64) ...\n",
      "0.17985272399982932\n",
      "Training model 2569: (30,65) ...\n",
      "0.1545607109997036\n",
      "Training model 2570: (30,66) ...\n",
      "0.1513602379995973\n",
      "Training model 2571: (30,67) ...\n",
      "0.1661726440001985\n",
      "Training model 2572: (30,68) ...\n",
      "0.1589346089999708\n",
      "Training model 2573: (30,69) ...\n",
      "0.12442871399980504\n",
      "Training model 2574: (30,70) ...\n",
      "0.12646800999982588\n",
      "Training model 2575: (30,71) ...\n",
      "0.16944262200013327\n",
      "Training model 2576: (30,72) ...\n",
      "0.13042436599971552\n",
      "Training model 2577: (30,73) ...\n",
      "0.12847504699993806\n",
      "Training model 2578: (30,74) ...\n",
      "0.13854208200018547\n",
      "Training model 2579: (30,75) ...\n",
      "0.11697534299992185\n",
      "Training model 2580: (30,76) ...\n",
      "0.15757186300015746\n",
      "Training model 2581: (30,77) ...\n",
      "0.16535207100014304\n",
      "Training model 2582: (30,78) ...\n",
      "0.12927635000005466\n",
      "Training model 2583: (30,79) ...\n",
      "0.1544085149998864\n",
      "Training model 2584: (30,80) ...\n",
      "0.11709387000018978\n",
      "Training model 2585: (30,81) ...\n",
      "0.13445380800021667\n",
      "Training model 2586: (30,82) ...\n",
      "0.16232896499968774\n",
      "Training model 2587: (30,83) ...\n",
      "0.11797433799983992\n",
      "Training model 2588: (30,84) ...\n",
      "0.1305527079998683\n",
      "Training model 2589: (30,85) ...\n",
      "0.16156694099981905\n",
      "Training model 2590: (30,86) ...\n",
      "0.14490312300040387\n",
      "Training model 2591: (30,87) ...\n",
      "0.11096717700002046\n",
      "Training model 2592: (30,88) ...\n",
      "0.13064384700010123\n",
      "Training model 2593: (30,89) ...\n",
      "0.12262844199995016\n",
      "Training model 2594: (30,90) ...\n",
      "0.11964897799998653\n",
      "Training model 2595: (30,91) ...\n",
      "0.1477570229999401\n",
      "Training model 2596: (30,92) ...\n",
      "0.11961731900009909\n",
      "Training model 2597: (30,93) ...\n",
      "0.1311203340001157\n",
      "Training model 2598: (30,94) ...\n",
      "0.13241564899999503\n",
      "Training model 2599: (30,95) ...\n",
      "0.12659401099972456\n",
      "Training model 2600: (30,96) ...\n",
      "0.13163448200020866\n",
      "Training model 2601: (30,97) ...\n",
      "0.13838883200014607\n",
      "Training model 2602: (30,98) ...\n",
      "0.13257301699968593\n",
      "Training model 2603: (30,99) ...\n",
      "0.12083065100023305\n",
      "Training model 2604: (31,32) ...\n",
      "0.29227651399969545\n",
      "Training model 2605: (31,33) ...\n",
      "0.15263715999981287\n",
      "Training model 2606: (31,34) ...\n",
      "0.12559733200032497\n",
      "Training model 2607: (31,35) ...\n",
      "0.1334678050002367\n",
      "Training model 2608: (31,36) ...\n",
      "0.16654861300003176\n",
      "Training model 2609: (31,37) ...\n",
      "0.12854457000003094\n",
      "Training model 2610: (31,38) ...\n",
      "0.15933873400035736\n",
      "Training model 2611: (31,39) ...\n",
      "0.20327035099990098\n",
      "Training model 2612: (31,40) ...\n",
      "0.5032314090003638\n",
      "Training model 2613: (31,41) ...\n",
      "0.12830569600009767\n",
      "Training model 2614: (31,42) ...\n",
      "0.1516163620003681\n",
      "Training model 2615: (31,43) ...\n",
      "0.16084483700024066\n",
      "Training model 2616: (31,44) ...\n",
      "0.14541495399998894\n",
      "Training model 2617: (31,45) ...\n",
      "0.11575402500011478\n",
      "Training model 2618: (31,46) ...\n",
      "0.4737911299998814\n",
      "Training model 2619: (31,47) ...\n",
      "0.2860928279997097\n",
      "Training model 2620: (31,48) ...\n",
      "0.1338108300001295\n",
      "Training model 2621: (31,49) ...\n",
      "0.1378212929998881\n",
      "Training model 2622: (31,50) ...\n",
      "0.12493513900017206\n",
      "Training model 2623: (31,51) ...\n",
      "0.11953775300025882\n",
      "Training model 2624: (31,52) ...\n",
      "0.14184199000010267\n",
      "Training model 2625: (31,53) ...\n",
      "0.16235632400002942\n",
      "Training model 2626: (31,54) ...\n",
      "0.1407575270000052\n",
      "Training model 2627: (31,55) ...\n",
      "0.3673100030000569\n",
      "Training model 2628: (31,56) ...\n",
      "0.12184546299977228\n",
      "Training model 2629: (31,57) ...\n",
      "0.1388840650001839\n",
      "Training model 2630: (31,58) ...\n",
      "0.15475852100007614\n",
      "Training model 2631: (31,59) ...\n",
      "0.33780814100009593\n",
      "Training model 2632: (31,60) ...\n",
      "0.18352464700001292\n",
      "Training model 2633: (31,61) ...\n",
      "0.1463300010000239\n",
      "Training model 2634: (31,62) ...\n",
      "0.15425524000011137\n",
      "Training model 2635: (31,63) ...\n",
      "0.1450920409997707\n",
      "Training model 2636: (31,64) ...\n",
      "0.3553671680001571\n",
      "Training model 2637: (31,65) ...\n",
      "0.13079557199989722\n",
      "Training model 2638: (31,66) ...\n",
      "0.13726057499980016\n",
      "Training model 2639: (31,67) ...\n",
      "0.12709317999997438\n",
      "Training model 2640: (31,68) ...\n",
      "0.12943035400030567\n",
      "Training model 2641: (31,69) ...\n",
      "0.12189871700002186\n",
      "Training model 2642: (31,70) ...\n",
      "0.15442752799981463\n",
      "Training model 2643: (31,71) ...\n",
      "0.14060788599999796\n",
      "Training model 2644: (31,72) ...\n",
      "0.12667408600009367\n",
      "Training model 2645: (31,73) ...\n",
      "0.1366888679999647\n",
      "Training model 2646: (31,74) ...\n",
      "0.14213158900020062\n",
      "Training model 2647: (31,75) ...\n",
      "0.11886733399978766\n",
      "Training model 2648: (31,76) ...\n",
      "0.12734928699956072\n",
      "Training model 2649: (31,77) ...\n",
      "0.16905289800024548\n",
      "Training model 2650: (31,78) ...\n",
      "0.13976117099991825\n",
      "Training model 2651: (31,79) ...\n",
      "0.13910586099973443\n",
      "Training model 2652: (31,80) ...\n",
      "0.10588330700011284\n",
      "Training model 2653: (31,81) ...\n",
      "0.10970816899998681\n",
      "Training model 2654: (31,82) ...\n",
      "0.11378573199999664\n",
      "Training model 2655: (31,83) ...\n",
      "0.10589860899972336\n",
      "Training model 2656: (31,84) ...\n",
      "0.12554428900011771\n",
      "Training model 2657: (31,85) ...\n",
      "0.126435372999822\n",
      "Training model 2658: (31,86) ...\n",
      "0.12183943299987732\n",
      "Training model 2659: (31,87) ...\n",
      "0.11851746999991519\n",
      "Training model 2660: (31,88) ...\n",
      "0.13762206199999127\n",
      "Training model 2661: (31,89) ...\n",
      "0.11486304600020958\n",
      "Training model 2662: (31,90) ...\n",
      "0.1348534670000845\n",
      "Training model 2663: (31,91) ...\n",
      "0.1274894849998418\n",
      "Training model 2664: (31,92) ...\n",
      "0.13512465400026485\n",
      "Training model 2665: (31,93) ...\n",
      "0.12584031100004722\n",
      "Training model 2666: (31,94) ...\n",
      "0.15359354099973643\n",
      "Training model 2667: (31,95) ...\n",
      "0.1354440430000068\n",
      "Training model 2668: (31,96) ...\n",
      "0.13439342599986048\n",
      "Training model 2669: (31,97) ...\n",
      "0.11473869899964484\n",
      "Training model 2670: (31,98) ...\n",
      "0.11256126999978733\n",
      "Training model 2671: (31,99) ...\n",
      "0.11657825600013894\n",
      "Training model 2672: (32,33) ...\n",
      "0.20733091500005685\n",
      "Training model 2673: (32,34) ...\n",
      "0.17395223200037435\n",
      "Training model 2674: (32,35) ...\n",
      "0.2223904490001587\n",
      "Training model 2675: (32,36) ...\n",
      "0.2553227970001899\n",
      "Training model 2676: (32,37) ...\n",
      "0.20190368000021408\n",
      "Training model 2677: (32,38) ...\n",
      "0.28566445200021917\n",
      "Training model 2678: (32,39) ...\n",
      "0.2406625830003577\n",
      "Training model 2679: (32,40) ...\n",
      "0.1834779890000391\n",
      "Training model 2680: (32,41) ...\n",
      "0.2563123700001597\n",
      "Training model 2681: (32,42) ...\n",
      "0.2515450000000783\n",
      "Training model 2682: (32,43) ...\n",
      "0.2750296780000099\n",
      "Training model 2683: (32,44) ...\n",
      "0.305168276999666\n",
      "Training model 2684: (32,45) ...\n",
      "0.19097557500026596\n",
      "Training model 2685: (32,46) ...\n",
      "0.2071216010003809\n",
      "Training model 2686: (32,47) ...\n",
      "0.2713135929998316\n",
      "Training model 2687: (32,48) ...\n",
      "0.16927408099991226\n",
      "Training model 2688: (32,49) ...\n",
      "0.18992553100042642\n",
      "Training model 2689: (32,50) ...\n",
      "0.16680042999996658\n",
      "Training model 2690: (32,51) ...\n",
      "0.14380633300015688\n",
      "Training model 2691: (32,52) ...\n",
      "0.20987496799989458\n",
      "Training model 2692: (32,53) ...\n",
      "0.210624187999656\n",
      "Training model 2693: (32,54) ...\n",
      "0.3161359509999784\n",
      "Training model 2694: (32,55) ...\n",
      "0.1730129819998183\n",
      "Training model 2695: (32,56) ...\n",
      "0.17932920600014768\n",
      "Training model 2696: (32,57) ...\n",
      "0.2571333930000037\n",
      "Training model 2697: (32,58) ...\n",
      "0.2782597989998976\n",
      "Training model 2698: (32,59) ...\n",
      "0.18182224600013797\n",
      "Training model 2699: (32,60) ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3498641830001361\n",
      "Training model 2700: (32,61) ...\n",
      "0.2503125270000055\n",
      "Training model 2701: (32,62) ...\n",
      "0.2995589150000342\n",
      "Training model 2702: (32,63) ...\n",
      "0.3203130570000212\n",
      "Training model 2703: (32,64) ...\n",
      "0.1876545800000713\n",
      "Training model 2704: (32,65) ...\n",
      "0.20167124199997488\n",
      "Training model 2705: (32,66) ...\n",
      "0.3046087040002021\n",
      "Training model 2706: (32,67) ...\n",
      "0.27414104599984057\n",
      "Training model 2707: (32,68) ...\n",
      "0.31503159300018524\n",
      "Training model 2708: (32,69) ...\n",
      "0.1515365479999673\n",
      "Training model 2709: (32,70) ...\n",
      "0.14581646800024828\n",
      "Training model 2710: (32,71) ...\n",
      "0.2558038000001943\n",
      "Training model 2711: (32,72) ...\n",
      "0.12208547900036137\n",
      "Training model 2712: (32,73) ...\n",
      "0.16197461199999452\n",
      "Training model 2713: (32,74) ...\n",
      "0.13974336599994786\n",
      "Training model 2714: (32,75) ...\n",
      "0.12929267999970762\n",
      "Training model 2715: (32,76) ...\n",
      "0.19424664300004224\n",
      "Training model 2716: (32,77) ...\n",
      "0.21670009700028459\n",
      "Training model 2717: (32,78) ...\n",
      "0.173456088000421\n",
      "Training model 2718: (32,79) ...\n",
      "0.19669155899964608\n",
      "Training model 2719: (32,80) ...\n",
      "0.12257785400015564\n",
      "Training model 2720: (32,81) ...\n",
      "0.14204886100014846\n",
      "Training model 2721: (32,82) ...\n",
      "0.16991477399960786\n",
      "Training model 2722: (32,83) ...\n",
      "0.1321651319999546\n",
      "Training model 2723: (32,84) ...\n",
      "0.13126667200003794\n",
      "Training model 2724: (32,85) ...\n",
      "0.15846898200015858\n",
      "Training model 2725: (32,86) ...\n",
      "0.16087256999981037\n",
      "Training model 2726: (32,87) ...\n",
      "0.11539059899996573\n",
      "Training model 2727: (32,88) ...\n",
      "0.12206191499990382\n",
      "Training model 2728: (32,89) ...\n",
      "0.11998539200021696\n",
      "Training model 2729: (32,90) ...\n",
      "0.12136229599991566\n",
      "Training model 2730: (32,91) ...\n",
      "0.13299440699984189\n",
      "Training model 2731: (32,92) ...\n",
      "0.12700154899994232\n",
      "Training model 2732: (32,93) ...\n",
      "0.12381683300009172\n",
      "Training model 2733: (32,94) ...\n",
      "0.14731455499986623\n",
      "Training model 2734: (32,95) ...\n",
      "0.13091940699996485\n",
      "Training model 2735: (32,96) ...\n",
      "0.12131514100019558\n",
      "Training model 2736: (32,97) ...\n",
      "0.11890938900023684\n",
      "Training model 2737: (32,98) ...\n",
      "0.12331138699983057\n",
      "Training model 2738: (32,99) ...\n",
      "0.11744663700028468\n",
      "Training model 2739: (33,34) ...\n",
      "0.41439729600006103\n",
      "Training model 2740: (33,35) ...\n",
      "0.2422138250003627\n",
      "Training model 2741: (33,36) ...\n",
      "0.29922704999989946\n",
      "Training model 2742: (33,37) ...\n",
      "0.1758322489999955\n",
      "Training model 2743: (33,38) ...\n",
      "0.17331752200016126\n",
      "Training model 2744: (33,39) ...\n",
      "0.18923339800039685\n",
      "Training model 2745: (33,40) ...\n",
      "0.1352422659997501\n",
      "Training model 2746: (33,41) ...\n",
      "0.15360831999987568\n",
      "Training model 2747: (33,42) ...\n",
      "0.14470953299996836\n",
      "Training model 2748: (33,43) ...\n",
      "0.15611189599985664\n",
      "Training model 2749: (33,44) ...\n",
      "0.173299532999863\n",
      "Training model 2750: (33,45) ...\n",
      "0.16426716499972827\n",
      "Training model 2751: (33,46) ...\n",
      "0.12384888199994748\n",
      "Training model 2752: (33,47) ...\n",
      "0.1602697910002462\n",
      "Training model 2753: (33,48) ...\n",
      "0.1818673170000693\n",
      "Training model 2754: (33,49) ...\n",
      "0.1765455810000276\n",
      "Training model 2755: (33,50) ...\n",
      "0.19913160999976753\n",
      "Training model 2756: (33,51) ...\n",
      "0.1389388269999472\n",
      "Training model 2757: (33,52) ...\n",
      "0.13915425400000458\n",
      "Training model 2758: (33,53) ...\n",
      "0.16310152000005473\n",
      "Training model 2759: (33,54) ...\n",
      "0.19188066900005651\n",
      "Training model 2760: (33,55) ...\n",
      "0.12937909799984482\n",
      "Training model 2761: (33,56) ...\n",
      "0.1517853240002296\n",
      "Training model 2762: (33,57) ...\n",
      "0.1422939670001142\n",
      "Training model 2763: (33,58) ...\n",
      "0.22276946200008751\n",
      "Training model 2764: (33,59) ...\n",
      "0.1290744050002104\n",
      "Training model 2765: (33,60) ...\n",
      "0.19479967800043596\n",
      "Training model 2766: (33,61) ...\n",
      "0.17997867899975972\n",
      "Training model 2767: (33,62) ...\n",
      "0.20104292200039708\n",
      "Training model 2768: (33,63) ...\n",
      "0.17464635999976963\n",
      "Training model 2769: (33,64) ...\n",
      "0.1370968839996749\n",
      "Training model 2770: (33,65) ...\n",
      "0.29968768900016585\n",
      "Training model 2771: (33,66) ...\n",
      "0.16742063999981838\n",
      "Training model 2772: (33,67) ...\n",
      "0.18314790800013725\n",
      "Training model 2773: (33,68) ...\n",
      "0.18040454199990563\n",
      "Training model 2774: (33,69) ...\n",
      "0.15937229700011812\n",
      "Training model 2775: (33,70) ...\n",
      "0.11316227799989065\n",
      "Training model 2776: (33,71) ...\n",
      "0.19445637099988744\n",
      "Training model 2777: (33,72) ...\n",
      "0.11615174799999295\n",
      "Training model 2778: (33,73) ...\n",
      "0.1432794760003162\n",
      "Training model 2779: (33,74) ...\n",
      "0.11904736599990429\n",
      "Training model 2780: (33,75) ...\n",
      "0.12551317199995538\n",
      "Training model 2781: (33,76) ...\n",
      "0.1726813889999903\n",
      "Training model 2782: (33,77) ...\n",
      "0.15337997200003883\n",
      "Training model 2783: (33,78) ...\n",
      "0.147806644999946\n",
      "Training model 2784: (33,79) ...\n",
      "0.15304935199992542\n",
      "Training model 2785: (33,80) ...\n",
      "0.11818586299978051\n",
      "Training model 2786: (33,81) ...\n",
      "0.1396808909998981\n",
      "Training model 2787: (33,82) ...\n",
      "0.14384443700009797\n",
      "Training model 2788: (33,83) ...\n",
      "0.12372872300011295\n",
      "Training model 2789: (33,84) ...\n",
      "0.11694029800037242\n",
      "Training model 2790: (33,85) ...\n",
      "0.1350369619999583\n",
      "Training model 2791: (33,86) ...\n",
      "0.12734391200001483\n",
      "Training model 2792: (33,87) ...\n",
      "0.12236687099994015\n",
      "Training model 2793: (33,88) ...\n",
      "0.11920053200037728\n",
      "Training model 2794: (33,89) ...\n",
      "0.1294068970000808\n",
      "Training model 2795: (33,90) ...\n",
      "0.11378917699994417\n",
      "Training model 2796: (33,91) ...\n",
      "0.1272370429996954\n",
      "Training model 2797: (33,92) ...\n",
      "0.11855119899973943\n",
      "Training model 2798: (33,93) ...\n",
      "0.12918134999972608\n",
      "Training model 2799: (33,94) ...\n",
      "0.13454336799986777\n",
      "Training model 2800: (33,95) ...\n",
      "0.12306009100029769\n",
      "Training model 2801: (33,96) ...\n",
      "0.11832284499996604\n",
      "Training model 2802: (33,97) ...\n",
      "0.14736337499971341\n",
      "Training model 2803: (33,98) ...\n",
      "0.14576330199997756\n",
      "Training model 2804: (33,99) ...\n",
      "0.1362216239999725\n",
      "Training model 2805: (34,35) ...\n",
      "0.2488925089996883\n",
      "Training model 2806: (34,36) ...\n",
      "0.3049443240001892\n",
      "Training model 2807: (34,37) ...\n",
      "0.14977601700002197\n",
      "Training model 2808: (34,38) ...\n",
      "0.1938169499999276\n",
      "Training model 2809: (34,39) ...\n",
      "0.22434654200014847\n",
      "Training model 2810: (34,40) ...\n",
      "0.1254550260000542\n",
      "Training model 2811: (34,41) ...\n",
      "0.1926472290001584\n",
      "Training model 2812: (34,42) ...\n",
      "0.1765825849997782\n",
      "Training model 2813: (34,43) ...\n",
      "0.15966442800026925\n",
      "Training model 2814: (34,44) ...\n",
      "0.18687240200006272\n",
      "Training model 2815: (34,45) ...\n",
      "0.20341487800033065\n",
      "Training model 2816: (34,46) ...\n",
      "0.12568524599964803\n",
      "Training model 2817: (34,47) ...\n",
      "0.15701508800020747\n",
      "Training model 2818: (34,48) ...\n",
      "0.2086542950000876\n",
      "Training model 2819: (34,49) ...\n",
      "0.2492382400000679\n",
      "Training model 2820: (34,50) ...\n",
      "0.27742468899987216\n",
      "Training model 2821: (34,51) ...\n",
      "0.1393866049997996\n",
      "Training model 2822: (34,52) ...\n",
      "0.16310947900001338\n",
      "Training model 2823: (34,53) ...\n",
      "0.1973122039998998\n",
      "Training model 2824: (34,54) ...\n",
      "0.22885676200030503\n",
      "Training model 2825: (34,55) ...\n",
      "0.11972823199994309\n",
      "Training model 2826: (34,56) ...\n",
      "0.19533024299971657\n",
      "Training model 2827: (34,57) ...\n",
      "0.1752494949996617\n",
      "Training model 2828: (34,58) ...\n",
      "0.2306927680001536\n",
      "Training model 2829: (34,59) ...\n",
      "0.1219350769997618\n",
      "Training model 2830: (34,60) ...\n",
      "0.23633208899991587\n",
      "Training model 2831: (34,61) ...\n",
      "0.196887562000029\n",
      "Training model 2832: (34,62) ...\n",
      "0.23051854599998478\n",
      "Training model 2833: (34,63) ...\n",
      "0.18151660099965738\n",
      "Training model 2834: (34,64) ...\n",
      "0.12658574400029465\n",
      "Training model 2835: (34,65) ...\n",
      "0.24963328399962847\n",
      "Training model 2836: (34,66) ...\n",
      "0.2002486050000698\n",
      "Training model 2837: (34,67) ...\n",
      "0.24008185799993953\n",
      "Training model 2838: (34,68) ...\n",
      "0.20184574699987934\n",
      "Training model 2839: (34,69) ...\n",
      "0.1838408349999554\n",
      "Training model 2840: (34,70) ...\n",
      "0.1183671180001511\n",
      "Training model 2841: (34,71) ...\n",
      "0.20981047300028877\n",
      "Training model 2842: (34,72) ...\n",
      "0.10941823499979364\n",
      "Training model 2843: (34,73) ...\n",
      "0.1350302659998306\n",
      "Training model 2844: (34,74) ...\n",
      "0.11710937599991667\n",
      "Training model 2845: (34,75) ...\n",
      "0.14766086000008727\n",
      "Training model 2846: (34,76) ...\n",
      "0.18602452499999345\n",
      "Training model 2847: (34,77) ...\n",
      "0.15950899399967966\n",
      "Training model 2848: (34,78) ...\n",
      "0.15849927299996125\n",
      "Training model 2849: (34,79) ...\n",
      "0.14384834899965426\n",
      "Training model 2850: (34,80) ...\n",
      "0.15125271800025075\n",
      "Training model 2851: (34,81) ...\n",
      "0.1471871819999251\n",
      "Training model 2852: (34,82) ...\n",
      "0.15888492100020812\n",
      "Training model 2853: (34,83) ...\n",
      "0.12154014100042332\n",
      "Training model 2854: (34,84) ...\n",
      "0.14573286599988933\n",
      "Training model 2855: (34,85) ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.17373968699985198\n",
      "Training model 2856: (34,86) ...\n",
      "0.13293087400006698\n",
      "Training model 2857: (34,87) ...\n",
      "0.13354841799991846\n",
      "Training model 2858: (34,88) ...\n",
      "0.1187655030003043\n",
      "Training model 2859: (34,89) ...\n",
      "0.11779208300004029\n",
      "Training model 2860: (34,90) ...\n",
      "0.10874325900022086\n",
      "Training model 2861: (34,91) ...\n",
      "0.11662579799985906\n",
      "Training model 2862: (34,92) ...\n",
      "0.1111651740002344\n",
      "Training model 2863: (34,93) ...\n",
      "0.12835852700027317\n",
      "Training model 2864: (34,94) ...\n",
      "0.11731332099998326\n",
      "Training model 2865: (34,95) ...\n",
      "0.10835957699964638\n",
      "Training model 2866: (34,96) ...\n",
      "0.1111727659999815\n",
      "Training model 2867: (34,97) ...\n",
      "0.16366498000024876\n",
      "Training model 2868: (34,98) ...\n",
      "0.17848670100011077\n",
      "Training model 2869: (34,99) ...\n",
      "0.14794678299995212\n",
      "Training model 2870: (35,36) ...\n",
      "0.66182709099985\n",
      "Training model 2871: (35,37) ...\n",
      "0.49729068599981474\n",
      "Training model 2872: (35,38) ...\n",
      "0.1603790540002592\n",
      "Training model 2873: (35,39) ...\n",
      "0.19439411599978484\n",
      "Training model 2874: (35,40) ...\n",
      "0.12248721600008139\n",
      "Training model 2875: (35,41) ...\n",
      "0.1790226650000477\n",
      "Training model 2876: (35,42) ...\n",
      "0.15991026499978034\n",
      "Training model 2877: (35,43) ...\n",
      "0.17896860800010472\n",
      "Training model 2878: (35,44) ...\n",
      "0.20391589900009421\n",
      "Training model 2879: (35,45) ...\n",
      "0.16081576199985648\n",
      "Training model 2880: (35,46) ...\n",
      "0.12933785199993508\n",
      "Training model 2881: (35,47) ...\n",
      "0.16489727899988793\n",
      "Training model 2882: (35,48) ...\n",
      "0.16623847500022748\n",
      "Training model 2883: (35,49) ...\n",
      "0.1910533929999474\n",
      "Training model 2884: (35,50) ...\n",
      "0.20519920700007788\n",
      "Training model 2885: (35,51) ...\n",
      "0.13837434200013377\n",
      "Training model 2886: (35,52) ...\n",
      "0.16903387499996825\n",
      "Training model 2887: (35,53) ...\n",
      "0.1886573770002542\n",
      "Training model 2888: (35,54) ...\n",
      "0.233862247000161\n",
      "Training model 2889: (35,55) ...\n",
      "0.12643302099968423\n",
      "Training model 2890: (35,56) ...\n",
      "0.16306127999996534\n",
      "Training model 2891: (35,57) ...\n",
      "0.19327256699989448\n",
      "Training model 2892: (35,58) ...\n",
      "0.23396011199974964\n",
      "Training model 2893: (35,59) ...\n",
      "0.1305824080000093\n",
      "Training model 2894: (35,60) ...\n",
      "0.2582133020000583\n",
      "Training model 2895: (35,61) ...\n",
      "0.2071750449999854\n",
      "Training model 2896: (35,62) ...\n",
      "0.24677182400000675\n",
      "Training model 2897: (35,63) ...\n",
      "0.17439079500036314\n",
      "Training model 2898: (35,64) ...\n",
      "0.14326355699995474\n",
      "Training model 2899: (35,65) ...\n",
      "0.14128732199969818\n",
      "Training model 2900: (35,66) ...\n",
      "0.1651246770002217\n",
      "Training model 2901: (35,67) ...\n",
      "0.18815647100018396\n",
      "Training model 2902: (35,68) ...\n",
      "0.1975929459999861\n",
      "Training model 2903: (35,69) ...\n",
      "0.18192286500016053\n",
      "Training model 2904: (35,70) ...\n",
      "0.12173333999999159\n",
      "Training model 2905: (35,71) ...\n",
      "0.1914132619999691\n",
      "Training model 2906: (35,72) ...\n",
      "0.1119310859999132\n",
      "Training model 2907: (35,73) ...\n",
      "0.13117044199998418\n",
      "Training model 2908: (35,74) ...\n",
      "0.11515766700040331\n",
      "Training model 2909: (35,75) ...\n",
      "0.13023705099976723\n",
      "Training model 2910: (35,76) ...\n",
      "0.1702928059999067\n",
      "Training model 2911: (35,77) ...\n",
      "0.15629324500014263\n",
      "Training model 2912: (35,78) ...\n",
      "0.14094554700022854\n",
      "Training model 2913: (35,79) ...\n",
      "0.1477439109999068\n",
      "Training model 2914: (35,80) ...\n",
      "0.11994707499979995\n",
      "Training model 2915: (35,81) ...\n",
      "0.1244391230002293\n",
      "Training model 2916: (35,82) ...\n",
      "0.14060971400022027\n",
      "Training model 2917: (35,83) ...\n",
      "0.11882642799992027\n",
      "Training model 2918: (35,84) ...\n",
      "0.12144148400011545\n",
      "Training model 2919: (35,85) ...\n",
      "0.15391605100012384\n",
      "Training model 2920: (35,86) ...\n",
      "0.14021604900017337\n",
      "Training model 2921: (35,87) ...\n",
      "0.11711863300024561\n",
      "Training model 2922: (35,88) ...\n",
      "0.1185262019998845\n",
      "Training model 2923: (35,89) ...\n",
      "0.10943695200012371\n",
      "Training model 2924: (35,90) ...\n",
      "0.11372724300008485\n",
      "Training model 2925: (35,91) ...\n",
      "0.12885312000025806\n",
      "Training model 2926: (35,92) ...\n",
      "0.10706452200020067\n",
      "Training model 2927: (35,93) ...\n",
      "0.13060538299987456\n",
      "Training model 2928: (35,94) ...\n",
      "0.11932573300009608\n",
      "Training model 2929: (35,95) ...\n",
      "0.11181482900019546\n",
      "Training model 2930: (35,96) ...\n",
      "0.11679494000009072\n",
      "Training model 2931: (35,97) ...\n",
      "0.13384929000039847\n",
      "Training model 2932: (35,98) ...\n",
      "0.11123419900013687\n",
      "Training model 2933: (35,99) ...\n",
      "0.11899149900000339\n",
      "Training model 2934: (36,37) ...\n",
      "0.4714429820000987\n",
      "Training model 2935: (36,38) ...\n",
      "0.1869545869999456\n",
      "Training model 2936: (36,39) ...\n",
      "0.25836759699996037\n",
      "Training model 2937: (36,40) ...\n",
      "0.15683637299980546\n",
      "Training model 2938: (36,41) ...\n",
      "0.20007553699997516\n",
      "Training model 2939: (36,42) ...\n",
      "0.1917606590000105\n",
      "Training model 2940: (36,43) ...\n",
      "0.205532637000033\n",
      "Training model 2941: (36,44) ...\n",
      "0.21412413100006233\n",
      "Training model 2942: (36,45) ...\n",
      "0.18657554699984757\n",
      "Training model 2943: (36,46) ...\n",
      "0.17505190800011405\n",
      "Training model 2944: (36,47) ...\n",
      "0.2119325530002243\n",
      "Training model 2945: (36,48) ...\n",
      "0.23621287399964785\n",
      "Training model 2946: (36,49) ...\n",
      "0.2642186790003507\n",
      "Training model 2947: (36,50) ...\n",
      "0.2941453530002036\n",
      "Training model 2948: (36,51) ...\n",
      "0.16566950600008568\n",
      "Training model 2949: (36,52) ...\n",
      "0.1856860479997522\n",
      "Training model 2950: (36,53) ...\n",
      "0.22088617800000065\n",
      "Training model 2951: (36,54) ...\n",
      "0.26400751299979675\n",
      "Training model 2952: (36,55) ...\n",
      "0.15804791200025647\n",
      "Training model 2953: (36,56) ...\n",
      "0.20516787699989436\n",
      "Training model 2954: (36,57) ...\n",
      "0.20905168700028298\n",
      "Training model 2955: (36,58) ...\n",
      "0.29611626999985674\n",
      "Training model 2956: (36,59) ...\n",
      "0.15987947499979782\n",
      "Training model 2957: (36,60) ...\n",
      "0.2659278460000678\n",
      "Training model 2958: (36,61) ...\n",
      "0.24152276399991024\n",
      "Training model 2959: (36,62) ...\n",
      "0.2685019559999091\n",
      "Training model 2960: (36,63) ...\n",
      "0.2055527920001623\n",
      "Training model 2961: (36,64) ...\n",
      "0.17939641500015568\n",
      "Training model 2962: (36,65) ...\n",
      "0.18475239100007457\n",
      "Training model 2963: (36,66) ...\n",
      "0.20358724900006564\n",
      "Training model 2964: (36,67) ...\n",
      "0.2137418790002812\n",
      "Training model 2965: (36,68) ...\n",
      "0.21670675799987293\n",
      "Training model 2966: (36,69) ...\n",
      "0.19147819699992397\n",
      "Training model 2967: (36,70) ...\n",
      "0.13272019799978807\n",
      "Training model 2968: (36,71) ...\n",
      "0.2055004869998811\n",
      "Training model 2969: (36,72) ...\n",
      "0.12997105999966152\n",
      "Training model 2970: (36,73) ...\n",
      "0.1519858619999468\n",
      "Training model 2971: (36,74) ...\n",
      "0.14532081699962873\n",
      "Training model 2972: (36,75) ...\n",
      "0.14448702499976207\n",
      "Training model 2973: (36,76) ...\n",
      "0.1790265320000799\n",
      "Training model 2974: (36,77) ...\n",
      "0.16944759700027134\n",
      "Training model 2975: (36,78) ...\n",
      "0.16037413899994135\n",
      "Training model 2976: (36,79) ...\n",
      "0.17394137099972795\n",
      "Training model 2977: (36,80) ...\n",
      "0.1403554640000948\n",
      "Training model 2978: (36,81) ...\n",
      "0.16990332700015642\n",
      "Training model 2979: (36,82) ...\n",
      "0.19233101600002556\n",
      "Training model 2980: (36,83) ...\n",
      "0.14078498900016712\n",
      "Training model 2981: (36,84) ...\n",
      "0.15081950500007224\n",
      "Training model 2982: (36,85) ...\n",
      "0.18280056799994782\n",
      "Training model 2983: (36,86) ...\n",
      "0.16369227999985014\n",
      "Training model 2984: (36,87) ...\n",
      "0.14574971000001824\n",
      "Training model 2985: (36,88) ...\n",
      "0.14165830999991158\n",
      "Training model 2986: (36,89) ...\n",
      "0.12841977200014298\n",
      "Training model 2987: (36,90) ...\n",
      "0.14336877999994613\n",
      "Training model 2988: (36,91) ...\n",
      "0.14161300599971582\n",
      "Training model 2989: (36,92) ...\n",
      "0.12535542500017982\n",
      "Training model 2990: (36,93) ...\n",
      "0.14722564100020463\n",
      "Training model 2991: (36,94) ...\n",
      "0.14076687200031301\n",
      "Training model 2992: (36,95) ...\n",
      "0.12988874399979977\n",
      "Training model 2993: (36,96) ...\n",
      "0.12899912599959862\n",
      "Training model 2994: (36,97) ...\n",
      "0.16686591500001668\n",
      "Training model 2995: (36,98) ...\n",
      "0.16451981699992757\n",
      "Training model 2996: (36,99) ...\n",
      "0.16460774799998035\n",
      "Training model 2997: (37,38) ...\n",
      "0.14615736300038407\n",
      "Training model 2998: (37,39) ...\n",
      "0.1816626949998863\n",
      "Training model 2999: (37,40) ...\n",
      "0.11841801799982932\n",
      "Training model 3000: (37,41) ...\n",
      "0.17954477200009933\n",
      "Training model 3001: (37,42) ...\n",
      "0.15013292499997988\n",
      "Training model 3002: (37,43) ...\n",
      "0.15636611599984462\n",
      "Training model 3003: (37,44) ...\n",
      "0.18529374900026596\n",
      "Training model 3004: (37,45) ...\n",
      "0.16644660200017825\n",
      "Training model 3005: (37,46) ...\n",
      "0.13374641800010068\n",
      "Training model 3006: (37,47) ...\n",
      "0.1554594399999587\n",
      "Training model 3007: (37,48) ...\n",
      "0.14701954000020123\n",
      "Training model 3008: (37,49) ...\n",
      "0.15142557999979545\n",
      "Training model 3009: (37,50) ...\n",
      "0.16062302799991812\n",
      "Training model 3010: (37,51) ...\n",
      "0.12553866700000071\n",
      "Training model 3011: (37,52) ...\n",
      "0.1799896469997293\n",
      "Training model 3012: (37,53) ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.172185589000037\n",
      "Training model 3013: (37,54) ...\n",
      "0.23015386299994134\n",
      "Training model 3014: (37,55) ...\n",
      "0.12109477500007415\n",
      "Training model 3015: (37,56) ...\n",
      "0.17892227899983482\n",
      "Training model 3016: (37,57) ...\n",
      "0.18888508400004866\n",
      "Training model 3017: (37,58) ...\n",
      "0.1916334550001011\n",
      "Training model 3018: (37,59) ...\n",
      "0.12071813299962741\n",
      "Training model 3019: (37,60) ...\n",
      "0.20965530900002705\n",
      "Training model 3020: (37,61) ...\n",
      "0.18573393199994825\n",
      "Training model 3021: (37,62) ...\n",
      "0.22865737099982653\n",
      "Training model 3022: (37,63) ...\n",
      "0.16582696500017846\n",
      "Training model 3023: (37,64) ...\n",
      "0.13177649799990832\n",
      "Training model 3024: (37,65) ...\n",
      "0.13179571800037593\n",
      "Training model 3025: (37,66) ...\n",
      "0.1440193990001717\n",
      "Training model 3026: (37,67) ...\n",
      "0.18374299500010238\n",
      "Training model 3027: (37,68) ...\n",
      "0.16085971399979826\n",
      "Training model 3028: (37,69) ...\n",
      "0.16321678499980408\n",
      "Training model 3029: (37,70) ...\n",
      "0.1153600610000467\n",
      "Training model 3030: (37,71) ...\n",
      "0.18504044499968586\n",
      "Training model 3031: (37,72) ...\n",
      "0.10723770100003094\n",
      "Training model 3032: (37,73) ...\n",
      "0.11536868799976219\n",
      "Training model 3033: (37,74) ...\n",
      "0.1095736370002669\n",
      "Training model 3034: (37,75) ...\n",
      "0.1203018350001912\n",
      "Training model 3035: (37,76) ...\n",
      "0.16267984599971896\n",
      "Training model 3036: (37,77) ...\n",
      "0.1433839389997047\n",
      "Training model 3037: (37,78) ...\n",
      "0.13427441099975113\n",
      "Training model 3038: (37,79) ...\n",
      "0.16486670200038134\n",
      "Training model 3039: (37,80) ...\n",
      "0.10726629700002377\n",
      "Training model 3040: (37,81) ...\n",
      "0.12678315300036047\n",
      "Training model 3041: (37,82) ...\n",
      "0.15917533299989373\n",
      "Training model 3042: (37,83) ...\n",
      "0.12436800299974493\n",
      "Training model 3043: (37,84) ...\n",
      "0.12767478299974755\n",
      "Training model 3044: (37,85) ...\n",
      "0.1515097359997526\n",
      "Training model 3045: (37,86) ...\n",
      "0.1455081229996722\n",
      "Training model 3046: (37,87) ...\n",
      "0.10687095100001898\n",
      "Training model 3047: (37,88) ...\n",
      "0.11941219000027559\n",
      "Training model 3048: (37,89) ...\n",
      "0.1050092800001039\n",
      "Training model 3049: (37,90) ...\n",
      "0.11283972399996856\n",
      "Training model 3050: (37,91) ...\n",
      "0.1365642799996749\n",
      "Training model 3051: (37,92) ...\n",
      "0.1084717849998924\n",
      "Training model 3052: (37,93) ...\n",
      "0.12139031900005648\n",
      "Training model 3053: (37,94) ...\n",
      "0.11760103100004926\n",
      "Training model 3054: (37,95) ...\n",
      "0.11096397899973454\n",
      "Training model 3055: (37,96) ...\n",
      "0.11277894700015167\n",
      "Training model 3056: (37,97) ...\n",
      "0.1182773380000981\n",
      "Training model 3057: (37,98) ...\n",
      "0.10154787999999826\n",
      "Training model 3058: (37,99) ...\n",
      "0.1085509730000922\n",
      "Training model 3059: (38,39) ...\n",
      "0.1741666980001355\n",
      "Training model 3060: (38,40) ...\n",
      "0.17056831199988665\n",
      "Training model 3061: (38,41) ...\n",
      "0.3276194889999715\n",
      "Training model 3062: (38,42) ...\n",
      "0.2555194480000864\n",
      "Training model 3063: (38,43) ...\n",
      "0.21673265200024616\n",
      "Training model 3064: (38,44) ...\n",
      "0.3506069589998333\n",
      "Training model 3065: (38,45) ...\n",
      "0.22599940400004925\n",
      "Training model 3066: (38,46) ...\n",
      "0.16834325799982253\n",
      "Training model 3067: (38,47) ...\n",
      "0.27465851799979646\n",
      "Training model 3068: (38,48) ...\n",
      "0.14461002600000938\n",
      "Training model 3069: (38,49) ...\n",
      "0.19422666399987065\n",
      "Training model 3070: (38,50) ...\n",
      "0.14899080799978037\n",
      "Training model 3071: (38,51) ...\n",
      "0.1547712770002363\n",
      "Training model 3072: (38,52) ...\n",
      "0.23987353100028486\n",
      "Training model 3073: (38,53) ...\n",
      "0.24037533499995334\n",
      "Training model 3074: (38,54) ...\n",
      "0.3468729359997269\n",
      "Training model 3075: (38,55) ...\n",
      "0.14601315600020826\n",
      "Training model 3076: (38,56) ...\n",
      "0.24995192899996255\n",
      "Training model 3077: (38,57) ...\n",
      "0.21863555799973255\n",
      "Training model 3078: (38,58) ...\n",
      "0.2137684670001363\n",
      "Training model 3079: (38,59) ...\n",
      "0.1587627980002253\n",
      "Training model 3080: (38,60) ...\n",
      "0.4051522949998798\n",
      "Training model 3081: (38,61) ...\n",
      "0.2506949679996069\n",
      "Training model 3082: (38,62) ...\n",
      "0.3154996680000295\n",
      "Training model 3083: (38,63) ...\n",
      "0.22113790299999891\n",
      "Training model 3084: (38,64) ...\n",
      "0.1518744049999441\n",
      "Training model 3085: (38,65) ...\n",
      "0.2100083430000268\n",
      "Training model 3086: (38,66) ...\n",
      "0.34169990600003075\n",
      "Training model 3087: (38,67) ...\n",
      "0.2995192399998814\n",
      "Training model 3088: (38,68) ...\n",
      "0.3478833119997944\n",
      "Training model 3089: (38,69) ...\n",
      "0.1472754729998087\n",
      "Training model 3090: (38,70) ...\n",
      "0.13596132800012128\n",
      "Training model 3091: (38,71) ...\n",
      "0.265862929999912\n",
      "Training model 3092: (38,72) ...\n",
      "0.12137279900025533\n",
      "Training model 3093: (38,73) ...\n",
      "0.17244726600029026\n",
      "Training model 3094: (38,74) ...\n",
      "0.1271542130002672\n",
      "Training model 3095: (38,75) ...\n",
      "0.13050673099996857\n",
      "Training model 3096: (38,76) ...\n",
      "0.18809773400016638\n",
      "Training model 3097: (38,77) ...\n",
      "0.19330167600037385\n",
      "Training model 3098: (38,78) ...\n",
      "0.18962100299995654\n",
      "Training model 3099: (38,79) ...\n",
      "0.22850970199988296\n",
      "Training model 3100: (38,80) ...\n",
      "0.12254745300015202\n",
      "Training model 3101: (38,81) ...\n",
      "0.14314342200032115\n",
      "Training model 3102: (38,82) ...\n",
      "0.14778379100016537\n",
      "Training model 3103: (38,83) ...\n",
      "0.12855261400000018\n",
      "Training model 3104: (38,84) ...\n",
      "0.12424274400018476\n",
      "Training model 3105: (38,85) ...\n",
      "0.1510812569999871\n",
      "Training model 3106: (38,86) ...\n",
      "0.14834544199993616\n",
      "Training model 3107: (38,87) ...\n",
      "0.1169606900002691\n",
      "Training model 3108: (38,88) ...\n",
      "0.11525960600010876\n",
      "Training model 3109: (38,89) ...\n",
      "0.11428834999969695\n",
      "Training model 3110: (38,90) ...\n",
      "0.10962635900023088\n",
      "Training model 3111: (38,91) ...\n",
      "0.12200794699992912\n",
      "Training model 3112: (38,92) ...\n",
      "0.11651032700001451\n",
      "Training model 3113: (38,93) ...\n",
      "0.12484643300012976\n",
      "Training model 3114: (38,94) ...\n",
      "0.14903976599998714\n",
      "Training model 3115: (38,95) ...\n",
      "0.11164165900027001\n",
      "Training model 3116: (38,96) ...\n",
      "0.10993492800025706\n",
      "Training model 3117: (38,97) ...\n",
      "0.11432947100001911\n",
      "Training model 3118: (38,98) ...\n",
      "0.13010495500020625\n",
      "Training model 3119: (38,99) ...\n",
      "0.11865105200013204\n",
      "Training model 3120: (39,40) ...\n",
      "0.21921879299998182\n",
      "Training model 3121: (39,41) ...\n",
      "0.21943246600039856\n",
      "Training model 3122: (39,42) ...\n",
      "0.24984849700013\n",
      "Training model 3123: (39,43) ...\n",
      "0.28913133899959576\n",
      "Training model 3124: (39,44) ...\n",
      "0.27354603200001293\n",
      "Training model 3125: (39,45) ...\n",
      "0.20078317600018636\n",
      "Training model 3126: (39,46) ...\n",
      "0.28851503899977615\n",
      "Training model 3127: (39,47) ...\n",
      "0.30014403899986064\n",
      "Training model 3128: (39,48) ...\n",
      "0.40994229599982646\n",
      "Training model 3129: (39,49) ...\n",
      "0.30189074400004756\n",
      "Training model 3130: (39,50) ...\n",
      "0.3256686310000987\n",
      "Training model 3131: (39,51) ...\n",
      "0.19365129000016168\n",
      "Training model 3132: (39,52) ...\n",
      "0.17458673400005864\n",
      "Training model 3133: (39,53) ...\n",
      "0.19484167099972183\n",
      "Training model 3134: (39,54) ...\n",
      "0.24565595900003245\n",
      "Training model 3135: (39,55) ...\n",
      "0.2155517979999786\n",
      "Training model 3136: (39,56) ...\n",
      "0.19323445800000627\n",
      "Training model 3137: (39,57) ...\n",
      "0.2043548789997658\n",
      "Training model 3138: (39,58) ...\n",
      "0.25720458700016025\n",
      "Training model 3139: (39,59) ...\n",
      "0.20054953899989414\n",
      "Training model 3140: (39,60) ...\n",
      "0.22843204099990544\n",
      "Training model 3141: (39,61) ...\n",
      "0.24840372100015884\n",
      "Training model 3142: (39,62) ...\n",
      "0.27080569800000376\n",
      "Training model 3143: (39,63) ...\n",
      "0.22075188600001638\n",
      "Training model 3144: (39,64) ...\n",
      "0.22138145500002793\n",
      "Training model 3145: (39,65) ...\n",
      "0.16821449000008215\n",
      "Training model 3146: (39,66) ...\n",
      "0.19227109599978576\n",
      "Training model 3147: (39,67) ...\n",
      "0.23905952400036767\n",
      "Training model 3148: (39,68) ...\n",
      "0.20175037199987855\n",
      "Training model 3149: (39,69) ...\n",
      "0.17500409100011893\n",
      "Training model 3150: (39,70) ...\n",
      "0.14407358199969167\n",
      "Training model 3151: (39,71) ...\n",
      "0.16866613800038976\n",
      "Training model 3152: (39,72) ...\n",
      "0.14188766999996005\n",
      "Training model 3153: (39,73) ...\n",
      "0.1449953189999178\n",
      "Training model 3154: (39,74) ...\n",
      "0.14580158700027823\n",
      "Training model 3155: (39,75) ...\n",
      "0.1342216380003265\n",
      "Training model 3156: (39,76) ...\n",
      "0.18740589500021088\n",
      "Training model 3157: (39,77) ...\n",
      "0.18133409900019615\n",
      "Training model 3158: (39,78) ...\n",
      "0.14065601799984506\n",
      "Training model 3159: (39,79) ...\n",
      "0.16994233100012934\n",
      "Training model 3160: (39,80) ...\n",
      "0.1502057769998828\n",
      "Training model 3161: (39,81) ...\n",
      "0.19207792699990023\n",
      "Training model 3162: (39,82) ...\n",
      "0.19950788500000272\n",
      "Training model 3163: (39,83) ...\n",
      "0.1533099719999882\n",
      "Training model 3164: (39,84) ...\n",
      "0.1797834540002441\n",
      "Training model 3165: (39,85) ...\n",
      "0.22462121500029752\n",
      "Training model 3166: (39,86) ...\n",
      "0.18519121099961922\n",
      "Training model 3167: (39,87) ...\n",
      "0.14995916099996975\n",
      "Training model 3168: (39,88) ...\n",
      "0.14715150800020638\n",
      "Training model 3169: (39,89) ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1365419940002539\n",
      "Training model 3170: (39,90) ...\n",
      "0.14387030700027026\n",
      "Training model 3171: (39,91) ...\n",
      "0.16632422000020597\n",
      "Training model 3172: (39,92) ...\n",
      "0.13686758400035615\n",
      "Training model 3173: (39,93) ...\n",
      "0.17198550900002374\n",
      "Training model 3174: (39,94) ...\n",
      "0.16132396300008622\n",
      "Training model 3175: (39,95) ...\n",
      "0.1476282040002843\n",
      "Training model 3176: (39,96) ...\n",
      "0.14942743900019195\n",
      "Training model 3177: (39,97) ...\n",
      "0.15255974699994113\n",
      "Training model 3178: (39,98) ...\n",
      "0.13303712399965661\n",
      "Training model 3179: (39,99) ...\n",
      "0.1632147969999096\n",
      "Training model 3180: (40,41) ...\n",
      "0.15672211099990818\n",
      "Training model 3181: (40,42) ...\n",
      "0.18476853599986498\n",
      "Training model 3182: (40,43) ...\n",
      "0.16992656100001113\n",
      "Training model 3183: (40,44) ...\n",
      "0.17700150700011363\n",
      "Training model 3184: (40,45) ...\n",
      "0.11560047200009649\n",
      "Training model 3185: (40,46) ...\n",
      "1.0069556290000037\n",
      "Training model 3186: (40,47) ...\n",
      "0.30086218399992504\n",
      "Training model 3187: (40,48) ...\n",
      "0.1295477070002562\n",
      "Training model 3188: (40,49) ...\n",
      "0.1297035729999152\n",
      "Training model 3189: (40,50) ...\n",
      "0.1356720169997061\n",
      "Training model 3190: (40,51) ...\n",
      "0.11593345900018903\n",
      "Training model 3191: (40,52) ...\n",
      "0.1727685810001276\n",
      "Training model 3192: (40,53) ...\n",
      "0.18437704699999813\n",
      "Training model 3193: (40,54) ...\n",
      "0.15609786400000303\n",
      "Training model 3194: (40,55) ...\n",
      "0.41667304600014177\n",
      "Training model 3195: (40,56) ...\n",
      "0.12202570099998411\n",
      "Training model 3196: (40,57) ...\n",
      "0.14182020799989914\n",
      "Training model 3197: (40,58) ...\n",
      "0.16703816200015353\n",
      "Training model 3198: (40,59) ...\n",
      "0.4810828700001366\n",
      "Training model 3199: (40,60) ...\n",
      "0.17393740299985438\n",
      "Training model 3200: (40,61) ...\n",
      "0.142892417999974\n",
      "Training model 3201: (40,62) ...\n",
      "0.14874880299976212\n",
      "Training model 3202: (40,63) ...\n",
      "0.1466538770000625\n",
      "Training model 3203: (40,64) ...\n",
      "0.34611238600018623\n",
      "Training model 3204: (40,65) ...\n",
      "0.137338052999894\n",
      "Training model 3205: (40,66) ...\n",
      "0.1346567049999976\n",
      "Training model 3206: (40,67) ...\n",
      "0.13524418499991953\n",
      "Training model 3207: (40,68) ...\n",
      "0.1298280609998983\n",
      "Training model 3208: (40,69) ...\n",
      "0.1107891589999781\n",
      "Training model 3209: (40,70) ...\n",
      "0.17674901500004125\n",
      "Training model 3210: (40,71) ...\n",
      "0.1492384419998416\n",
      "Training model 3211: (40,72) ...\n",
      "0.14092705799976102\n",
      "Training model 3212: (40,73) ...\n",
      "0.13669923400038897\n",
      "Training model 3213: (40,74) ...\n",
      "0.14126863899991804\n",
      "Training model 3214: (40,75) ...\n",
      "0.1307819250000648\n",
      "Training model 3215: (40,76) ...\n",
      "0.1323724349999793\n",
      "Training model 3216: (40,77) ...\n",
      "0.1744428209999569\n",
      "Training model 3217: (40,78) ...\n",
      "0.16026310100005503\n",
      "Training model 3218: (40,79) ...\n",
      "0.14271230299982562\n",
      "Training model 3219: (40,80) ...\n",
      "0.1179027580001275\n",
      "Training model 3220: (40,81) ...\n",
      "0.11820115400041686\n",
      "Training model 3221: (40,82) ...\n",
      "0.1342370669999582\n",
      "Training model 3222: (40,83) ...\n",
      "0.11318082500019955\n",
      "Training model 3223: (40,84) ...\n",
      "0.13047795299962672\n",
      "Training model 3224: (40,85) ...\n",
      "0.14372850000017934\n",
      "Training model 3225: (40,86) ...\n",
      "0.1307293570002912\n",
      "Training model 3226: (40,87) ...\n",
      "0.1201273689998743\n",
      "Training model 3227: (40,88) ...\n",
      "0.1337196499998754\n",
      "Training model 3228: (40,89) ...\n",
      "0.1233499390000361\n",
      "Training model 3229: (40,90) ...\n",
      "0.129079386000285\n",
      "Training model 3230: (40,91) ...\n",
      "0.1480148979999285\n",
      "Training model 3231: (40,92) ...\n",
      "0.16352909699980955\n",
      "Training model 3232: (40,93) ...\n",
      "0.13706571800003076\n",
      "Training model 3233: (40,94) ...\n",
      "0.19367305600007967\n",
      "Training model 3234: (40,95) ...\n",
      "0.1634887670002172\n",
      "Training model 3235: (40,96) ...\n",
      "0.13666095400003542\n",
      "Training model 3236: (40,97) ...\n",
      "0.11316890399984914\n",
      "Training model 3237: (40,98) ...\n",
      "0.10744666900018274\n",
      "Training model 3238: (40,99) ...\n",
      "0.11894369499987079\n",
      "Training model 3239: (41,42) ...\n",
      "0.2961821119997694\n",
      "Training model 3240: (41,43) ...\n",
      "0.2002016400001594\n",
      "Training model 3241: (41,44) ...\n",
      "0.6399649159998262\n",
      "Training model 3242: (41,45) ...\n",
      "0.23946787199975006\n",
      "Training model 3243: (41,46) ...\n",
      "0.18095045600011872\n",
      "Training model 3244: (41,47) ...\n",
      "0.22978715199997168\n",
      "Training model 3245: (41,48) ...\n",
      "0.17581097700031023\n",
      "Training model 3246: (41,49) ...\n",
      "0.24359253500006162\n",
      "Training model 3247: (41,50) ...\n",
      "0.20262226300019393\n",
      "Training model 3248: (41,51) ...\n",
      "0.12544386099989424\n",
      "Training model 3249: (41,52) ...\n",
      "0.3121682119999605\n",
      "Training model 3250: (41,53) ...\n",
      "0.25876964300005056\n",
      "Training model 3251: (41,54) ...\n",
      "0.439324809000027\n",
      "Training model 3252: (41,55) ...\n",
      "0.14529727499984801\n",
      "Training model 3253: (41,56) ...\n",
      "0.2500086449999799\n",
      "Training model 3254: (41,57) ...\n",
      "0.3969212399997559\n",
      "Training model 3255: (41,58) ...\n",
      "0.28805533299964736\n",
      "Training model 3256: (41,59) ...\n",
      "0.16798030100017058\n",
      "Training model 3257: (41,60) ...\n",
      "0.49323703899972315\n",
      "Training model 3258: (41,61) ...\n",
      "0.24407160400005523\n",
      "Training model 3259: (41,62) ...\n",
      "0.36587079900027675\n",
      "Training model 3260: (41,63) ...\n",
      "0.23206250200018985\n",
      "Training model 3261: (41,64) ...\n",
      "0.15727441200033354\n",
      "Training model 3262: (41,65) ...\n",
      "0.19018301599999177\n",
      "Training model 3263: (41,66) ...\n",
      "0.3186415429995577\n",
      "Training model 3264: (41,67) ...\n",
      "0.4222333169996091\n",
      "Training model 3265: (41,68) ...\n",
      "0.3829572269996788\n",
      "Training model 3266: (41,69) ...\n",
      "0.16381550000005518\n",
      "Training model 3267: (41,70) ...\n",
      "0.14341340300006777\n",
      "Training model 3268: (41,71) ...\n",
      "0.2472938079999949\n",
      "Training model 3269: (41,72) ...\n",
      "0.12476405999996132\n",
      "Training model 3270: (41,73) ...\n",
      "0.1453083679998599\n",
      "Training model 3271: (41,74) ...\n",
      "0.11940689499988366\n",
      "Training model 3272: (41,75) ...\n",
      "0.1418723570000111\n",
      "Training model 3273: (41,76) ...\n",
      "0.21141641900021568\n",
      "Training model 3274: (41,77) ...\n",
      "0.22392700199998217\n",
      "Training model 3275: (41,78) ...\n",
      "0.1388423469998088\n",
      "Training model 3276: (41,79) ...\n",
      "0.23419305600009466\n",
      "Training model 3277: (41,80) ...\n",
      "0.12710634599989135\n",
      "Training model 3278: (41,81) ...\n",
      "0.1608415870000499\n",
      "Training model 3279: (41,82) ...\n",
      "0.18609549200027686\n",
      "Training model 3280: (41,83) ...\n",
      "0.14586203199996817\n",
      "Training model 3281: (41,84) ...\n",
      "0.13467016200002035\n",
      "Training model 3282: (41,85) ...\n",
      "0.19499752499996248\n",
      "Training model 3283: (41,86) ...\n",
      "0.1696587599999475\n",
      "Training model 3284: (41,87) ...\n",
      "0.10782246600001599\n",
      "Training model 3285: (41,88) ...\n",
      "0.11371647699979803\n",
      "Training model 3286: (41,89) ...\n",
      "0.11390979799989509\n",
      "Training model 3287: (41,90) ...\n",
      "0.11457346099996357\n",
      "Training model 3288: (41,91) ...\n",
      "0.14685227700010728\n",
      "Training model 3289: (41,92) ...\n",
      "0.12019220799993491\n",
      "Training model 3290: (41,93) ...\n",
      "0.13246244599986312\n",
      "Training model 3291: (41,94) ...\n",
      "0.1256124080000518\n",
      "Training model 3292: (41,95) ...\n",
      "0.11702541399972688\n",
      "Training model 3293: (41,96) ...\n",
      "0.11897718999989593\n",
      "Training model 3294: (41,97) ...\n",
      "0.12480420499969114\n",
      "Training model 3295: (41,98) ...\n",
      "0.1165822160000971\n",
      "Training model 3296: (41,99) ...\n",
      "0.12630425699990155\n",
      "Training model 3297: (42,43) ...\n",
      "0.262650288000259\n",
      "Training model 3298: (42,44) ...\n",
      "0.28443080399983955\n",
      "Training model 3299: (42,45) ...\n",
      "0.19309182699998928\n",
      "Training model 3300: (42,46) ...\n",
      "0.1671153680003954\n",
      "Training model 3301: (42,47) ...\n",
      "0.18868929400014167\n",
      "Training model 3302: (42,48) ...\n",
      "0.18123642199998358\n",
      "Training model 3303: (42,49) ...\n",
      "0.21998654199978773\n",
      "Training model 3304: (42,50) ...\n",
      "0.19907496999985597\n",
      "Training model 3305: (42,51) ...\n",
      "0.1298871170001803\n",
      "Training model 3306: (42,52) ...\n",
      "0.21327566399986608\n",
      "Training model 3307: (42,53) ...\n",
      "0.22753237100005208\n",
      "Training model 3308: (42,54) ...\n",
      "0.2711148010002944\n",
      "Training model 3309: (42,55) ...\n",
      "0.13418365699999413\n",
      "Training model 3310: (42,56) ...\n",
      "0.17690156599974216\n",
      "Training model 3311: (42,57) ...\n",
      "0.19865224100021805\n",
      "Training model 3312: (42,58) ...\n",
      "0.2363305459998628\n",
      "Training model 3313: (42,59) ...\n",
      "0.15585623199967813\n",
      "Training model 3314: (42,60) ...\n",
      "0.2658638030002294\n",
      "Training model 3315: (42,61) ...\n",
      "0.21257032899984551\n",
      "Training model 3316: (42,62) ...\n",
      "0.25321068699986427\n",
      "Training model 3317: (42,63) ...\n",
      "0.19962700199994288\n",
      "Training model 3318: (42,64) ...\n",
      "0.15027240399967923\n",
      "Training model 3319: (42,65) ...\n",
      "0.1819848909999564\n",
      "Training model 3320: (42,66) ...\n",
      "0.24207053600002837\n",
      "Training model 3321: (42,67) ...\n",
      "0.2157107449997966\n",
      "Training model 3322: (42,68) ...\n",
      "0.2502187810000578\n",
      "Training model 3323: (42,69) ...\n",
      "0.1536067379997803\n",
      "Training model 3324: (42,70) ...\n",
      "0.14258185499966203\n",
      "Training model 3325: (42,71) ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.20148450199985746\n",
      "Training model 3326: (42,72) ...\n",
      "0.13348765999990064\n",
      "Training model 3327: (42,73) ...\n",
      "0.15176703699989957\n",
      "Training model 3328: (42,74) ...\n",
      "0.13075521199971263\n",
      "Training model 3329: (42,75) ...\n",
      "0.1416850640002849\n",
      "Training model 3330: (42,76) ...\n",
      "0.18504627100037396\n",
      "Training model 3331: (42,77) ...\n",
      "0.20347784300020066\n",
      "Training model 3332: (42,78) ...\n",
      "0.14552165599980071\n",
      "Training model 3333: (42,79) ...\n",
      "0.1867035529999157\n",
      "Training model 3334: (42,80) ...\n",
      "0.1410280239997519\n",
      "Training model 3335: (42,81) ...\n",
      "0.17933012399998915\n",
      "Training model 3336: (42,82) ...\n",
      "0.17811219099985465\n",
      "Training model 3337: (42,83) ...\n",
      "0.14594517300020016\n",
      "Training model 3338: (42,84) ...\n",
      "0.15405797099992924\n",
      "Training model 3339: (42,85) ...\n",
      "0.1868146270003308\n",
      "Training model 3340: (42,86) ...\n",
      "0.16415937799956737\n",
      "Training model 3341: (42,87) ...\n",
      "0.1219913899999483\n",
      "Training model 3342: (42,88) ...\n",
      "0.13056628499998624\n",
      "Training model 3343: (42,89) ...\n",
      "0.11874576499985778\n",
      "Training model 3344: (42,90) ...\n",
      "0.13066059399989172\n",
      "Training model 3345: (42,91) ...\n",
      "0.16588795699999537\n",
      "Training model 3346: (42,92) ...\n",
      "0.15603014400039683\n",
      "Training model 3347: (42,93) ...\n",
      "0.14550836999978856\n",
      "Training model 3348: (42,94) ...\n",
      "0.14646968700026264\n",
      "Training model 3349: (42,95) ...\n",
      "0.13205310700004702\n",
      "Training model 3350: (42,96) ...\n",
      "0.1272003100002621\n",
      "Training model 3351: (42,97) ...\n",
      "0.1338844080000854\n",
      "Training model 3352: (42,98) ...\n",
      "0.12404881400016166\n",
      "Training model 3353: (42,99) ...\n",
      "0.12664773699998477\n",
      "Training model 3354: (43,44) ...\n",
      "0.22288263799964625\n",
      "Training model 3355: (43,45) ...\n",
      "0.15773434599987013\n",
      "Training model 3356: (43,46) ...\n",
      "0.17412207899997156\n",
      "Training model 3357: (43,47) ...\n",
      "0.23649583299993537\n",
      "Training model 3358: (43,48) ...\n",
      "0.20481034399972486\n",
      "Training model 3359: (43,49) ...\n",
      "0.19184264400018947\n",
      "Training model 3360: (43,50) ...\n",
      "0.19017941200036148\n",
      "Training model 3361: (43,51) ...\n",
      "0.20526718000019173\n",
      "Training model 3362: (43,52) ...\n",
      "0.16578013399976044\n",
      "Training model 3363: (43,53) ...\n",
      "0.16092485999979544\n",
      "Training model 3364: (43,54) ...\n",
      "0.21825937100038573\n",
      "Training model 3365: (43,55) ...\n",
      "0.1412982860001648\n",
      "Training model 3366: (43,56) ...\n",
      "0.1630304929999511\n",
      "Training model 3367: (43,57) ...\n",
      "0.16885135699976672\n",
      "Training model 3368: (43,58) ...\n",
      "0.19507716300040556\n",
      "Training model 3369: (43,59) ...\n",
      "0.14491456699988703\n",
      "Training model 3370: (43,60) ...\n",
      "0.25633196799981306\n",
      "Training model 3371: (43,61) ...\n",
      "0.21288834999995743\n",
      "Training model 3372: (43,62) ...\n",
      "0.2708855239998229\n",
      "Training model 3373: (43,63) ...\n",
      "0.24702540699991005\n",
      "Training model 3374: (43,64) ...\n",
      "0.15493536800022412\n",
      "Training model 3375: (43,65) ...\n",
      "0.14165802999968946\n",
      "Training model 3376: (43,66) ...\n",
      "0.22021674200004782\n",
      "Training model 3377: (43,67) ...\n",
      "0.19801510199977201\n",
      "Training model 3378: (43,68) ...\n",
      "0.2194940160002261\n",
      "Training model 3379: (43,69) ...\n",
      "0.15329787399969064\n",
      "Training model 3380: (43,70) ...\n",
      "0.1336261229998854\n",
      "Training model 3381: (43,71) ...\n",
      "0.18918329500002073\n",
      "Training model 3382: (43,72) ...\n",
      "0.12135916699980953\n",
      "Training model 3383: (43,73) ...\n",
      "0.15909796599999027\n",
      "Training model 3384: (43,74) ...\n",
      "0.1359939859999031\n",
      "Training model 3385: (43,75) ...\n",
      "0.13356923800029108\n",
      "Training model 3386: (43,76) ...\n",
      "0.20155088499996054\n",
      "Training model 3387: (43,77) ...\n",
      "0.1932566460000089\n",
      "Training model 3388: (43,78) ...\n",
      "0.1500866770002176\n",
      "Training model 3389: (43,79) ...\n",
      "0.15717341900017345\n",
      "Training model 3390: (43,80) ...\n",
      "0.15504508100002568\n",
      "Training model 3391: (43,81) ...\n",
      "0.1487618230003136\n",
      "Training model 3392: (43,82) ...\n",
      "0.1976986869999564\n",
      "Training model 3393: (43,83) ...\n",
      "0.15480786799980706\n",
      "Training model 3394: (43,84) ...\n",
      "0.14562602200021502\n",
      "Training model 3395: (43,85) ...\n",
      "0.17566638600010265\n",
      "Training model 3396: (43,86) ...\n",
      "0.1677511630000481\n",
      "Training model 3397: (43,87) ...\n",
      "0.13943250900001658\n",
      "Training model 3398: (43,88) ...\n",
      "0.1311624249997294\n",
      "Training model 3399: (43,89) ...\n",
      "0.12135424799998873\n",
      "Training model 3400: (43,90) ...\n",
      "0.12463162600033684\n",
      "Training model 3401: (43,91) ...\n",
      "0.15739966299997832\n",
      "Training model 3402: (43,92) ...\n",
      "0.12987887500003126\n",
      "Training model 3403: (43,93) ...\n",
      "0.15157015700015108\n",
      "Training model 3404: (43,94) ...\n",
      "0.14216347100000348\n",
      "Training model 3405: (43,95) ...\n",
      "0.14631743300014932\n",
      "Training model 3406: (43,96) ...\n",
      "0.12453718999995544\n",
      "Training model 3407: (43,97) ...\n",
      "0.12948006499982512\n",
      "Training model 3408: (43,98) ...\n",
      "0.12605291499994564\n",
      "Training model 3409: (43,99) ...\n",
      "0.12490791500022169\n",
      "Training model 3410: (44,45) ...\n",
      "0.23338866600033725\n",
      "Training model 3411: (44,46) ...\n",
      "0.1928320709998843\n",
      "Training model 3412: (44,47) ...\n",
      "0.26231909399984943\n",
      "Training model 3413: (44,48) ...\n",
      "0.20188228000006347\n",
      "Training model 3414: (44,49) ...\n",
      "0.30107755300014105\n",
      "Training model 3415: (44,50) ...\n",
      "0.2788229190000493\n",
      "Training model 3416: (44,51) ...\n",
      "0.14673484500008271\n",
      "Training model 3417: (44,52) ...\n",
      "0.36649222400001236\n",
      "Training model 3418: (44,53) ...\n",
      "0.29895168099983493\n",
      "Training model 3419: (44,54) ...\n",
      "0.5101717659999849\n",
      "Training model 3420: (44,55) ...\n",
      "0.1571679899998344\n",
      "Training model 3421: (44,56) ...\n",
      "0.2546477910000249\n",
      "Training model 3422: (44,57) ...\n",
      "0.4373203250002007\n",
      "Training model 3423: (44,58) ...\n",
      "0.3671725740000511\n",
      "Training model 3424: (44,59) ...\n",
      "0.17492455599995083\n",
      "Training model 3425: (44,60) ...\n",
      "0.4978163000000677\n",
      "Training model 3426: (44,61) ...\n",
      "0.29006546600021466\n",
      "Training model 3427: (44,62) ...\n",
      "0.396064834000299\n",
      "Training model 3428: (44,63) ...\n",
      "0.23604849899993496\n",
      "Training model 3429: (44,64) ...\n",
      "0.18496071500021571\n",
      "Training model 3430: (44,65) ...\n",
      "0.2293371920000027\n",
      "Training model 3431: (44,66) ...\n",
      "0.31405522300019584\n",
      "Training model 3432: (44,67) ...\n",
      "0.3786645929999395\n",
      "Training model 3433: (44,68) ...\n",
      "0.3296230129999458\n",
      "Training model 3434: (44,69) ...\n",
      "0.17607126799975958\n",
      "Training model 3435: (44,70) ...\n",
      "0.18815309899991917\n",
      "Training model 3436: (44,71) ...\n",
      "0.2976851970001917\n",
      "Training model 3437: (44,72) ...\n",
      "0.13025261099983254\n",
      "Training model 3438: (44,73) ...\n",
      "0.15485106799997084\n",
      "Training model 3439: (44,74) ...\n",
      "0.13956624999991618\n",
      "Training model 3440: (44,75) ...\n",
      "0.1435845959999824\n",
      "Training model 3441: (44,76) ...\n",
      "0.2030446240000856\n",
      "Training model 3442: (44,77) ...\n",
      "0.23628257199970903\n",
      "Training model 3443: (44,78) ...\n",
      "0.18448521099981008\n",
      "Training model 3444: (44,79) ...\n",
      "0.33949913100013873\n",
      "Training model 3445: (44,80) ...\n",
      "0.12204500699999699\n",
      "Training model 3446: (44,81) ...\n",
      "0.16238846300029763\n",
      "Training model 3447: (44,82) ...\n",
      "0.17940615099996648\n",
      "Training model 3448: (44,83) ...\n",
      "0.13155426599996645\n",
      "Training model 3449: (44,84) ...\n",
      "0.1345739789999243\n",
      "Training model 3450: (44,85) ...\n",
      "0.17009438400009458\n",
      "Training model 3451: (44,86) ...\n",
      "0.16007060899983117\n",
      "Training model 3452: (44,87) ...\n",
      "0.12160364300007132\n",
      "Training model 3453: (44,88) ...\n",
      "0.11951772199972766\n",
      "Training model 3454: (44,89) ...\n",
      "0.12118162900014795\n",
      "Training model 3455: (44,90) ...\n",
      "0.11796327999991263\n",
      "Training model 3456: (44,91) ...\n",
      "0.14055605799967452\n",
      "Training model 3457: (44,92) ...\n",
      "0.1263026059996264\n",
      "Training model 3458: (44,93) ...\n",
      "0.13830313400012528\n",
      "Training model 3459: (44,94) ...\n",
      "0.1383865039997545\n",
      "Training model 3460: (44,95) ...\n",
      "0.13151739300019472\n",
      "Training model 3461: (44,96) ...\n",
      "0.12334726400013096\n",
      "Training model 3462: (44,97) ...\n",
      "0.11523831999966205\n",
      "Training model 3463: (44,98) ...\n",
      "0.11133899800006475\n",
      "Training model 3464: (44,99) ...\n",
      "0.13179040999966674\n",
      "Training model 3465: (45,46) ...\n",
      "0.12636177600006704\n",
      "Training model 3466: (45,47) ...\n",
      "0.18062582999982624\n",
      "Training model 3467: (45,48) ...\n",
      "0.18541950500002713\n",
      "Training model 3468: (45,49) ...\n",
      "0.26791437499969106\n",
      "Training model 3469: (45,50) ...\n",
      "0.22109576200000447\n",
      "Training model 3470: (45,51) ...\n",
      "0.11882291800020539\n",
      "Training model 3471: (45,52) ...\n",
      "0.1566589539997949\n",
      "Training model 3472: (45,53) ...\n",
      "0.16882273200008058\n",
      "Training model 3473: (45,54) ...\n",
      "0.34985660199981794\n",
      "Training model 3474: (45,55) ...\n",
      "0.11349514900030044\n",
      "Training model 3475: (45,56) ...\n",
      "0.23722868799995922\n",
      "Training model 3476: (45,57) ...\n",
      "0.16908800700002757\n",
      "Training model 3477: (45,58) ...\n",
      "0.21525257100029194\n",
      "Training model 3478: (45,59) ...\n",
      "0.12891665699999066\n",
      "Training model 3479: (45,60) ...\n",
      "0.32818371900020793\n",
      "Training model 3480: (45,61) ...\n",
      "0.2267536360000122\n",
      "Training model 3481: (45,62) ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.29880478199993377\n",
      "Training model 3482: (45,63) ...\n",
      "0.1765878259998317\n",
      "Training model 3483: (45,64) ...\n",
      "0.13874031100021966\n",
      "Training model 3484: (45,65) ...\n",
      "0.18594041400001515\n",
      "Training model 3485: (45,66) ...\n",
      "0.24342708799986212\n",
      "Training model 3486: (45,67) ...\n",
      "0.3621383740000965\n",
      "Training model 3487: (45,68) ...\n",
      "0.28042733700021927\n",
      "Training model 3488: (45,69) ...\n",
      "0.1665922249999312\n",
      "Training model 3489: (45,70) ...\n",
      "0.1160288619998937\n",
      "Training model 3490: (45,71) ...\n",
      "0.18182252199994764\n",
      "Training model 3491: (45,72) ...\n",
      "0.10257999100031157\n",
      "Training model 3492: (45,73) ...\n",
      "0.12977322400001867\n",
      "Training model 3493: (45,74) ...\n",
      "0.11050355500037767\n",
      "Training model 3494: (45,75) ...\n",
      "0.12096489499981544\n",
      "Training model 3495: (45,76) ...\n",
      "0.1859102600001279\n",
      "Training model 3496: (45,77) ...\n",
      "0.1656831210002565\n",
      "Training model 3497: (45,78) ...\n",
      "0.1323654030002217\n",
      "Training model 3498: (45,79) ...\n",
      "0.1779375269998127\n",
      "Training model 3499: (45,80) ...\n",
      "0.122056813999734\n",
      "Training model 3500: (45,81) ...\n",
      "0.16470147999962137\n",
      "Training model 3501: (45,82) ...\n",
      "0.16496563900000183\n",
      "Training model 3502: (45,83) ...\n",
      "0.12422964300003514\n",
      "Training model 3503: (45,84) ...\n",
      "0.12550622400021894\n",
      "Training model 3504: (45,85) ...\n",
      "0.17530967799984865\n",
      "Training model 3505: (45,86) ...\n",
      "0.14981271100032245\n",
      "Training model 3506: (45,87) ...\n",
      "0.10952768900006049\n",
      "Training model 3507: (45,88) ...\n",
      "0.10732373600012579\n",
      "Training model 3508: (45,89) ...\n",
      "0.10163816100020995\n",
      "Training model 3509: (45,90) ...\n",
      "0.10468569800013938\n",
      "Training model 3510: (45,91) ...\n",
      "0.11853220000011788\n",
      "Training model 3511: (45,92) ...\n",
      "0.10565462400018077\n",
      "Training model 3512: (45,93) ...\n",
      "0.12302763299976505\n",
      "Training model 3513: (45,94) ...\n",
      "0.11229070399986085\n",
      "Training model 3514: (45,95) ...\n",
      "0.10078927900030976\n",
      "Training model 3515: (45,96) ...\n",
      "0.11106502700022247\n",
      "Training model 3516: (45,97) ...\n",
      "0.11184599199987133\n",
      "Training model 3517: (45,98) ...\n",
      "0.10482531300021947\n",
      "Training model 3518: (45,99) ...\n",
      "0.11502800300013405\n",
      "Training model 3519: (46,47) ...\n",
      "0.3648115780001717\n",
      "Training model 3520: (46,48) ...\n",
      "0.1552833340001598\n",
      "Training model 3521: (46,49) ...\n",
      "0.16573130500000843\n",
      "Training model 3522: (46,50) ...\n",
      "0.167199454999718\n",
      "Training model 3523: (46,51) ...\n",
      "0.11964665300001798\n",
      "Training model 3524: (46,52) ...\n",
      "0.1545846200001506\n",
      "Training model 3525: (46,53) ...\n",
      "0.15618815400011954\n",
      "Training model 3526: (46,54) ...\n",
      "0.17535811700008708\n",
      "Training model 3527: (46,55) ...\n",
      "0.4576806019999822\n",
      "Training model 3528: (46,56) ...\n",
      "0.13370746000009603\n",
      "Training model 3529: (46,57) ...\n",
      "0.17921968900009233\n",
      "Training model 3530: (46,58) ...\n",
      "0.20937995900021633\n",
      "Training model 3531: (46,59) ...\n",
      "0.470844550000038\n",
      "Training model 3532: (46,60) ...\n",
      "0.19062659000019266\n",
      "Training model 3533: (46,61) ...\n",
      "0.1553272209998795\n",
      "Training model 3534: (46,62) ...\n",
      "0.18427332700002808\n",
      "Training model 3535: (46,63) ...\n",
      "0.15115868900011264\n",
      "Training model 3536: (46,64) ...\n",
      "0.3913760179998462\n",
      "Training model 3537: (46,65) ...\n",
      "0.1349755900000673\n",
      "Training model 3538: (46,66) ...\n",
      "0.1414883219999865\n",
      "Training model 3539: (46,67) ...\n",
      "0.15261976500005403\n",
      "Training model 3540: (46,68) ...\n",
      "0.14120792800031268\n",
      "Training model 3541: (46,69) ...\n",
      "0.11462225600007514\n",
      "Training model 3542: (46,70) ...\n",
      "0.16698113299980832\n",
      "Training model 3543: (46,71) ...\n",
      "0.13453809599968736\n",
      "Training model 3544: (46,72) ...\n",
      "0.14865198799998325\n",
      "Training model 3545: (46,73) ...\n",
      "0.13493823099997826\n",
      "Training model 3546: (46,74) ...\n",
      "0.14383945700001277\n",
      "Training model 3547: (46,75) ...\n",
      "0.12663920499971937\n",
      "Training model 3548: (46,76) ...\n",
      "0.15512543700015158\n",
      "Training model 3549: (46,77) ...\n",
      "0.18390129199997318\n",
      "Training model 3550: (46,78) ...\n",
      "0.13730440500012264\n",
      "Training model 3551: (46,79) ...\n",
      "0.16149209300010625\n",
      "Training model 3552: (46,80) ...\n",
      "0.11162991299988789\n",
      "Training model 3553: (46,81) ...\n",
      "0.13952708800024993\n",
      "Training model 3554: (46,82) ...\n",
      "0.14039666000007855\n",
      "Training model 3555: (46,83) ...\n",
      "0.11487458600004175\n",
      "Training model 3556: (46,84) ...\n",
      "0.13799711699994077\n",
      "Training model 3557: (46,85) ...\n",
      "0.15047335000008388\n",
      "Training model 3558: (46,86) ...\n",
      "0.13089661399999386\n",
      "Training model 3559: (46,87) ...\n",
      "0.12290565800003606\n",
      "Training model 3560: (46,88) ...\n",
      "0.1442855119998967\n",
      "Training model 3561: (46,89) ...\n",
      "0.12925157500012574\n",
      "Training model 3562: (46,90) ...\n",
      "0.13910464800028421\n",
      "Training model 3563: (46,91) ...\n",
      "0.15722102500012625\n",
      "Training model 3564: (46,92) ...\n",
      "0.1501809400001548\n",
      "Training model 3565: (46,93) ...\n",
      "0.1572355719999905\n",
      "Training model 3566: (46,94) ...\n",
      "0.18853714900023988\n",
      "Training model 3567: (46,95) ...\n",
      "0.16109374699999535\n",
      "Training model 3568: (46,96) ...\n",
      "0.16171835700015436\n",
      "Training model 3569: (46,97) ...\n",
      "0.11608083100009026\n",
      "Training model 3570: (46,98) ...\n",
      "0.11900762699997358\n",
      "Training model 3571: (46,99) ...\n",
      "0.12631957499979762\n",
      "Training model 3572: (47,48) ...\n",
      "0.18078987099988808\n",
      "Training model 3573: (47,49) ...\n",
      "0.1878991449998466\n",
      "Training model 3574: (47,50) ...\n",
      "0.1788679339997543\n",
      "Training model 3575: (47,51) ...\n",
      "0.16317978699999003\n",
      "Training model 3576: (47,52) ...\n",
      "0.19292795500041393\n",
      "Training model 3577: (47,53) ...\n",
      "0.20498227699999916\n",
      "Training model 3578: (47,54) ...\n",
      "0.2546302089999699\n",
      "Training model 3579: (47,55) ...\n",
      "0.3042736879997392\n",
      "Training model 3580: (47,56) ...\n",
      "0.16074595200007025\n",
      "Training model 3581: (47,57) ...\n",
      "0.19778269500011447\n",
      "Training model 3582: (47,58) ...\n",
      "0.22873102799985645\n",
      "Training model 3583: (47,59) ...\n",
      "0.2917418160000125\n",
      "Training model 3584: (47,60) ...\n",
      "0.27874865099965973\n",
      "Training model 3585: (47,61) ...\n",
      "0.20594782199987094\n",
      "Training model 3586: (47,62) ...\n",
      "0.24614686299992172\n",
      "Training model 3587: (47,63) ...\n",
      "0.17999221199988824\n",
      "Training model 3588: (47,64) ...\n",
      "0.3756665789996987\n",
      "Training model 3589: (47,65) ...\n",
      "0.15948924699978306\n",
      "Training model 3590: (47,66) ...\n",
      "0.23345858499988026\n",
      "Training model 3591: (47,67) ...\n",
      "0.21548890100029894\n",
      "Training model 3592: (47,68) ...\n",
      "0.22827809899990825\n",
      "Training model 3593: (47,69) ...\n",
      "0.1382074839998495\n",
      "Training model 3594: (47,70) ...\n",
      "0.15513729199983572\n",
      "Training model 3595: (47,71) ...\n",
      "0.19599647399991227\n",
      "Training model 3596: (47,72) ...\n",
      "0.15557436400013103\n",
      "Training model 3597: (47,73) ...\n",
      "0.15023116200018194\n",
      "Training model 3598: (47,74) ...\n",
      "0.15459053299991865\n",
      "Training model 3599: (47,75) ...\n",
      "0.13421125899958497\n",
      "Training model 3600: (47,76) ...\n",
      "0.1705455549999897\n",
      "Training model 3601: (47,77) ...\n",
      "0.18626103399992644\n",
      "Training model 3602: (47,78) ...\n",
      "0.15269393600010517\n",
      "Training model 3603: (47,79) ...\n",
      "0.15619547400001466\n",
      "Training model 3604: (47,80) ...\n",
      "0.12023763499973938\n",
      "Training model 3605: (47,81) ...\n",
      "0.13383613999985755\n",
      "Training model 3606: (47,82) ...\n",
      "0.14383540000017092\n",
      "Training model 3607: (47,83) ...\n",
      "0.12364213000000746\n",
      "Training model 3608: (47,84) ...\n",
      "0.1499169029998484\n",
      "Training model 3609: (47,85) ...\n",
      "0.14577923000024384\n",
      "Training model 3610: (47,86) ...\n",
      "0.13942052500033242\n",
      "Training model 3611: (47,87) ...\n",
      "0.1233042639996711\n",
      "Training model 3612: (47,88) ...\n",
      "0.13492853099978674\n",
      "Training model 3613: (47,89) ...\n",
      "0.1234487540000373\n",
      "Training model 3614: (47,90) ...\n",
      "0.13721597800031304\n",
      "Training model 3615: (47,91) ...\n",
      "0.14504359300008218\n",
      "Training model 3616: (47,92) ...\n",
      "0.1481825129999379\n",
      "Training model 3617: (47,93) ...\n",
      "0.13813101300002018\n",
      "Training model 3618: (47,94) ...\n",
      "0.184098128000187\n",
      "Training model 3619: (47,95) ...\n",
      "0.17056425200007652\n",
      "Training model 3620: (47,96) ...\n",
      "0.13541261399996074\n",
      "Training model 3621: (47,97) ...\n",
      "0.11866723799994361\n",
      "Training model 3622: (47,98) ...\n",
      "0.11798288399995727\n",
      "Training model 3623: (47,99) ...\n",
      "0.11796771299987086\n",
      "Training model 3624: (48,49) ...\n",
      "0.29656231599983585\n",
      "Training model 3625: (48,50) ...\n",
      "0.3139209849996405\n",
      "Training model 3626: (48,51) ...\n",
      "0.15591618200005541\n",
      "Training model 3627: (48,52) ...\n",
      "0.14664515599997685\n",
      "Training model 3628: (48,53) ...\n",
      "0.16595984600007796\n",
      "Training model 3629: (48,54) ...\n",
      "0.21603236600003584\n",
      "Training model 3630: (48,55) ...\n",
      "0.12360807899995052\n",
      "Training model 3631: (48,56) ...\n",
      "0.14405072399995333\n",
      "Training model 3632: (48,57) ...\n",
      "0.141999401999783\n",
      "Training model 3633: (48,58) ...\n",
      "0.22489912599985473\n",
      "Training model 3634: (48,59) ...\n",
      "0.12010989500004143\n",
      "Training model 3635: (48,60) ...\n",
      "0.20255977199985864\n",
      "Training model 3636: (48,61) ...\n",
      "0.1807273070003248\n",
      "Training model 3637: (48,62) ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2074831599998106\n",
      "Training model 3638: (48,63) ...\n",
      "0.19108238199987682\n",
      "Training model 3639: (48,64) ...\n",
      "0.14099534000024505\n",
      "Training model 3640: (48,65) ...\n",
      "0.13724825399958718\n",
      "Training model 3641: (48,66) ...\n",
      "0.16506467799990787\n",
      "Training model 3642: (48,67) ...\n",
      "0.20029477700018106\n",
      "Training model 3643: (48,68) ...\n",
      "0.16698216400027377\n",
      "Training model 3644: (48,69) ...\n",
      "0.17059453599995322\n",
      "Training model 3645: (48,70) ...\n",
      "0.10604764200024874\n",
      "Training model 3646: (48,71) ...\n",
      "0.14314233899995088\n",
      "Training model 3647: (48,72) ...\n",
      "0.10049084299998867\n",
      "Training model 3648: (48,73) ...\n",
      "0.11522090299968113\n",
      "Training model 3649: (48,74) ...\n",
      "0.10560132799992061\n",
      "Training model 3650: (48,75) ...\n",
      "0.10799655600021651\n",
      "Training model 3651: (48,76) ...\n",
      "0.14941305199999988\n",
      "Training model 3652: (48,77) ...\n",
      "0.1354740059996402\n",
      "Training model 3653: (48,78) ...\n",
      "0.1161449240003094\n",
      "Training model 3654: (48,79) ...\n",
      "0.12718865299984827\n",
      "Training model 3655: (48,80) ...\n",
      "0.12388681399988855\n",
      "Training model 3656: (48,81) ...\n",
      "0.16339902500021708\n",
      "Training model 3657: (48,82) ...\n",
      "0.1781058229998962\n",
      "Training model 3658: (48,83) ...\n",
      "0.12171551300025385\n",
      "Training model 3659: (48,84) ...\n",
      "0.1473639149999144\n",
      "Training model 3660: (48,85) ...\n",
      "0.20149878700021873\n",
      "Training model 3661: (48,86) ...\n",
      "0.14342925599976297\n",
      "Training model 3662: (48,87) ...\n",
      "0.12596560199972373\n",
      "Training model 3663: (48,88) ...\n",
      "0.10927215999981854\n",
      "Training model 3664: (48,89) ...\n",
      "0.11340155000016239\n",
      "Training model 3665: (48,90) ...\n",
      "0.10424382500013962\n",
      "Training model 3666: (48,91) ...\n",
      "0.1186556229999951\n",
      "Training model 3667: (48,92) ...\n",
      "0.10418470400009028\n",
      "Training model 3668: (48,93) ...\n",
      "0.1313553300001331\n",
      "Training model 3669: (48,94) ...\n",
      "0.11250027000005502\n",
      "Training model 3670: (48,95) ...\n",
      "0.1062953320001725\n",
      "Training model 3671: (48,96) ...\n",
      "0.10983082499978991\n",
      "Training model 3672: (48,97) ...\n",
      "0.12167850900004851\n",
      "Training model 3673: (48,98) ...\n",
      "0.10332078200008254\n",
      "Training model 3674: (48,99) ...\n",
      "0.13844788599999447\n",
      "Training model 3675: (49,50) ...\n",
      "0.716316531999837\n",
      "Training model 3676: (49,51) ...\n",
      "0.12313358999972479\n",
      "Training model 3677: (49,52) ...\n",
      "0.15826394899977458\n",
      "Training model 3678: (49,53) ...\n",
      "0.16591719699999885\n",
      "Training model 3679: (49,54) ...\n",
      "0.3061409189999722\n",
      "Training model 3680: (49,55) ...\n",
      "0.13152903899981538\n",
      "Training model 3681: (49,56) ...\n",
      "0.16215154400015308\n",
      "Training model 3682: (49,57) ...\n",
      "0.1896391240002231\n",
      "Training model 3683: (49,58) ...\n",
      "0.3213034179998431\n",
      "Training model 3684: (49,59) ...\n",
      "0.1441366779999953\n",
      "Training model 3685: (49,60) ...\n",
      "0.3030690769996909\n",
      "Training model 3686: (49,61) ...\n",
      "0.21844953500021802\n",
      "Training model 3687: (49,62) ...\n",
      "0.3083894940000391\n",
      "Training model 3688: (49,63) ...\n",
      "0.19810474399992017\n",
      "Training model 3689: (49,64) ...\n",
      "0.15699670900039564\n",
      "Training model 3690: (49,65) ...\n",
      "0.1702154800000244\n",
      "Training model 3691: (49,66) ...\n",
      "0.22651279599995178\n",
      "Training model 3692: (49,67) ...\n",
      "0.3264233130003049\n",
      "Training model 3693: (49,68) ...\n",
      "0.24272883300000103\n",
      "Training model 3694: (49,69) ...\n",
      "0.15898397699993438\n",
      "Training model 3695: (49,70) ...\n",
      "0.1229392000000189\n",
      "Training model 3696: (49,71) ...\n",
      "0.18090138100023978\n",
      "Training model 3697: (49,72) ...\n",
      "0.11960026499991727\n",
      "Training model 3698: (49,73) ...\n",
      "0.13431270699993547\n",
      "Training model 3699: (49,74) ...\n",
      "0.1124846439997782\n",
      "Training model 3700: (49,75) ...\n",
      "0.11537597200003802\n",
      "Training model 3701: (49,76) ...\n",
      "0.16374668300022677\n",
      "Training model 3702: (49,77) ...\n",
      "0.15059542900007727\n",
      "Training model 3703: (49,78) ...\n",
      "0.12257016099965767\n",
      "Training model 3704: (49,79) ...\n",
      "0.15267737199974363\n",
      "Training model 3705: (49,80) ...\n",
      "0.14463378699974783\n",
      "Training model 3706: (49,81) ...\n",
      "0.1915467069998158\n",
      "Training model 3707: (49,82) ...\n",
      "0.2026639509999768\n",
      "Training model 3708: (49,83) ...\n",
      "0.15409143100032452\n",
      "Training model 3709: (49,84) ...\n",
      "0.156621592999727\n",
      "Training model 3710: (49,85) ...\n",
      "0.21716398799981107\n",
      "Training model 3711: (49,86) ...\n",
      "0.1602487850000216\n",
      "Training model 3712: (49,87) ...\n",
      "0.11393609199967614\n",
      "Training model 3713: (49,88) ...\n",
      "0.10886754500006646\n",
      "Training model 3714: (49,89) ...\n",
      "0.11345407699991483\n",
      "Training model 3715: (49,90) ...\n",
      "0.11225067300028968\n",
      "Training model 3716: (49,91) ...\n",
      "0.14114140999981828\n",
      "Training model 3717: (49,92) ...\n",
      "0.11726612300026318\n",
      "Training model 3718: (49,93) ...\n",
      "0.13090205100024832\n",
      "Training model 3719: (49,94) ...\n",
      "0.11251860899983512\n",
      "Training model 3720: (49,95) ...\n",
      "0.10617451600001004\n",
      "Training model 3721: (49,96) ...\n",
      "0.10853136600007929\n",
      "Training model 3722: (49,97) ...\n",
      "0.15280895499972758\n",
      "Training model 3723: (49,98) ...\n",
      "0.164187598999888\n",
      "Training model 3724: (49,99) ...\n",
      "0.18157720299996072\n",
      "Training model 3725: (50,51) ...\n",
      "0.14314230400032102\n",
      "Training model 3726: (50,52) ...\n",
      "0.15423505399985515\n",
      "Training model 3727: (50,53) ...\n",
      "0.1805815050001911\n",
      "Training model 3728: (50,54) ...\n",
      "0.23568595799997638\n",
      "Training model 3729: (50,55) ...\n",
      "0.12823140400041666\n",
      "Training model 3730: (50,56) ...\n",
      "0.16819357799977297\n",
      "Training model 3731: (50,57) ...\n",
      "0.2006111509999755\n",
      "Training model 3732: (50,58) ...\n",
      "0.36240393400021276\n",
      "Training model 3733: (50,59) ...\n",
      "0.1380652990001181\n",
      "Training model 3734: (50,60) ...\n",
      "0.24710285900027884\n",
      "Training model 3735: (50,61) ...\n",
      "0.19428171600020505\n",
      "Training model 3736: (50,62) ...\n",
      "0.26076632099966446\n",
      "Training model 3737: (50,63) ...\n",
      "0.19382702400025664\n",
      "Training model 3738: (50,64) ...\n",
      "0.17047114699971644\n",
      "Training model 3739: (50,65) ...\n",
      "0.22300797900015823\n",
      "Training model 3740: (50,66) ...\n",
      "0.16112188199986122\n",
      "Training model 3741: (50,67) ...\n",
      "0.2626344599998447\n",
      "Training model 3742: (50,68) ...\n",
      "0.17030209699987608\n",
      "Training model 3743: (50,69) ...\n",
      "0.1694964510002137\n",
      "Training model 3744: (50,70) ...\n",
      "0.12946640199970716\n",
      "Training model 3745: (50,71) ...\n",
      "0.15806815399992047\n",
      "Training model 3746: (50,72) ...\n",
      "0.11797096899999815\n",
      "Training model 3747: (50,73) ...\n",
      "0.13601903400012816\n",
      "Training model 3748: (50,74) ...\n",
      "0.12144239299959736\n",
      "Training model 3749: (50,75) ...\n",
      "0.12313511499996821\n",
      "Training model 3750: (50,76) ...\n",
      "0.17085633699980463\n",
      "Training model 3751: (50,77) ...\n",
      "0.15113976199972967\n",
      "Training model 3752: (50,78) ...\n",
      "0.1342084579996481\n",
      "Training model 3753: (50,79) ...\n",
      "0.16278264799984754\n",
      "Training model 3754: (50,80) ...\n",
      "0.1399022580003475\n",
      "Training model 3755: (50,81) ...\n",
      "0.1778355400001601\n",
      "Training model 3756: (50,82) ...\n",
      "0.1930005889998938\n",
      "Training model 3757: (50,83) ...\n",
      "0.14408284400042248\n",
      "Training model 3758: (50,84) ...\n",
      "0.17178843900001084\n",
      "Training model 3759: (50,85) ...\n",
      "0.20348065700000006\n",
      "Training model 3760: (50,86) ...\n",
      "0.15762354600019535\n",
      "Training model 3761: (50,87) ...\n",
      "0.12648498199996538\n",
      "Training model 3762: (50,88) ...\n",
      "0.13004735899994557\n",
      "Training model 3763: (50,89) ...\n",
      "0.12918353599980037\n",
      "Training model 3764: (50,90) ...\n",
      "0.12398976499980563\n",
      "Training model 3765: (50,91) ...\n",
      "0.14498244600008547\n",
      "Training model 3766: (50,92) ...\n",
      "0.11731195500033209\n",
      "Training model 3767: (50,93) ...\n",
      "0.1432599439999649\n",
      "Training model 3768: (50,94) ...\n",
      "0.12780159500016453\n",
      "Training model 3769: (50,95) ...\n",
      "0.12475571799996032\n",
      "Training model 3770: (50,96) ...\n",
      "0.12928198300005533\n",
      "Training model 3771: (50,97) ...\n",
      "0.15518249499973535\n",
      "Training model 3772: (50,98) ...\n",
      "0.1717212369999288\n",
      "Training model 3773: (50,99) ...\n",
      "0.20093295000015132\n",
      "Training model 3774: (51,52) ...\n",
      "0.14126650299976973\n",
      "Training model 3775: (51,53) ...\n",
      "0.13769723899986275\n",
      "Training model 3776: (51,54) ...\n",
      "0.13258887799975128\n",
      "Training model 3777: (51,55) ...\n",
      "0.11543631099993945\n",
      "Training model 3778: (51,56) ...\n",
      "0.134290202000102\n",
      "Training model 3779: (51,57) ...\n",
      "0.12561389100028464\n",
      "Training model 3780: (51,58) ...\n",
      "0.1350073959997644\n",
      "Training model 3781: (51,59) ...\n",
      "0.11655611200012572\n",
      "Training model 3782: (51,60) ...\n",
      "0.15703304099997695\n",
      "Training model 3783: (51,61) ...\n",
      "0.20257969400017828\n",
      "Training model 3784: (51,62) ...\n",
      "0.17982584599985785\n",
      "Training model 3785: (51,63) ...\n",
      "0.17119872300008865\n",
      "Training model 3786: (51,64) ...\n",
      "0.12189998500025467\n",
      "Training model 3787: (51,65) ...\n",
      "0.12069496499998422\n",
      "Training model 3788: (51,66) ...\n",
      "0.13776865500040003\n",
      "Training model 3789: (51,67) ...\n",
      "0.13052008800013937\n",
      "Training model 3790: (51,68) ...\n",
      "0.13588655999956245\n",
      "Training model 3791: (51,69) ...\n",
      "0.13709430999961114\n",
      "Training model 3792: (51,70) ...\n",
      "0.10940242900005615\n",
      "Training model 3793: (51,71) ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.17173667499992007\n",
      "Training model 3794: (51,72) ...\n",
      "0.10972561700009464\n",
      "Training model 3795: (51,73) ...\n",
      "0.1352273200000127\n",
      "Training model 3796: (51,74) ...\n",
      "0.11545109300004697\n",
      "Training model 3797: (51,75) ...\n",
      "0.11158460799970271\n",
      "Training model 3798: (51,76) ...\n",
      "0.15506820700011303\n",
      "Training model 3799: (51,77) ...\n",
      "0.1344867049997447\n",
      "Training model 3800: (51,78) ...\n",
      "0.14351412399992114\n",
      "Training model 3801: (51,79) ...\n",
      "0.1438333880000755\n",
      "Training model 3802: (51,80) ...\n",
      "0.14211788600005093\n",
      "Training model 3803: (51,81) ...\n",
      "0.11581216399963523\n",
      "Training model 3804: (51,82) ...\n",
      "0.12634256000001187\n",
      "Training model 3805: (51,83) ...\n",
      "0.11224354700016193\n",
      "Training model 3806: (51,84) ...\n",
      "0.13064107699983651\n",
      "Training model 3807: (51,85) ...\n",
      "0.13945176500010348\n",
      "Training model 3808: (51,86) ...\n",
      "0.1281911000000946\n",
      "Training model 3809: (51,87) ...\n",
      "0.14361628500000734\n",
      "Training model 3810: (51,88) ...\n",
      "0.1364640059996418\n",
      "Training model 3811: (51,89) ...\n",
      "0.147609119000208\n",
      "Training model 3812: (51,90) ...\n",
      "0.11278341700017336\n",
      "Training model 3813: (51,91) ...\n",
      "0.11553722600001493\n",
      "Training model 3814: (51,92) ...\n",
      "0.11003759599998375\n",
      "Training model 3815: (51,93) ...\n",
      "0.1459424179997768\n",
      "Training model 3816: (51,94) ...\n",
      "0.12203656400015461\n",
      "Training model 3817: (51,95) ...\n",
      "0.11054444899991722\n",
      "Training model 3818: (51,96) ...\n",
      "0.12411575500027539\n",
      "Training model 3819: (51,97) ...\n",
      "0.1211209390003205\n",
      "Training model 3820: (51,98) ...\n",
      "0.11529286299992236\n",
      "Training model 3821: (51,99) ...\n",
      "0.13774250100004792\n",
      "Training model 3822: (52,53) ...\n",
      "0.5553717200000392\n",
      "Training model 3823: (52,54) ...\n",
      "0.3115652470000896\n",
      "Training model 3824: (52,55) ...\n",
      "0.1718274449999626\n",
      "Training model 3825: (52,56) ...\n",
      "0.21647847000031106\n",
      "Training model 3826: (52,57) ...\n",
      "0.411905064000166\n",
      "Training model 3827: (52,58) ...\n",
      "0.2627042449998953\n",
      "Training model 3828: (52,59) ...\n",
      "0.16450109399966095\n",
      "Training model 3829: (52,60) ...\n",
      "0.4123763220000001\n",
      "Training model 3830: (52,61) ...\n",
      "0.22046391399999266\n",
      "Training model 3831: (52,62) ...\n",
      "0.26561716900005194\n",
      "Training model 3832: (52,63) ...\n",
      "0.24240664300032222\n",
      "Training model 3833: (52,64) ...\n",
      "0.17205805699995835\n",
      "Training model 3834: (52,65) ...\n",
      "0.19009864199961157\n",
      "Training model 3835: (52,66) ...\n",
      "0.2081560259998696\n",
      "Training model 3836: (52,67) ...\n",
      "0.19651293300012185\n",
      "Training model 3837: (52,68) ...\n",
      "0.2298914389998572\n",
      "Training model 3838: (52,69) ...\n",
      "0.15210214800026733\n",
      "Training model 3839: (52,70) ...\n",
      "0.128629476000242\n",
      "Training model 3840: (52,71) ...\n",
      "0.21524060600040684\n",
      "Training model 3841: (52,72) ...\n",
      "0.12143883600037952\n",
      "Training model 3842: (52,73) ...\n",
      "0.13084685599960721\n",
      "Training model 3843: (52,74) ...\n",
      "0.1116880360000323\n",
      "Training model 3844: (52,75) ...\n",
      "0.1274543489998905\n",
      "Training model 3845: (52,76) ...\n",
      "0.17388167499984775\n",
      "Training model 3846: (52,77) ...\n",
      "0.16567248999990625\n",
      "Training model 3847: (52,78) ...\n",
      "0.202986570000121\n",
      "Training model 3848: (52,79) ...\n",
      "0.23446282499980953\n",
      "Training model 3849: (52,80) ...\n",
      "0.1130962800002635\n",
      "Training model 3850: (52,81) ...\n",
      "0.12425045700001647\n",
      "Training model 3851: (52,82) ...\n",
      "0.15817555200010247\n",
      "Training model 3852: (52,83) ...\n",
      "0.11634248099971956\n",
      "Training model 3853: (52,84) ...\n",
      "0.13088283100023546\n",
      "Training model 3854: (52,85) ...\n",
      "0.16322640599992155\n",
      "Training model 3855: (52,86) ...\n",
      "0.15324477600006503\n",
      "Training model 3856: (52,87) ...\n",
      "0.12212665199967887\n",
      "Training model 3857: (52,88) ...\n",
      "0.11657448400001158\n",
      "Training model 3858: (52,89) ...\n",
      "0.10979060899990145\n",
      "Training model 3859: (52,90) ...\n",
      "0.1118564299999889\n",
      "Training model 3860: (52,91) ...\n",
      "0.14515470900005312\n",
      "Training model 3861: (52,92) ...\n",
      "0.11956550199965932\n",
      "Training model 3862: (52,93) ...\n",
      "0.12820341500037102\n",
      "Training model 3863: (52,94) ...\n",
      "0.14115338500005237\n",
      "Training model 3864: (52,95) ...\n",
      "0.12266598699989117\n",
      "Training model 3865: (52,96) ...\n",
      "0.12359846600020319\n",
      "Training model 3866: (52,97) ...\n",
      "0.11813903099982781\n",
      "Training model 3867: (52,98) ...\n",
      "0.1186638019999009\n",
      "Training model 3868: (52,99) ...\n",
      "0.11878320800042275\n",
      "Training model 3869: (53,54) ...\n",
      "0.2737296390000665\n",
      "Training model 3870: (53,55) ...\n",
      "0.16932751200010898\n",
      "Training model 3871: (53,56) ...\n",
      "0.2760778320002828\n",
      "Training model 3872: (53,57) ...\n",
      "0.3305502919997707\n",
      "Training model 3873: (53,58) ...\n",
      "0.2965252959997997\n",
      "Training model 3874: (53,59) ...\n",
      "0.1793382070000007\n",
      "Training model 3875: (53,60) ...\n",
      "0.3559053449998828\n",
      "Training model 3876: (53,61) ...\n",
      "0.21480665500030227\n",
      "Training model 3877: (53,62) ...\n",
      "0.24986187700005758\n",
      "Training model 3878: (53,63) ...\n",
      "0.2335244999999304\n",
      "Training model 3879: (53,64) ...\n",
      "0.16773045799982356\n",
      "Training model 3880: (53,65) ...\n",
      "0.23742405800021515\n",
      "Training model 3881: (53,66) ...\n",
      "0.19207306299995253\n",
      "Training model 3882: (53,67) ...\n",
      "0.21271702000012738\n",
      "Training model 3883: (53,68) ...\n",
      "0.2169011859996317\n",
      "Training model 3884: (53,69) ...\n",
      "0.16686338700037595\n",
      "Training model 3885: (53,70) ...\n",
      "0.1397981999998592\n",
      "Training model 3886: (53,71) ...\n",
      "0.2594178659996942\n",
      "Training model 3887: (53,72) ...\n",
      "0.13212433100034104\n",
      "Training model 3888: (53,73) ...\n",
      "0.1537017979999291\n",
      "Training model 3889: (53,74) ...\n",
      "0.1315638589999253\n",
      "Training model 3890: (53,75) ...\n",
      "0.157077801000014\n",
      "Training model 3891: (53,76) ...\n",
      "0.18209225700002207\n",
      "Training model 3892: (53,77) ...\n",
      "0.16946143899986055\n",
      "Training model 3893: (53,78) ...\n",
      "0.185463425999842\n",
      "Training model 3894: (53,79) ...\n",
      "0.2183162330002233\n",
      "Training model 3895: (53,80) ...\n",
      "0.12946243900023546\n",
      "Training model 3896: (53,81) ...\n",
      "0.12896924999995463\n",
      "Training model 3897: (53,82) ...\n",
      "0.14373639699988416\n",
      "Training model 3898: (53,83) ...\n",
      "0.1314901710002232\n",
      "Training model 3899: (53,84) ...\n",
      "0.14306384500014246\n",
      "Training model 3900: (53,85) ...\n",
      "0.1638236250000773\n",
      "Training model 3901: (53,86) ...\n",
      "0.1376396300001943\n",
      "Training model 3902: (53,87) ...\n",
      "0.13464633400008097\n",
      "Training model 3903: (53,88) ...\n",
      "0.1313182720000441\n",
      "Training model 3904: (53,89) ...\n",
      "0.128866239999752\n",
      "Training model 3905: (53,90) ...\n",
      "0.1283407860000807\n",
      "Training model 3906: (53,91) ...\n",
      "0.1387328509999861\n",
      "Training model 3907: (53,92) ...\n",
      "0.12634933500021361\n",
      "Training model 3908: (53,93) ...\n",
      "0.1545868589996644\n",
      "Training model 3909: (53,94) ...\n",
      "0.15632386299967038\n",
      "Training model 3910: (53,95) ...\n",
      "0.1337201470000764\n",
      "Training model 3911: (53,96) ...\n",
      "0.1466078970001945\n",
      "Training model 3912: (53,97) ...\n",
      "0.1344710580001447\n",
      "Training model 3913: (53,98) ...\n",
      "0.1374663420001525\n",
      "Training model 3914: (53,99) ...\n",
      "0.1306838619998416\n",
      "Training model 3915: (54,55) ...\n",
      "0.15208902800031865\n",
      "Training model 3916: (54,56) ...\n",
      "0.37789607600007\n",
      "Training model 3917: (54,57) ...\n",
      "0.39207418899968616\n",
      "Training model 3918: (54,58) ...\n",
      "0.34654914999964603\n",
      "Training model 3919: (54,59) ...\n",
      "0.16993670100009695\n",
      "Training model 3920: (54,60) ...\n",
      "0.6971514219999335\n",
      "Training model 3921: (54,61) ...\n",
      "0.37018349399977524\n",
      "Training model 3922: (54,62) ...\n",
      "0.5618879290000223\n",
      "Training model 3923: (54,63) ...\n",
      "0.25922678599999927\n",
      "Training model 3924: (54,64) ...\n",
      "0.16889610899988838\n",
      "Training model 3925: (54,65) ...\n",
      "0.2593120089995864\n",
      "Training model 3926: (54,66) ...\n",
      "0.5332862720001685\n",
      "Training model 3927: (54,67) ...\n",
      "0.6788192619997062\n",
      "Training model 3928: (54,68) ...\n",
      "0.6119583459999376\n",
      "Training model 3929: (54,69) ...\n",
      "0.2006254650000301\n",
      "Training model 3930: (54,70) ...\n",
      "0.14620858700027384\n",
      "Training model 3931: (54,71) ...\n",
      "0.24564314899998863\n",
      "Training model 3932: (54,72) ...\n",
      "0.1252045179999186\n",
      "Training model 3933: (54,73) ...\n",
      "0.15112229099986507\n",
      "Training model 3934: (54,74) ...\n",
      "0.13153455599967856\n",
      "Training model 3935: (54,75) ...\n",
      "0.14443102799987173\n",
      "Training model 3936: (54,76) ...\n",
      "0.22328008300019064\n",
      "Training model 3937: (54,77) ...\n",
      "0.20240656199985096\n",
      "Training model 3938: (54,78) ...\n",
      "0.1497898519996852\n",
      "Training model 3939: (54,79) ...\n",
      "0.2291426310002862\n",
      "Training model 3940: (54,80) ...\n",
      "0.13253671200027384\n",
      "Training model 3941: (54,81) ...\n",
      "0.17558876600014628\n",
      "Training model 3942: (54,82) ...\n",
      "0.20454562700024326\n",
      "Training model 3943: (54,83) ...\n",
      "0.1355681380000533\n",
      "Training model 3944: (54,84) ...\n",
      "0.12655001000030097\n",
      "Training model 3945: (54,85) ...\n",
      "0.19441047400005118\n",
      "Training model 3946: (54,86) ...\n",
      "0.16879092199997103\n",
      "Training model 3947: (54,87) ...\n",
      "0.11788266099983957\n",
      "Training model 3948: (54,88) ...\n",
      "0.12542643699998735\n",
      "Training model 3949: (54,89) ...\n",
      "0.11674049300017941\n",
      "Training model 3950: (54,90) ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.11838403499996275\n",
      "Training model 3951: (54,91) ...\n",
      "0.14383884800008673\n",
      "Training model 3952: (54,92) ...\n",
      "0.11815453000008347\n",
      "Training model 3953: (54,93) ...\n",
      "0.13476999500016973\n",
      "Training model 3954: (54,94) ...\n",
      "0.12599854900008722\n",
      "Training model 3955: (54,95) ...\n",
      "0.12253452400000242\n",
      "Training model 3956: (54,96) ...\n",
      "0.12060078600006818\n",
      "Training model 3957: (54,97) ...\n",
      "0.12645506500030024\n",
      "Training model 3958: (54,98) ...\n",
      "0.11447512099994128\n",
      "Training model 3959: (54,99) ...\n",
      "0.11628239700030463\n",
      "Training model 3960: (55,56) ...\n",
      "0.12018238400014525\n",
      "Training model 3961: (55,57) ...\n",
      "0.16553553899984763\n",
      "Training model 3962: (55,58) ...\n",
      "0.18491955999979837\n",
      "Training model 3963: (55,59) ...\n",
      "0.7010853179999685\n",
      "Training model 3964: (55,60) ...\n",
      "0.19790742699979091\n",
      "Training model 3965: (55,61) ...\n",
      "0.14551730199991653\n",
      "Training model 3966: (55,62) ...\n",
      "0.1752392969997345\n",
      "Training model 3967: (55,63) ...\n",
      "0.14429128199981278\n",
      "Training model 3968: (55,64) ...\n",
      "0.7261040930002309\n",
      "Training model 3969: (55,65) ...\n",
      "0.15651973799958796\n",
      "Training model 3970: (55,66) ...\n",
      "0.1369304380000358\n",
      "Training model 3971: (55,67) ...\n",
      "0.12974861600014265\n",
      "Training model 3972: (55,68) ...\n",
      "0.13122607900004368\n",
      "Training model 3973: (55,69) ...\n",
      "0.11258152100026564\n",
      "Training model 3974: (55,70) ...\n",
      "0.14469004500006122\n",
      "Training model 3975: (55,71) ...\n",
      "0.13479860699999335\n",
      "Training model 3976: (55,72) ...\n",
      "0.13077154999973573\n",
      "Training model 3977: (55,73) ...\n",
      "0.1253339669997331\n",
      "Training model 3978: (55,74) ...\n",
      "0.13705493599991314\n",
      "Training model 3979: (55,75) ...\n",
      "0.1185742239999854\n",
      "Training model 3980: (55,76) ...\n",
      "0.14069720599991342\n",
      "Training model 3981: (55,77) ...\n",
      "0.1509018870001455\n",
      "Training model 3982: (55,78) ...\n",
      "0.1254691270000876\n",
      "Training model 3983: (55,79) ...\n",
      "0.1407521410001209\n",
      "Training model 3984: (55,80) ...\n",
      "0.10603514200010977\n",
      "Training model 3985: (55,81) ...\n",
      "0.11881952600015211\n",
      "Training model 3986: (55,82) ...\n",
      "0.13179915499995332\n",
      "Training model 3987: (55,83) ...\n",
      "0.1071091910002906\n",
      "Training model 3988: (55,84) ...\n",
      "0.12451375199998438\n",
      "Training model 3989: (55,85) ...\n",
      "0.1397506869998324\n",
      "Training model 3990: (55,86) ...\n",
      "0.11838713499992082\n",
      "Training model 3991: (55,87) ...\n",
      "0.1097818590001225\n",
      "Training model 3992: (55,88) ...\n",
      "0.13664115800020227\n",
      "Training model 3993: (55,89) ...\n",
      "0.124568502999864\n",
      "Training model 3994: (55,90) ...\n",
      "0.12865167200016003\n",
      "Training model 3995: (55,91) ...\n",
      "0.13072005599997283\n",
      "Training model 3996: (55,92) ...\n",
      "0.13744180899993808\n",
      "Training model 3997: (55,93) ...\n",
      "0.14244913099992118\n",
      "Training model 3998: (55,94) ...\n",
      "0.151947181000196\n",
      "Training model 3999: (55,95) ...\n",
      "0.15349531199990452\n",
      "Training model 4000: (55,96) ...\n",
      "0.1449321299996882\n",
      "Training model 4001: (55,97) ...\n",
      "0.11480067200000121\n",
      "Training model 4002: (55,98) ...\n",
      "0.1053968710002664\n",
      "Training model 4003: (55,99) ...\n",
      "0.10776120399987121\n",
      "Training model 4004: (56,57) ...\n",
      "0.21763468100016325\n",
      "Training model 4005: (56,58) ...\n",
      "0.19913497000015923\n",
      "Training model 4006: (56,59) ...\n",
      "0.13060117599980003\n",
      "Training model 4007: (56,60) ...\n",
      "0.3848989029997938\n",
      "Training model 4008: (56,61) ...\n",
      "0.29277291100015645\n",
      "Training model 4009: (56,62) ...\n",
      "0.32844684300016525\n",
      "Training model 4010: (56,63) ...\n",
      "0.21156859399980021\n",
      "Training model 4011: (56,64) ...\n",
      "0.13273003699987385\n",
      "Training model 4012: (56,65) ...\n",
      "0.2386955840001974\n",
      "Training model 4013: (56,66) ...\n",
      "0.22362014099962835\n",
      "Training model 4014: (56,67) ...\n",
      "0.28166472500015516\n",
      "Training model 4015: (56,68) ...\n",
      "0.24504663900006562\n",
      "Training model 4016: (56,69) ...\n",
      "0.15581389499993747\n",
      "Training model 4017: (56,70) ...\n",
      "0.12349099799985197\n",
      "Training model 4018: (56,71) ...\n",
      "0.23803454700009752\n",
      "Training model 4019: (56,72) ...\n",
      "0.11879368900008558\n",
      "Training model 4020: (56,73) ...\n",
      "0.14062586199997895\n",
      "Training model 4021: (56,74) ...\n",
      "0.11857320199987953\n",
      "Training model 4022: (56,75) ...\n",
      "0.13261299999976472\n",
      "Training model 4023: (56,76) ...\n",
      "0.19988631999967765\n",
      "Training model 4024: (56,77) ...\n",
      "0.16554502000008142\n",
      "Training model 4025: (56,78) ...\n",
      "0.14533854699993753\n",
      "Training model 4026: (56,79) ...\n",
      "0.20177117799994448\n",
      "Training model 4027: (56,80) ...\n",
      "0.12690561799990974\n",
      "Training model 4028: (56,81) ...\n",
      "0.13815815500038298\n",
      "Training model 4029: (56,82) ...\n",
      "0.15695993999997881\n",
      "Training model 4030: (56,83) ...\n",
      "0.12210173899984511\n",
      "Training model 4031: (56,84) ...\n",
      "0.13893173500036937\n",
      "Training model 4032: (56,85) ...\n",
      "0.15188290000014604\n",
      "Training model 4033: (56,86) ...\n",
      "0.14655440700016698\n",
      "Training model 4034: (56,87) ...\n",
      "0.1314351349997196\n",
      "Training model 4035: (56,88) ...\n",
      "0.1265078720002748\n",
      "Training model 4036: (56,89) ...\n",
      "0.11128861899987896\n",
      "Training model 4037: (56,90) ...\n",
      "0.12458812399972885\n",
      "Training model 4038: (56,91) ...\n",
      "0.12753807599983702\n",
      "Training model 4039: (56,92) ...\n",
      "0.10798679900017305\n",
      "Training model 4040: (56,93) ...\n",
      "0.14375706600003468\n",
      "Training model 4041: (56,94) ...\n",
      "0.12879944199994497\n",
      "Training model 4042: (56,95) ...\n",
      "0.10674962399980359\n",
      "Training model 4043: (56,96) ...\n",
      "0.12325548599983449\n",
      "Training model 4044: (56,97) ...\n",
      "0.1271467510000548\n",
      "Training model 4045: (56,98) ...\n",
      "0.11973556699967958\n",
      "Training model 4046: (56,99) ...\n",
      "0.12320454399969094\n",
      "Training model 4047: (57,58) ...\n",
      "0.2615291110000726\n",
      "Training model 4048: (57,59) ...\n",
      "0.20563241000036214\n",
      "Training model 4049: (57,60) ...\n",
      "0.365748505999818\n",
      "Training model 4050: (57,61) ...\n",
      "0.2370421829996303\n",
      "Training model 4051: (57,62) ...\n",
      "0.3385054779996608\n",
      "Training model 4052: (57,63) ...\n",
      "0.2000648819998787\n",
      "Training model 4053: (57,64) ...\n",
      "0.18297366300021167\n",
      "Training model 4054: (57,65) ...\n",
      "0.1841190939999251\n",
      "Training model 4055: (57,66) ...\n",
      "0.2300584129998242\n",
      "Training model 4056: (57,67) ...\n",
      "0.23200958999996146\n",
      "Training model 4057: (57,68) ...\n",
      "0.24720553499992093\n",
      "Training model 4058: (57,69) ...\n",
      "0.14213233100008438\n",
      "Training model 4059: (57,70) ...\n",
      "0.1357119879999118\n",
      "Training model 4060: (57,71) ...\n",
      "0.2052860420003526\n",
      "Training model 4061: (57,72) ...\n",
      "0.13825250499985486\n",
      "Training model 4062: (57,73) ...\n",
      "0.12485020600024654\n",
      "Training model 4063: (57,74) ...\n",
      "0.12383746400018936\n",
      "Training model 4064: (57,75) ...\n",
      "0.12581991200022458\n",
      "Training model 4065: (57,76) ...\n",
      "0.18857452799966268\n",
      "Training model 4066: (57,77) ...\n",
      "0.18332119100023192\n",
      "Training model 4067: (57,78) ...\n",
      "0.1326401060000535\n",
      "Training model 4068: (57,79) ...\n",
      "0.22378294999998616\n",
      "Training model 4069: (57,80) ...\n",
      "0.11565810299998702\n",
      "Training model 4070: (57,81) ...\n",
      "0.12846445500008485\n",
      "Training model 4071: (57,82) ...\n",
      "0.17351051500008907\n",
      "Training model 4072: (57,83) ...\n",
      "0.12348875299994688\n",
      "Training model 4073: (57,84) ...\n",
      "0.12876542999993035\n",
      "Training model 4074: (57,85) ...\n",
      "0.17989605100001427\n",
      "Training model 4075: (57,86) ...\n",
      "0.1607448969998586\n",
      "Training model 4076: (57,87) ...\n",
      "0.11285521899981177\n",
      "Training model 4077: (57,88) ...\n",
      "0.11999058599985801\n",
      "Training model 4078: (57,89) ...\n",
      "0.10731075699959547\n",
      "Training model 4079: (57,90) ...\n",
      "0.11035144200013747\n",
      "Training model 4080: (57,91) ...\n",
      "0.1405599650001932\n",
      "Training model 4081: (57,92) ...\n",
      "0.1155941699998948\n",
      "Training model 4082: (57,93) ...\n",
      "0.12410296200005178\n",
      "Training model 4083: (57,94) ...\n",
      "0.1302768919999835\n",
      "Training model 4084: (57,95) ...\n",
      "0.12863516800007346\n",
      "Training model 4085: (57,96) ...\n",
      "0.11270186599995213\n",
      "Training model 4086: (57,97) ...\n",
      "0.11840817600023001\n",
      "Training model 4087: (57,98) ...\n",
      "0.12339290400041136\n",
      "Training model 4088: (57,99) ...\n",
      "0.11927672899992103\n",
      "Training model 4089: (58,59) ...\n",
      "0.18719637000003786\n",
      "Training model 4090: (58,60) ...\n",
      "0.3568247930002144\n",
      "Training model 4091: (58,61) ...\n",
      "0.23888283199994476\n",
      "Training model 4092: (58,62) ...\n",
      "0.3743172500003311\n",
      "Training model 4093: (58,63) ...\n",
      "0.23568990700005088\n",
      "Training model 4094: (58,64) ...\n",
      "0.20966755700010253\n",
      "Training model 4095: (58,65) ...\n",
      "0.3293662589999258\n",
      "Training model 4096: (58,66) ...\n",
      "0.2421597429997746\n",
      "Training model 4097: (58,67) ...\n",
      "0.27783108999983597\n",
      "Training model 4098: (58,68) ...\n",
      "0.2650231210000129\n",
      "Training model 4099: (58,69) ...\n",
      "0.2021014169999944\n",
      "Training model 4100: (58,70) ...\n",
      "0.1558344750001197\n",
      "Training model 4101: (58,71) ...\n",
      "0.22303826899997148\n",
      "Training model 4102: (58,72) ...\n",
      "0.14874057299994092\n",
      "Training model 4103: (58,73) ...\n",
      "0.1712560839996513\n",
      "Training model 4104: (58,74) ...\n",
      "0.15858738799988714\n",
      "Training model 4105: (58,75) ...\n",
      "0.16739531200028068\n",
      "Training model 4106: (58,76) ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.20299580400023842\n",
      "Training model 4107: (58,77) ...\n",
      "0.19094901500011474\n",
      "Training model 4108: (58,78) ...\n",
      "0.19189279100010026\n",
      "Training model 4109: (58,79) ...\n",
      "0.23471976100017855\n",
      "Training model 4110: (58,80) ...\n",
      "0.14807255699997768\n",
      "Training model 4111: (58,81) ...\n",
      "0.18115779699974155\n",
      "Training model 4112: (58,82) ...\n",
      "0.20262066599980244\n",
      "Training model 4113: (58,83) ...\n",
      "0.14705031499988763\n",
      "Training model 4114: (58,84) ...\n",
      "0.16293417099996077\n",
      "Training model 4115: (58,85) ...\n",
      "0.21819302099993365\n",
      "Training model 4116: (58,86) ...\n",
      "0.1700087409999469\n",
      "Training model 4117: (58,87) ...\n",
      "0.1324592969999685\n",
      "Training model 4118: (58,88) ...\n",
      "0.12793745499993747\n",
      "Training model 4119: (58,89) ...\n",
      "0.12893458200005625\n",
      "Training model 4120: (58,90) ...\n",
      "0.12942127600035747\n",
      "Training model 4121: (58,91) ...\n",
      "0.15990409200003342\n",
      "Training model 4122: (58,92) ...\n",
      "0.14178922400014926\n",
      "Training model 4123: (58,93) ...\n",
      "0.1498027920001732\n",
      "Training model 4124: (58,94) ...\n",
      "0.14676036299988482\n",
      "Training model 4125: (58,95) ...\n",
      "0.14338769100004356\n",
      "Training model 4126: (58,96) ...\n",
      "0.13957769499984352\n",
      "Training model 4127: (58,97) ...\n",
      "0.17148883400022896\n",
      "Training model 4128: (58,98) ...\n",
      "0.17033700599995427\n",
      "Training model 4129: (58,99) ...\n",
      "0.16144660400004796\n",
      "Training model 4130: (59,60) ...\n",
      "0.19391683200001353\n",
      "Training model 4131: (59,61) ...\n",
      "0.15327879599999505\n",
      "Training model 4132: (59,62) ...\n",
      "0.1821577780001462\n",
      "Training model 4133: (59,63) ...\n",
      "0.14866467399997418\n",
      "Training model 4134: (59,64) ...\n",
      "0.4834037719997468\n",
      "Training model 4135: (59,65) ...\n",
      "0.14355690999991566\n",
      "Training model 4136: (59,66) ...\n",
      "0.1452097359997424\n",
      "Training model 4137: (59,67) ...\n",
      "0.148900569000034\n",
      "Training model 4138: (59,68) ...\n",
      "0.14821781399996325\n",
      "Training model 4139: (59,69) ...\n",
      "0.11551828500023475\n",
      "Training model 4140: (59,70) ...\n",
      "0.16346911500022543\n",
      "Training model 4141: (59,71) ...\n",
      "0.13784538600020824\n",
      "Training model 4142: (59,72) ...\n",
      "0.13573549400007323\n",
      "Training model 4143: (59,73) ...\n",
      "0.1382191459997557\n",
      "Training model 4144: (59,74) ...\n",
      "0.13659565699981613\n",
      "Training model 4145: (59,75) ...\n",
      "0.1203547529999014\n",
      "Training model 4146: (59,76) ...\n",
      "0.14793520900002477\n",
      "Training model 4147: (59,77) ...\n",
      "0.1689930219999951\n",
      "Training model 4148: (59,78) ...\n",
      "0.1369395019996773\n",
      "Training model 4149: (59,79) ...\n",
      "0.14065144799997142\n",
      "Training model 4150: (59,80) ...\n",
      "0.10807682899985593\n",
      "Training model 4151: (59,81) ...\n",
      "0.11743550099981803\n",
      "Training model 4152: (59,82) ...\n",
      "0.12511106600004496\n",
      "Training model 4153: (59,83) ...\n",
      "0.10681602200020279\n",
      "Training model 4154: (59,84) ...\n",
      "0.1238722470002358\n",
      "Training model 4155: (59,85) ...\n",
      "0.14430307400016318\n",
      "Training model 4156: (59,86) ...\n",
      "0.12244946200007689\n",
      "Training model 4157: (59,87) ...\n",
      "0.11007276899999852\n",
      "Training model 4158: (59,88) ...\n",
      "0.13605729600021732\n",
      "Training model 4159: (59,89) ...\n",
      "0.11448388200005866\n",
      "Training model 4160: (59,90) ...\n",
      "0.13547611000012694\n",
      "Training model 4161: (59,91) ...\n",
      "0.14339048000010735\n",
      "Training model 4162: (59,92) ...\n",
      "0.17139172499992128\n",
      "Training model 4163: (59,93) ...\n",
      "0.1370650660001047\n",
      "Training model 4164: (59,94) ...\n",
      "0.17480867599988414\n",
      "Training model 4165: (59,95) ...\n",
      "0.1711964649998663\n",
      "Training model 4166: (59,96) ...\n",
      "0.1486856380001882\n",
      "Training model 4167: (59,97) ...\n",
      "0.1130193959997996\n",
      "Training model 4168: (59,98) ...\n",
      "0.1131655750000391\n",
      "Training model 4169: (59,99) ...\n",
      "0.11740934199997355\n",
      "Training model 4170: (60,61) ...\n",
      "0.4297889239996948\n",
      "Training model 4171: (60,62) ...\n",
      "0.5306127519997972\n",
      "Training model 4172: (60,63) ...\n",
      "0.305818539000029\n",
      "Training model 4173: (60,64) ...\n",
      "0.18602202300007775\n",
      "Training model 4174: (60,65) ...\n",
      "0.2885145420000299\n",
      "Training model 4175: (60,66) ...\n",
      "0.5766742599998906\n",
      "Training model 4176: (60,67) ...\n",
      "0.5731736249999813\n",
      "Training model 4177: (60,68) ...\n",
      "0.6810951809998187\n",
      "Training model 4178: (60,69) ...\n",
      "0.2300718860001325\n",
      "Training model 4179: (60,70) ...\n",
      "0.15311762800001816\n",
      "Training model 4180: (60,71) ...\n",
      "0.29670909400010714\n",
      "Training model 4181: (60,72) ...\n",
      "0.13572478300011426\n",
      "Training model 4182: (60,73) ...\n",
      "0.1649404299996604\n",
      "Training model 4183: (60,74) ...\n",
      "0.14267821299972638\n",
      "Training model 4184: (60,75) ...\n",
      "0.15151586899992253\n",
      "Training model 4185: (60,76) ...\n",
      "0.23161270699984016\n",
      "Training model 4186: (60,77) ...\n",
      "0.22114001399995686\n",
      "Training model 4187: (60,78) ...\n",
      "0.1760235060000923\n",
      "Training model 4188: (60,79) ...\n",
      "0.28692653699999937\n",
      "Training model 4189: (60,80) ...\n",
      "0.12917386599974634\n",
      "Training model 4190: (60,81) ...\n",
      "0.17170353199981037\n",
      "Training model 4191: (60,82) ...\n",
      "0.17899783099983324\n",
      "Training model 4192: (60,83) ...\n",
      "0.1471491879997302\n",
      "Training model 4193: (60,84) ...\n",
      "0.14390579400014758\n",
      "Training model 4194: (60,85) ...\n",
      "0.17710326099995655\n",
      "Training model 4195: (60,86) ...\n",
      "0.16291488200022286\n",
      "Training model 4196: (60,87) ...\n",
      "0.1404459630002748\n",
      "Training model 4197: (60,88) ...\n",
      "0.13320298500002536\n",
      "Training model 4198: (60,89) ...\n",
      "0.12812802300004478\n",
      "Training model 4199: (60,90) ...\n",
      "0.12205089200006114\n",
      "Training model 4200: (60,91) ...\n",
      "0.14644928100005927\n",
      "Training model 4201: (60,92) ...\n",
      "0.12484792799978095\n",
      "Training model 4202: (60,93) ...\n",
      "0.14130154899976333\n",
      "Training model 4203: (60,94) ...\n",
      "0.13464933999966888\n",
      "Training model 4204: (60,95) ...\n",
      "0.13588910399994347\n",
      "Training model 4205: (60,96) ...\n",
      "0.13306239299981826\n",
      "Training model 4206: (60,97) ...\n",
      "0.13006055100004232\n",
      "Training model 4207: (60,98) ...\n",
      "0.12262751200023558\n",
      "Training model 4208: (60,99) ...\n",
      "0.13608148299999812\n",
      "Training model 4209: (61,62) ...\n",
      "0.5087582249998377\n",
      "Training model 4210: (61,63) ...\n",
      "0.24996747400018648\n",
      "Training model 4211: (61,64) ...\n",
      "0.1622069189998001\n",
      "Training model 4212: (61,65) ...\n",
      "0.1655877450002663\n",
      "Training model 4213: (61,66) ...\n",
      "0.28900744599968675\n",
      "Training model 4214: (61,67) ...\n",
      "0.3003268689999459\n",
      "Training model 4215: (61,68) ...\n",
      "0.2948936589996265\n",
      "Training model 4216: (61,69) ...\n",
      "0.18356821099996523\n",
      "Training model 4217: (61,70) ...\n",
      "0.1327475210000557\n",
      "Training model 4218: (61,71) ...\n",
      "0.26426672900015546\n",
      "Training model 4219: (61,72) ...\n",
      "0.1253400320001674\n",
      "Training model 4220: (61,73) ...\n",
      "0.14068585199993322\n",
      "Training model 4221: (61,74) ...\n",
      "0.12462357000003976\n",
      "Training model 4222: (61,75) ...\n",
      "0.12872415999981968\n",
      "Training model 4223: (61,76) ...\n",
      "0.20830527600037385\n",
      "Training model 4224: (61,77) ...\n",
      "0.18785076899985143\n",
      "Training model 4225: (61,78) ...\n",
      "0.1560915479999494\n",
      "Training model 4226: (61,79) ...\n",
      "0.18361787300000287\n",
      "Training model 4227: (61,80) ...\n",
      "0.12178161199972237\n",
      "Training model 4228: (61,81) ...\n",
      "0.17507800000021234\n",
      "Training model 4229: (61,82) ...\n",
      "0.16300635399966268\n",
      "Training model 4230: (61,83) ...\n",
      "0.12633432699976765\n",
      "Training model 4231: (61,84) ...\n",
      "0.12351543200020387\n",
      "Training model 4232: (61,85) ...\n",
      "0.16786634900017816\n",
      "Training model 4233: (61,86) ...\n",
      "0.16845497399981468\n",
      "Training model 4234: (61,87) ...\n",
      "0.14580489599984503\n",
      "Training model 4235: (61,88) ...\n",
      "0.13114422299986472\n",
      "Training model 4236: (61,89) ...\n",
      "0.12147789100026785\n",
      "Training model 4237: (61,90) ...\n",
      "0.11858216800010268\n",
      "Training model 4238: (61,91) ...\n",
      "0.12841540499994153\n",
      "Training model 4239: (61,92) ...\n",
      "0.11784193100038465\n",
      "Training model 4240: (61,93) ...\n",
      "0.14075646299988875\n",
      "Training model 4241: (61,94) ...\n",
      "0.12445765599977676\n",
      "Training model 4242: (61,95) ...\n",
      "0.12335501000006843\n",
      "Training model 4243: (61,96) ...\n",
      "0.12353020199998355\n",
      "Training model 4244: (61,97) ...\n",
      "0.12144516699981978\n",
      "Training model 4245: (61,98) ...\n",
      "0.12647953900022912\n",
      "Training model 4246: (61,99) ...\n",
      "0.12604736399998728\n",
      "Training model 4247: (62,63) ...\n",
      "0.29710238699999536\n",
      "Training model 4248: (62,64) ...\n",
      "0.1977146089998314\n",
      "Training model 4249: (62,65) ...\n",
      "0.20851466499971139\n",
      "Training model 4250: (62,66) ...\n",
      "0.3994402380003521\n",
      "Training model 4251: (62,67) ...\n",
      "0.4811440170001333\n",
      "Training model 4252: (62,68) ...\n",
      "0.5060036589998163\n",
      "Training model 4253: (62,69) ...\n",
      "0.1977804869998181\n",
      "Training model 4254: (62,70) ...\n",
      "0.14019907299962142\n",
      "Training model 4255: (62,71) ...\n",
      "0.24404708099973504\n",
      "Training model 4256: (62,72) ...\n",
      "0.128209488000266\n",
      "Training model 4257: (62,73) ...\n",
      "0.17774745799988523\n",
      "Training model 4258: (62,74) ...\n",
      "0.12361528900009944\n",
      "Training model 4259: (62,75) ...\n",
      "0.13405481900008454\n",
      "Training model 4260: (62,76) ...\n",
      "0.21404841399998986\n",
      "Training model 4261: (62,77) ...\n",
      "0.2027775369997471\n",
      "Training model 4262: (62,78) ...\n",
      "0.1572705240000687\n",
      "Training model 4263: (62,79) ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.22224975300014194\n",
      "Training model 4264: (62,80) ...\n",
      "0.1403247680000277\n",
      "Training model 4265: (62,81) ...\n",
      "0.18130415799987531\n",
      "Training model 4266: (62,82) ...\n",
      "0.20432998199976282\n",
      "Training model 4267: (62,83) ...\n",
      "0.1493492409999817\n",
      "Training model 4268: (62,84) ...\n",
      "0.14217907900001592\n",
      "Training model 4269: (62,85) ...\n",
      "0.196660497999801\n",
      "Training model 4270: (62,86) ...\n",
      "0.17752310900004886\n",
      "Training model 4271: (62,87) ...\n",
      "0.12527097799966214\n",
      "Training model 4272: (62,88) ...\n",
      "0.1297487470001215\n",
      "Training model 4273: (62,89) ...\n",
      "0.1271074410001347\n",
      "Training model 4274: (62,90) ...\n",
      "0.12285828499989293\n",
      "Training model 4275: (62,91) ...\n",
      "0.13962941399995543\n",
      "Training model 4276: (62,92) ...\n",
      "0.12364217999993343\n",
      "Training model 4277: (62,93) ...\n",
      "0.1433577160000823\n",
      "Training model 4278: (62,94) ...\n",
      "0.12757906199976787\n",
      "Training model 4279: (62,95) ...\n",
      "0.12853785100014647\n",
      "Training model 4280: (62,96) ...\n",
      "0.12226652099980129\n",
      "Training model 4281: (62,97) ...\n",
      "0.1251298309998674\n",
      "Training model 4282: (62,98) ...\n",
      "0.12775895200002196\n",
      "Training model 4283: (62,99) ...\n",
      "0.13295770200011248\n",
      "Training model 4284: (63,64) ...\n",
      "0.1502653709999322\n",
      "Training model 4285: (63,65) ...\n",
      "0.16625546300019778\n",
      "Training model 4286: (63,66) ...\n",
      "0.2633940629998506\n",
      "Training model 4287: (63,67) ...\n",
      "0.2284960720003255\n",
      "Training model 4288: (63,68) ...\n",
      "0.23182336499985468\n",
      "Training model 4289: (63,69) ...\n",
      "0.2105735069999355\n",
      "Training model 4290: (63,70) ...\n",
      "0.12793443700002172\n",
      "Training model 4291: (63,71) ...\n",
      "0.19780421199993725\n",
      "Training model 4292: (63,72) ...\n",
      "0.12328133499977412\n",
      "Training model 4293: (63,73) ...\n",
      "0.1575435549998474\n",
      "Training model 4294: (63,74) ...\n",
      "0.13355139999976018\n",
      "Training model 4295: (63,75) ...\n",
      "0.13814229899981\n",
      "Training model 4296: (63,76) ...\n",
      "0.16721965399983674\n",
      "Training model 4297: (63,77) ...\n",
      "0.15219136999985494\n",
      "Training model 4298: (63,78) ...\n",
      "0.1549455639997177\n",
      "Training model 4299: (63,79) ...\n",
      "0.17247799699998723\n",
      "Training model 4300: (63,80) ...\n",
      "0.16536231300005966\n",
      "Training model 4301: (63,81) ...\n",
      "0.1682506080001076\n",
      "Training model 4302: (63,82) ...\n",
      "0.19842322099975718\n",
      "Training model 4303: (63,83) ...\n",
      "0.17820945699986623\n",
      "Training model 4304: (63,84) ...\n",
      "0.15934599900037938\n",
      "Training model 4305: (63,85) ...\n",
      "0.2052734369999598\n",
      "Training model 4306: (63,86) ...\n",
      "0.18696243200020035\n",
      "Training model 4307: (63,87) ...\n",
      "0.14887650700029553\n",
      "Training model 4308: (63,88) ...\n",
      "0.14077129499992225\n",
      "Training model 4309: (63,89) ...\n",
      "0.12880407000011473\n",
      "Training model 4310: (63,90) ...\n",
      "0.12399497400019754\n",
      "Training model 4311: (63,91) ...\n",
      "0.14281911999978547\n",
      "Training model 4312: (63,92) ...\n",
      "0.12597307800024282\n",
      "Training model 4313: (63,93) ...\n",
      "0.14110021799979222\n",
      "Training model 4314: (63,94) ...\n",
      "0.13354422500015062\n",
      "Training model 4315: (63,95) ...\n",
      "0.12388162499973987\n",
      "Training model 4316: (63,96) ...\n",
      "0.12609414000007746\n",
      "Training model 4317: (63,97) ...\n",
      "0.14150663899999927\n",
      "Training model 4318: (63,98) ...\n",
      "0.13275490200021522\n",
      "Training model 4319: (63,99) ...\n",
      "0.1464854920000107\n",
      "Training model 4320: (64,65) ...\n",
      "0.146718786999827\n",
      "Training model 4321: (64,66) ...\n",
      "0.14592363200017644\n",
      "Training model 4322: (64,67) ...\n",
      "0.14976287100034824\n",
      "Training model 4323: (64,68) ...\n",
      "0.15497889700009182\n",
      "Training model 4324: (64,69) ...\n",
      "0.12399538899990148\n",
      "Training model 4325: (64,70) ...\n",
      "0.14800379799999064\n",
      "Training model 4326: (64,71) ...\n",
      "0.1478512359999513\n",
      "Training model 4327: (64,72) ...\n",
      "0.13987501500014332\n",
      "Training model 4328: (64,73) ...\n",
      "0.1415231149999272\n",
      "Training model 4329: (64,74) ...\n",
      "0.1386652219998723\n",
      "Training model 4330: (64,75) ...\n",
      "0.12612908000028256\n",
      "Training model 4331: (64,76) ...\n",
      "0.14261709300035363\n",
      "Training model 4332: (64,77) ...\n",
      "0.1593456079999669\n",
      "Training model 4333: (64,78) ...\n",
      "0.13442887000019255\n",
      "Training model 4334: (64,79) ...\n",
      "0.1432611430000179\n",
      "Training model 4335: (64,80) ...\n",
      "0.11600266499999634\n",
      "Training model 4336: (64,81) ...\n",
      "0.12698425400003543\n",
      "Training model 4337: (64,82) ...\n",
      "0.13896767799997178\n",
      "Training model 4338: (64,83) ...\n",
      "0.11869118800041178\n",
      "Training model 4339: (64,84) ...\n",
      "0.12811916600003315\n",
      "Training model 4340: (64,85) ...\n",
      "0.14344107999977496\n",
      "Training model 4341: (64,86) ...\n",
      "0.14562363799996092\n",
      "Training model 4342: (64,87) ...\n",
      "0.11642393200008883\n",
      "Training model 4343: (64,88) ...\n",
      "0.13786451999976634\n",
      "Training model 4344: (64,89) ...\n",
      "0.12505289199998515\n",
      "Training model 4345: (64,90) ...\n",
      "0.13815821199978018\n",
      "Training model 4346: (64,91) ...\n",
      "0.14282553400016695\n",
      "Training model 4347: (64,92) ...\n",
      "0.14688899100019626\n",
      "Training model 4348: (64,93) ...\n",
      "0.14051581200010332\n",
      "Training model 4349: (64,94) ...\n",
      "0.15275131299995337\n",
      "Training model 4350: (64,95) ...\n",
      "0.15481133399998726\n",
      "Training model 4351: (64,96) ...\n",
      "0.1565171089996511\n",
      "Training model 4352: (64,97) ...\n",
      "0.11794907899957252\n",
      "Training model 4353: (64,98) ...\n",
      "0.11980025999991994\n",
      "Training model 4354: (64,99) ...\n",
      "0.12321154300025228\n",
      "Training model 4355: (65,66) ...\n",
      "0.21726927200006685\n",
      "Training model 4356: (65,67) ...\n",
      "0.21372751900025833\n",
      "Training model 4357: (65,68) ...\n",
      "0.23163711400002285\n",
      "Training model 4358: (65,69) ...\n",
      "0.15885517300011998\n",
      "Training model 4359: (65,70) ...\n",
      "0.1258775629999036\n",
      "Training model 4360: (65,71) ...\n",
      "0.20670128699975976\n",
      "Training model 4361: (65,72) ...\n",
      "0.12386406599989641\n",
      "Training model 4362: (65,73) ...\n",
      "0.13865473799978645\n",
      "Training model 4363: (65,74) ...\n",
      "0.12653441400016163\n",
      "Training model 4364: (65,75) ...\n",
      "0.13980631899994478\n",
      "Training model 4365: (65,76) ...\n",
      "0.1865527509999083\n",
      "Training model 4366: (65,77) ...\n",
      "0.1640465430000404\n",
      "Training model 4367: (65,78) ...\n",
      "0.13757025900031294\n",
      "Training model 4368: (65,79) ...\n",
      "0.2096725679998599\n",
      "Training model 4369: (65,80) ...\n",
      "0.1255432960001599\n",
      "Training model 4370: (65,81) ...\n",
      "0.13034296399973755\n",
      "Training model 4371: (65,82) ...\n",
      "0.14340289100027803\n",
      "Training model 4372: (65,83) ...\n",
      "0.1162355579999712\n",
      "Training model 4373: (65,84) ...\n",
      "0.1427058039998883\n",
      "Training model 4374: (65,85) ...\n",
      "0.1571457370000644\n",
      "Training model 4375: (65,86) ...\n",
      "0.1237092510000366\n",
      "Training model 4376: (65,87) ...\n",
      "0.11257439800010616\n",
      "Training model 4377: (65,88) ...\n",
      "0.1156531689998701\n",
      "Training model 4378: (65,89) ...\n",
      "0.1181169729998146\n",
      "Training model 4379: (65,90) ...\n",
      "0.11024540000016714\n",
      "Training model 4380: (65,91) ...\n",
      "0.11135874100000365\n",
      "Training model 4381: (65,92) ...\n",
      "0.1157086690000142\n",
      "Training model 4382: (65,93) ...\n",
      "0.12507311299987123\n",
      "Training model 4383: (65,94) ...\n",
      "0.11728780000021288\n",
      "Training model 4384: (65,95) ...\n",
      "0.1105943960001241\n",
      "Training model 4385: (65,96) ...\n",
      "0.12166355299996212\n",
      "Training model 4386: (65,97) ...\n",
      "0.12125374900006136\n",
      "Training model 4387: (65,98) ...\n",
      "0.12904118699998435\n",
      "Training model 4388: (65,99) ...\n",
      "0.12397922399986783\n",
      "Training model 4389: (66,67) ...\n",
      "0.5670020089996797\n",
      "Training model 4390: (66,68) ...\n",
      "1.1314686110004004\n",
      "Training model 4391: (66,69) ...\n",
      "0.2033434079999097\n",
      "Training model 4392: (66,70) ...\n",
      "0.13089591600009953\n",
      "Training model 4393: (66,71) ...\n",
      "0.22171688000025824\n",
      "Training model 4394: (66,72) ...\n",
      "0.11131700500027364\n",
      "Training model 4395: (66,73) ...\n",
      "0.15135259200042128\n",
      "Training model 4396: (66,74) ...\n",
      "0.11189340399960201\n",
      "Training model 4397: (66,75) ...\n",
      "0.14057367400027942\n",
      "Training model 4398: (66,76) ...\n",
      "0.16440163900006155\n",
      "Training model 4399: (66,77) ...\n",
      "0.17596226499972545\n",
      "Training model 4400: (66,78) ...\n",
      "0.1469541440001194\n",
      "Training model 4401: (66,79) ...\n",
      "0.166856184000153\n",
      "Training model 4402: (66,80) ...\n",
      "0.128195914999651\n",
      "Training model 4403: (66,81) ...\n",
      "0.17198199299991757\n",
      "Training model 4404: (66,82) ...\n",
      "0.15331017799962865\n",
      "Training model 4405: (66,83) ...\n",
      "0.13047237799992217\n",
      "Training model 4406: (66,84) ...\n",
      "0.11762238600022101\n",
      "Training model 4407: (66,85) ...\n",
      "0.16271082799994474\n",
      "Training model 4408: (66,86) ...\n",
      "0.1507183370003986\n",
      "Training model 4409: (66,87) ...\n",
      "0.1126187069999105\n",
      "Training model 4410: (66,88) ...\n",
      "0.10838593400012542\n",
      "Training model 4411: (66,89) ...\n",
      "0.10527280100041025\n",
      "Training model 4412: (66,90) ...\n",
      "0.10669443100005083\n",
      "Training model 4413: (66,91) ...\n",
      "0.11812034399963522\n",
      "Training model 4414: (66,92) ...\n",
      "0.1097628839997924\n",
      "Training model 4415: (66,93) ...\n",
      "0.11408207700014827\n",
      "Training model 4416: (66,94) ...\n",
      "0.11565724100000807\n",
      "Training model 4417: (66,95) ...\n",
      "0.10921398599975873\n",
      "Training model 4418: (66,96) ...\n",
      "0.10245766399975764\n",
      "Training model 4419: (66,97) ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.10862712900006954\n",
      "Training model 4420: (66,98) ...\n",
      "0.1187571770001341\n",
      "Training model 4421: (66,99) ...\n",
      "0.10919202300010511\n",
      "Training model 4422: (67,68) ...\n",
      "0.6853475460002301\n",
      "Training model 4423: (67,69) ...\n",
      "0.20151490899979763\n",
      "Training model 4424: (67,70) ...\n",
      "0.12616411899989544\n",
      "Training model 4425: (67,71) ...\n",
      "0.21530753600018215\n",
      "Training model 4426: (67,72) ...\n",
      "0.11800126199977967\n",
      "Training model 4427: (67,73) ...\n",
      "0.1325662200001716\n",
      "Training model 4428: (67,74) ...\n",
      "0.11431013099991105\n",
      "Training model 4429: (67,75) ...\n",
      "0.12218544799998199\n",
      "Training model 4430: (67,76) ...\n",
      "0.20430858600002466\n",
      "Training model 4431: (67,77) ...\n",
      "0.1843313530002888\n",
      "Training model 4432: (67,78) ...\n",
      "0.13377967299993543\n",
      "Training model 4433: (67,79) ...\n",
      "0.2061559179996948\n",
      "Training model 4434: (67,80) ...\n",
      "0.13209649099962917\n",
      "Training model 4435: (67,81) ...\n",
      "0.21199948100002075\n",
      "Training model 4436: (67,82) ...\n",
      "0.21672800700025618\n",
      "Training model 4437: (67,83) ...\n",
      "0.15170112400028302\n",
      "Training model 4438: (67,84) ...\n",
      "0.1688972259998991\n",
      "Training model 4439: (67,85) ...\n",
      "0.20467100199994093\n",
      "Training model 4440: (67,86) ...\n",
      "0.16287038900009065\n",
      "Training model 4441: (67,87) ...\n",
      "0.11835281499998018\n",
      "Training model 4442: (67,88) ...\n",
      "0.1398518089999925\n",
      "Training model 4443: (67,89) ...\n",
      "0.11836788899972817\n",
      "Training model 4444: (67,90) ...\n",
      "0.1101239119998354\n",
      "Training model 4445: (67,91) ...\n",
      "0.12721406699984072\n",
      "Training model 4446: (67,92) ...\n",
      "0.111962855999991\n",
      "Training model 4447: (67,93) ...\n",
      "0.12718266699994274\n",
      "Training model 4448: (67,94) ...\n",
      "0.11570701500022551\n",
      "Training model 4449: (67,95) ...\n",
      "0.11344812300012563\n",
      "Training model 4450: (67,96) ...\n",
      "0.11093686999993224\n",
      "Training model 4451: (67,97) ...\n",
      "0.11854577399981281\n",
      "Training model 4452: (67,98) ...\n",
      "0.13088793299993995\n",
      "Training model 4453: (67,99) ...\n",
      "0.12571304399989458\n",
      "Training model 4454: (68,69) ...\n",
      "0.20467850499971973\n",
      "Training model 4455: (68,70) ...\n",
      "0.12370814800033259\n",
      "Training model 4456: (68,71) ...\n",
      "0.22392705800029944\n",
      "Training model 4457: (68,72) ...\n",
      "0.11276256500013915\n",
      "Training model 4458: (68,73) ...\n",
      "0.1531679790000453\n",
      "Training model 4459: (68,74) ...\n",
      "0.11048639299997376\n",
      "Training model 4460: (68,75) ...\n",
      "0.1301904930001001\n",
      "Training model 4461: (68,76) ...\n",
      "0.19688548300018738\n",
      "Training model 4462: (68,77) ...\n",
      "0.17896576099974482\n",
      "Training model 4463: (68,78) ...\n",
      "0.14797507599996607\n",
      "Training model 4464: (68,79) ...\n",
      "0.19382085899997037\n",
      "Training model 4465: (68,80) ...\n",
      "0.12740637099977903\n",
      "Training model 4466: (68,81) ...\n",
      "0.16211890399972617\n",
      "Training model 4467: (68,82) ...\n",
      "0.16248790100007682\n",
      "Training model 4468: (68,83) ...\n",
      "0.12748195399990436\n",
      "Training model 4469: (68,84) ...\n",
      "0.11791071200013903\n",
      "Training model 4470: (68,85) ...\n",
      "0.17197855799986428\n",
      "Training model 4471: (68,86) ...\n",
      "0.15237014800004545\n",
      "Training model 4472: (68,87) ...\n",
      "0.10390751499971884\n",
      "Training model 4473: (68,88) ...\n",
      "0.1069537630000923\n",
      "Training model 4474: (68,89) ...\n",
      "0.10754231700002492\n",
      "Training model 4475: (68,90) ...\n",
      "0.10215870999991239\n",
      "Training model 4476: (68,91) ...\n",
      "0.11520355699985885\n",
      "Training model 4477: (68,92) ...\n",
      "0.10710733599989908\n",
      "Training model 4478: (68,93) ...\n",
      "0.11392407299990737\n",
      "Training model 4479: (68,94) ...\n",
      "0.1148930660001497\n",
      "Training model 4480: (68,95) ...\n",
      "0.10061462500016205\n",
      "Training model 4481: (68,96) ...\n",
      "0.10705780100033735\n",
      "Training model 4482: (68,97) ...\n",
      "0.10570570099980614\n",
      "Training model 4483: (68,98) ...\n",
      "0.11777642900005958\n",
      "Training model 4484: (68,99) ...\n",
      "0.10925391000000673\n",
      "Training model 4485: (69,70) ...\n",
      "0.11802960299974075\n",
      "Training model 4486: (69,71) ...\n",
      "0.17542170900014753\n",
      "Training model 4487: (69,72) ...\n",
      "0.10676721600020755\n",
      "Training model 4488: (69,73) ...\n",
      "0.14019254400000136\n",
      "Training model 4489: (69,74) ...\n",
      "0.09857052300003488\n",
      "Training model 4490: (69,75) ...\n",
      "0.11599805299965738\n",
      "Training model 4491: (69,76) ...\n",
      "0.17634704200008855\n",
      "Training model 4492: (69,77) ...\n",
      "0.15373928200006048\n",
      "Training model 4493: (69,78) ...\n",
      "0.13738047300012113\n",
      "Training model 4494: (69,79) ...\n",
      "0.177260380000007\n",
      "Training model 4495: (69,80) ...\n",
      "0.10974357099985355\n",
      "Training model 4496: (69,81) ...\n",
      "0.1170825720000721\n",
      "Training model 4497: (69,82) ...\n",
      "0.139478138999948\n",
      "Training model 4498: (69,83) ...\n",
      "0.11909848799996325\n",
      "Training model 4499: (69,84) ...\n",
      "0.12660657099968375\n",
      "Training model 4500: (69,85) ...\n",
      "0.13432717799969396\n",
      "Training model 4501: (69,86) ...\n",
      "0.13733628399995723\n",
      "Training model 4502: (69,87) ...\n",
      "0.12122761299997364\n",
      "Training model 4503: (69,88) ...\n",
      "0.1073402659999374\n",
      "Training model 4504: (69,89) ...\n",
      "0.10986321700011104\n",
      "Training model 4505: (69,90) ...\n",
      "0.10323273099993457\n",
      "Training model 4506: (69,91) ...\n",
      "0.1059193520000008\n",
      "Training model 4507: (69,92) ...\n",
      "0.10153709799988064\n",
      "Training model 4508: (69,93) ...\n",
      "0.11458933599988086\n",
      "Training model 4509: (69,94) ...\n",
      "0.10971578399994542\n",
      "Training model 4510: (69,95) ...\n",
      "0.09674129100039863\n",
      "Training model 4511: (69,96) ...\n",
      "0.09899885100003303\n",
      "Training model 4512: (69,97) ...\n",
      "0.10798887800001467\n",
      "Training model 4513: (69,98) ...\n",
      "0.09887326399984886\n",
      "Training model 4514: (69,99) ...\n",
      "0.1184122629997546\n",
      "Training model 4515: (70,71) ...\n",
      "0.17846041700022397\n",
      "Training model 4516: (70,72) ...\n",
      "0.23734829899967735\n",
      "Training model 4517: (70,73) ...\n",
      "0.3619448670001475\n",
      "Training model 4518: (70,74) ...\n",
      "0.26771845599978406\n",
      "Training model 4519: (70,75) ...\n",
      "0.22527100399975097\n",
      "Training model 4520: (70,76) ...\n",
      "0.16255566400013777\n",
      "Training model 4521: (70,77) ...\n",
      "0.3903613789998417\n",
      "Training model 4522: (70,78) ...\n",
      "0.23759168299966404\n",
      "Training model 4523: (70,79) ...\n",
      "0.2175269889999072\n",
      "Training model 4524: (70,80) ...\n",
      "0.10893065499976728\n",
      "Training model 4525: (70,81) ...\n",
      "0.12201050700014093\n",
      "Training model 4526: (70,82) ...\n",
      "0.13440678599999956\n",
      "Training model 4527: (70,83) ...\n",
      "0.10916086099996392\n",
      "Training model 4528: (70,84) ...\n",
      "0.11327512899970316\n",
      "Training model 4529: (70,85) ...\n",
      "0.12692699700028243\n",
      "Training model 4530: (70,86) ...\n",
      "0.12231648799979666\n",
      "Training model 4531: (70,87) ...\n",
      "0.11273260899997695\n",
      "Training model 4532: (70,88) ...\n",
      "0.12721255099995687\n",
      "Training model 4533: (70,89) ...\n",
      "0.11409611699991729\n",
      "Training model 4534: (70,90) ...\n",
      "0.1202675670001554\n",
      "Training model 4535: (70,91) ...\n",
      "0.15281883199986623\n",
      "Training model 4536: (70,92) ...\n",
      "0.16946591699979763\n",
      "Training model 4537: (70,93) ...\n",
      "0.12206026899957578\n",
      "Training model 4538: (70,94) ...\n",
      "0.17154183000002377\n",
      "Training model 4539: (70,95) ...\n",
      "0.1450310739996894\n",
      "Training model 4540: (70,96) ...\n",
      "0.11651095299976078\n",
      "Training model 4541: (70,97) ...\n",
      "0.10617924200005291\n",
      "Training model 4542: (70,98) ...\n",
      "0.11129216600011205\n",
      "Training model 4543: (70,99) ...\n",
      "0.110676445000081\n",
      "Training model 4544: (71,72) ...\n",
      "0.14922031400010383\n",
      "Training model 4545: (71,73) ...\n",
      "0.23855502900005376\n",
      "Training model 4546: (71,74) ...\n",
      "0.17380986199987092\n",
      "Training model 4547: (71,75) ...\n",
      "0.20509190700022373\n",
      "Training model 4548: (71,76) ...\n",
      "0.3086487949999537\n",
      "Training model 4549: (71,77) ...\n",
      "0.30119640300017636\n",
      "Training model 4550: (71,78) ...\n",
      "0.328099451000071\n",
      "Training model 4551: (71,79) ...\n",
      "0.3191436420001992\n",
      "Training model 4552: (71,80) ...\n",
      "0.13164329300025202\n",
      "Training model 4553: (71,81) ...\n",
      "0.12551033099998676\n",
      "Training model 4554: (71,82) ...\n",
      "0.14569394400041347\n",
      "Training model 4555: (71,83) ...\n",
      "0.13377984799990372\n",
      "Training model 4556: (71,84) ...\n",
      "0.12635139100029846\n",
      "Training model 4557: (71,85) ...\n",
      "0.15942020900001808\n",
      "Training model 4558: (71,86) ...\n",
      "0.15315527899974768\n",
      "Training model 4559: (71,87) ...\n",
      "0.1272533400001521\n",
      "Training model 4560: (71,88) ...\n",
      "0.13877439900034005\n",
      "Training model 4561: (71,89) ...\n",
      "0.11826466100001198\n",
      "Training model 4562: (71,90) ...\n",
      "0.12102600300022459\n",
      "Training model 4563: (71,91) ...\n",
      "0.1292127189999519\n",
      "Training model 4564: (71,92) ...\n",
      "0.12493592400005582\n",
      "Training model 4565: (71,93) ...\n",
      "0.13228007399993658\n",
      "Training model 4566: (71,94) ...\n",
      "0.13953035099984845\n",
      "Training model 4567: (71,95) ...\n",
      "0.12123033899979418\n",
      "Training model 4568: (71,96) ...\n",
      "0.12706554099986533\n",
      "Training model 4569: (71,97) ...\n",
      "0.12429777399984232\n",
      "Training model 4570: (71,98) ...\n",
      "0.12016995399972075\n",
      "Training model 4571: (71,99) ...\n",
      "0.13293823499998325\n",
      "Training model 4572: (72,73) ...\n",
      "0.3652256400000624\n",
      "Training model 4573: (72,74) ...\n",
      "0.8581834790002176\n",
      "Training model 4574: (72,75) ...\n",
      "0.22798975099976815\n",
      "Training model 4575: (72,76) ...\n",
      "0.13970220800001698\n",
      "Training model 4576: (72,77) ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2072612899996784\n",
      "Training model 4577: (72,78) ...\n",
      "0.15024072400001387\n",
      "Training model 4578: (72,79) ...\n",
      "0.14667945599967425\n",
      "Training model 4579: (72,80) ...\n",
      "0.10781378299998323\n",
      "Training model 4580: (72,81) ...\n",
      "0.11271817200031364\n",
      "Training model 4581: (72,82) ...\n",
      "0.12899007300029552\n",
      "Training model 4582: (72,83) ...\n",
      "0.11054868200017154\n",
      "Training model 4583: (72,84) ...\n",
      "0.11943086699966443\n",
      "Training model 4584: (72,85) ...\n",
      "0.13076562599962926\n",
      "Training model 4585: (72,86) ...\n",
      "0.11789416200008418\n",
      "Training model 4586: (72,87) ...\n",
      "0.10928477500010558\n",
      "Training model 4587: (72,88) ...\n",
      "0.13190599400013525\n",
      "Training model 4588: (72,89) ...\n",
      "0.1124885809999796\n",
      "Training model 4589: (72,90) ...\n",
      "0.11305635500002609\n",
      "Training model 4590: (72,91) ...\n",
      "0.13105566000012914\n",
      "Training model 4591: (72,92) ...\n",
      "0.15907677599989256\n",
      "Training model 4592: (72,93) ...\n",
      "0.14192785600016578\n",
      "Training model 4593: (72,94) ...\n",
      "0.1802271279998422\n",
      "Training model 4594: (72,95) ...\n",
      "0.14871703099970546\n",
      "Training model 4595: (72,96) ...\n",
      "0.1335894339999868\n",
      "Training model 4596: (72,97) ...\n",
      "0.10419914899966898\n",
      "Training model 4597: (72,98) ...\n",
      "0.10549199100023543\n",
      "Training model 4598: (72,99) ...\n",
      "0.11568555900021238\n",
      "Training model 4599: (73,74) ...\n",
      "0.6733863810000003\n",
      "Training model 4600: (73,75) ...\n",
      "0.3366954159996567\n",
      "Training model 4601: (73,76) ...\n",
      "0.22994784899992737\n",
      "Training model 4602: (73,77) ...\n",
      "0.5193659599999592\n",
      "Training model 4603: (73,78) ...\n",
      "0.3924890729999788\n",
      "Training model 4604: (73,79) ...\n",
      "0.24185695300002408\n",
      "Training model 4605: (73,80) ...\n",
      "0.1307884389998435\n",
      "Training model 4606: (73,81) ...\n",
      "0.12416108399975201\n",
      "Training model 4607: (73,82) ...\n",
      "0.13398051199965266\n",
      "Training model 4608: (73,83) ...\n",
      "0.12912741400032246\n",
      "Training model 4609: (73,84) ...\n",
      "0.1325673530000131\n",
      "Training model 4610: (73,85) ...\n",
      "0.1384741279998707\n",
      "Training model 4611: (73,86) ...\n",
      "0.1290694990002521\n",
      "Training model 4612: (73,87) ...\n",
      "0.11286624100011977\n",
      "Training model 4613: (73,88) ...\n",
      "0.11836838499993974\n",
      "Training model 4614: (73,89) ...\n",
      "0.11715782500004934\n",
      "Training model 4615: (73,90) ...\n",
      "0.11811316499961322\n",
      "Training model 4616: (73,91) ...\n",
      "0.13001359200006846\n",
      "Training model 4617: (73,92) ...\n",
      "0.1645700549997855\n",
      "Training model 4618: (73,93) ...\n",
      "0.14461088400003064\n",
      "Training model 4619: (73,94) ...\n",
      "0.1603105650001453\n",
      "Training model 4620: (73,95) ...\n",
      "0.1332661609999377\n",
      "Training model 4621: (73,96) ...\n",
      "0.11590417800016439\n",
      "Training model 4622: (73,97) ...\n",
      "0.10948632300005556\n",
      "Training model 4623: (73,98) ...\n",
      "0.12180598399982046\n",
      "Training model 4624: (73,99) ...\n",
      "0.11977255600004355\n",
      "Training model 4625: (74,75) ...\n",
      "0.21963845900017986\n",
      "Training model 4626: (74,76) ...\n",
      "0.1718240479999622\n",
      "Training model 4627: (74,77) ...\n",
      "0.29077702700033115\n",
      "Training model 4628: (74,78) ...\n",
      "0.20255274999999529\n",
      "Training model 4629: (74,79) ...\n",
      "0.17352170599997407\n",
      "Training model 4630: (74,80) ...\n",
      "0.10680656500016994\n",
      "Training model 4631: (74,81) ...\n",
      "0.12125105299992356\n",
      "Training model 4632: (74,82) ...\n",
      "0.1304897339996387\n",
      "Training model 4633: (74,83) ...\n",
      "0.11354603799964025\n",
      "Training model 4634: (74,84) ...\n",
      "0.12073043700002017\n",
      "Training model 4635: (74,85) ...\n",
      "0.13281203099995764\n",
      "Training model 4636: (74,86) ...\n",
      "0.12897036899994418\n",
      "Training model 4637: (74,87) ...\n",
      "0.106775817000198\n",
      "Training model 4638: (74,88) ...\n",
      "0.11764299800006484\n",
      "Training model 4639: (74,89) ...\n",
      "0.12154645900000105\n",
      "Training model 4640: (74,90) ...\n",
      "0.11464725099995121\n",
      "Training model 4641: (74,91) ...\n",
      "0.13032347799980926\n",
      "Training model 4642: (74,92) ...\n",
      "0.15578934899986052\n",
      "Training model 4643: (74,93) ...\n",
      "0.14124133299992536\n",
      "Training model 4644: (74,94) ...\n",
      "0.17259198699957778\n",
      "Training model 4645: (74,95) ...\n",
      "0.14966197100011414\n",
      "Training model 4646: (74,96) ...\n",
      "0.14339030000019193\n",
      "Training model 4647: (74,97) ...\n",
      "0.10692712600030063\n",
      "Training model 4648: (74,98) ...\n",
      "0.10576252700002442\n",
      "Training model 4649: (74,99) ...\n",
      "0.11815412099986133\n",
      "Training model 4650: (75,76) ...\n",
      "0.19005446300025142\n",
      "Training model 4651: (75,77) ...\n",
      "0.2534592049996718\n",
      "Training model 4652: (75,78) ...\n",
      "0.2579617410001447\n",
      "Training model 4653: (75,79) ...\n",
      "0.18279620799967233\n",
      "Training model 4654: (75,80) ...\n",
      "0.1144657400000142\n",
      "Training model 4655: (75,81) ...\n",
      "0.11332180699992023\n",
      "Training model 4656: (75,82) ...\n",
      "0.11632618300018294\n",
      "Training model 4657: (75,83) ...\n",
      "0.11041128899978503\n",
      "Training model 4658: (75,84) ...\n",
      "0.11499407600013001\n",
      "Training model 4659: (75,85) ...\n",
      "0.12982421300011993\n",
      "Training model 4660: (75,86) ...\n",
      "0.11393863800003601\n",
      "Training model 4661: (75,87) ...\n",
      "0.11190899199982596\n",
      "Training model 4662: (75,88) ...\n",
      "0.12071749999995518\n",
      "Training model 4663: (75,89) ...\n",
      "0.10715257799984101\n",
      "Training model 4664: (75,90) ...\n",
      "0.11807499899987306\n",
      "Training model 4665: (75,91) ...\n",
      "0.12916796399986197\n",
      "Training model 4666: (75,92) ...\n",
      "0.13308978399982152\n",
      "Training model 4667: (75,93) ...\n",
      "0.12660815900017042\n",
      "Training model 4668: (75,94) ...\n",
      "0.1453861780000807\n",
      "Training model 4669: (75,95) ...\n",
      "0.1203931290001492\n",
      "Training model 4670: (75,96) ...\n",
      "0.11464887600004658\n",
      "Training model 4671: (75,97) ...\n",
      "0.11195878800026549\n",
      "Training model 4672: (75,98) ...\n",
      "0.11097892399993725\n",
      "Training model 4673: (75,99) ...\n",
      "0.11511577900000702\n",
      "Training model 4674: (76,77) ...\n",
      "0.3529337800000576\n",
      "Training model 4675: (76,78) ...\n",
      "0.20153626199999053\n",
      "Training model 4676: (76,79) ...\n",
      "0.22947132799981773\n",
      "Training model 4677: (76,80) ...\n",
      "0.12481454299995676\n",
      "Training model 4678: (76,81) ...\n",
      "0.13494424500004243\n",
      "Training model 4679: (76,82) ...\n",
      "0.17806724499996562\n",
      "Training model 4680: (76,83) ...\n",
      "0.1323059899996224\n",
      "Training model 4681: (76,84) ...\n",
      "0.13553210600002785\n",
      "Training model 4682: (76,85) ...\n",
      "0.15938797199987675\n",
      "Training model 4683: (76,86) ...\n",
      "0.1442395580002085\n",
      "Training model 4684: (76,87) ...\n",
      "0.13408311400007733\n",
      "Training model 4685: (76,88) ...\n",
      "0.13464435400010188\n",
      "Training model 4686: (76,89) ...\n",
      "0.1202542529999846\n",
      "Training model 4687: (76,90) ...\n",
      "0.11984260200006247\n",
      "Training model 4688: (76,91) ...\n",
      "0.13601942700006475\n",
      "Training model 4689: (76,92) ...\n",
      "0.12208691599971644\n",
      "Training model 4690: (76,93) ...\n",
      "0.12946187099987583\n",
      "Training model 4691: (76,94) ...\n",
      "0.1292906190001304\n",
      "Training model 4692: (76,95) ...\n",
      "0.11893945100018755\n",
      "Training model 4693: (76,96) ...\n",
      "0.12232904999973471\n",
      "Training model 4694: (76,97) ...\n",
      "0.11462418300015997\n",
      "Training model 4695: (76,98) ...\n",
      "0.12209371700009797\n",
      "Training model 4696: (76,99) ...\n",
      "0.12189679799985242\n",
      "Training model 4697: (77,78) ...\n",
      "0.279993819000083\n",
      "Training model 4698: (77,79) ...\n",
      "0.2666207779998331\n",
      "Training model 4699: (77,80) ...\n",
      "0.11691950400017959\n",
      "Training model 4700: (77,81) ...\n",
      "0.12570599999980914\n",
      "Training model 4701: (77,82) ...\n",
      "0.15184557500015217\n",
      "Training model 4702: (77,83) ...\n",
      "0.11876931100005095\n",
      "Training model 4703: (77,84) ...\n",
      "0.12433421300011105\n",
      "Training model 4704: (77,85) ...\n",
      "0.14307458700022835\n",
      "Training model 4705: (77,86) ...\n",
      "0.14279111599989847\n",
      "Training model 4706: (77,87) ...\n",
      "0.13007131599988497\n",
      "Training model 4707: (77,88) ...\n",
      "0.12569593499983966\n",
      "Training model 4708: (77,89) ...\n",
      "0.11188201599998138\n",
      "Training model 4709: (77,90) ...\n",
      "0.11612684900001113\n",
      "Training model 4710: (77,91) ...\n",
      "0.14537796800004799\n",
      "Training model 4711: (77,92) ...\n",
      "0.14526094699976966\n",
      "Training model 4712: (77,93) ...\n",
      "0.1306843890001801\n",
      "Training model 4713: (77,94) ...\n",
      "0.1599063759999808\n",
      "Training model 4714: (77,95) ...\n",
      "0.13242265400003816\n",
      "Training model 4715: (77,96) ...\n",
      "0.13133040400043683\n",
      "Training model 4716: (77,97) ...\n",
      "0.10653301999991527\n",
      "Training model 4717: (77,98) ...\n",
      "0.11044321400004264\n",
      "Training model 4718: (77,99) ...\n",
      "0.11577996799996981\n",
      "Training model 4719: (78,79) ...\n",
      "0.2516535009999643\n",
      "Training model 4720: (78,80) ...\n",
      "0.12165644000015163\n",
      "Training model 4721: (78,81) ...\n",
      "0.13636320299974614\n",
      "Training model 4722: (78,82) ...\n",
      "0.1275460810002187\n",
      "Training model 4723: (78,83) ...\n",
      "0.12113430499994138\n",
      "Training model 4724: (78,84) ...\n",
      "0.12039773900005457\n",
      "Training model 4725: (78,85) ...\n",
      "0.12527433800005383\n",
      "Training model 4726: (78,86) ...\n",
      "0.12994136900033482\n",
      "Training model 4727: (78,87) ...\n",
      "0.11860433899983036\n",
      "Training model 4728: (78,88) ...\n",
      "0.11588152000012997\n",
      "Training model 4729: (78,89) ...\n",
      "0.11670214000014312\n",
      "Training model 4730: (78,90) ...\n",
      "0.11165010799959418\n",
      "Training model 4731: (78,91) ...\n",
      "0.12565710099988792\n",
      "Training model 4732: (78,92) ...\n",
      "0.1320640359999743\n",
      "Training model 4733: (78,93) ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12557593199971961\n",
      "Training model 4734: (78,94) ...\n",
      "0.15123813199988945\n",
      "Training model 4735: (78,95) ...\n",
      "0.11659911100014142\n",
      "Training model 4736: (78,96) ...\n",
      "0.11534800599974915\n",
      "Training model 4737: (78,97) ...\n",
      "0.11382908099994893\n",
      "Training model 4738: (78,98) ...\n",
      "0.1341941619998579\n",
      "Training model 4739: (78,99) ...\n",
      "0.12902527699998245\n",
      "Training model 4740: (79,80) ...\n",
      "0.1201094819998616\n",
      "Training model 4741: (79,81) ...\n",
      "0.13663356699998985\n",
      "Training model 4742: (79,82) ...\n",
      "0.1559273499997289\n",
      "Training model 4743: (79,83) ...\n",
      "0.13155297499997687\n",
      "Training model 4744: (79,84) ...\n",
      "0.13205727399963507\n",
      "Training model 4745: (79,85) ...\n",
      "0.1391346719997273\n",
      "Training model 4746: (79,86) ...\n",
      "0.13705802599997696\n",
      "Training model 4747: (79,87) ...\n",
      "0.11668445300028907\n",
      "Training model 4748: (79,88) ...\n",
      "0.1344510399999308\n",
      "Training model 4749: (79,89) ...\n",
      "0.1231948940003349\n",
      "Training model 4750: (79,90) ...\n",
      "0.12633387000005314\n",
      "Training model 4751: (79,91) ...\n",
      "0.14058782599977349\n",
      "Training model 4752: (79,92) ...\n",
      "0.12702788499973394\n",
      "Training model 4753: (79,93) ...\n",
      "0.13096527700008664\n",
      "Training model 4754: (79,94) ...\n",
      "0.13852665800004615\n",
      "Training model 4755: (79,95) ...\n",
      "0.12088928899993334\n",
      "Training model 4756: (79,96) ...\n",
      "0.12910014399994907\n",
      "Training model 4757: (79,97) ...\n",
      "0.11864736799998354\n",
      "Training model 4758: (79,98) ...\n",
      "0.1258719700003894\n",
      "Training model 4759: (79,99) ...\n",
      "0.12071052700002838\n",
      "Training model 4760: (80,81) ...\n",
      "0.16531085199994777\n",
      "Training model 4761: (80,82) ...\n",
      "0.2091193450000901\n",
      "Training model 4762: (80,83) ...\n",
      "0.2242048920002162\n",
      "Training model 4763: (80,84) ...\n",
      "0.16287823099992238\n",
      "Training model 4764: (80,85) ...\n",
      "0.23089977700010422\n",
      "Training model 4765: (80,86) ...\n",
      "0.1899265019997074\n",
      "Training model 4766: (80,87) ...\n",
      "0.12073509299989382\n",
      "Training model 4767: (80,88) ...\n",
      "0.13044427599970732\n",
      "Training model 4768: (80,89) ...\n",
      "0.11416253200013671\n",
      "Training model 4769: (80,90) ...\n",
      "0.11412752300020657\n",
      "Training model 4770: (80,91) ...\n",
      "0.1570089049996568\n",
      "Training model 4771: (80,92) ...\n",
      "0.13425380600028802\n",
      "Training model 4772: (80,93) ...\n",
      "0.20976403300028323\n",
      "Training model 4773: (80,94) ...\n",
      "0.12986569299982875\n",
      "Training model 4774: (80,95) ...\n",
      "0.11252002199989874\n",
      "Training model 4775: (80,96) ...\n",
      "0.1509912900000927\n",
      "Training model 4776: (80,97) ...\n",
      "0.15773610099995494\n",
      "Training model 4777: (80,98) ...\n",
      "0.19044332900011796\n",
      "Training model 4778: (80,99) ...\n",
      "0.18012958799999979\n",
      "Training model 4779: (81,82) ...\n",
      "0.2871158680000008\n",
      "Training model 4780: (81,83) ...\n",
      "0.19857397099985974\n",
      "Training model 4781: (81,84) ...\n",
      "0.12915144900034647\n",
      "Training model 4782: (81,85) ...\n",
      "0.27055528200025947\n",
      "Training model 4783: (81,86) ...\n",
      "0.2880119100000229\n",
      "Training model 4784: (81,87) ...\n",
      "0.1185629980000158\n",
      "Training model 4785: (81,88) ...\n",
      "0.1121252220000315\n",
      "Training model 4786: (81,89) ...\n",
      "0.18303226899979563\n",
      "Training model 4787: (81,90) ...\n",
      "0.11180922299990925\n",
      "Training model 4788: (81,91) ...\n",
      "0.14603566200003115\n",
      "Training model 4789: (81,92) ...\n",
      "0.13534810500004824\n",
      "Training model 4790: (81,93) ...\n",
      "0.14992888799997672\n",
      "Training model 4791: (81,94) ...\n",
      "0.12977667599989218\n",
      "Training model 4792: (81,95) ...\n",
      "0.11115525700006401\n",
      "Training model 4793: (81,96) ...\n",
      "0.1129177789998721\n",
      "Training model 4794: (81,97) ...\n",
      "0.13785237100000813\n",
      "Training model 4795: (81,98) ...\n",
      "0.1377339519999623\n",
      "Training model 4796: (81,99) ...\n",
      "0.1817704169998251\n",
      "Training model 4797: (82,83) ...\n",
      "0.29861536399994293\n",
      "Training model 4798: (82,84) ...\n",
      "0.1686846580000747\n",
      "Training model 4799: (82,85) ...\n",
      "0.4256687410002087\n",
      "Training model 4800: (82,86) ...\n",
      "0.840454667999893\n",
      "Training model 4801: (82,87) ...\n",
      "0.12521139400041648\n",
      "Training model 4802: (82,88) ...\n",
      "0.1378822259998742\n",
      "Training model 4803: (82,89) ...\n",
      "0.14430135799966592\n",
      "Training model 4804: (82,90) ...\n",
      "0.1371685899998738\n",
      "Training model 4805: (82,91) ...\n",
      "0.2450414200002342\n",
      "Training model 4806: (82,92) ...\n",
      "0.15445148900016648\n",
      "Training model 4807: (82,93) ...\n",
      "0.23042343399993115\n",
      "Training model 4808: (82,94) ...\n",
      "0.14901979800015397\n",
      "Training model 4809: (82,95) ...\n",
      "0.13649539800007915\n",
      "Training model 4810: (82,96) ...\n",
      "0.1464879549998841\n",
      "Training model 4811: (82,97) ...\n",
      "0.15490567000006195\n",
      "Training model 4812: (82,98) ...\n",
      "0.15629353600024842\n",
      "Training model 4813: (82,99) ...\n",
      "0.16818165700033205\n",
      "Training model 4814: (83,84) ...\n",
      "0.13348857199980557\n",
      "Training model 4815: (83,85) ...\n",
      "0.23691310899994278\n",
      "Training model 4816: (83,86) ...\n",
      "0.28993900900013614\n",
      "Training model 4817: (83,87) ...\n",
      "0.10793641800000842\n",
      "Training model 4818: (83,88) ...\n",
      "0.10980462799989255\n",
      "Training model 4819: (83,89) ...\n",
      "0.1067437560000144\n",
      "Training model 4820: (83,90) ...\n",
      "0.11392277100003412\n",
      "Training model 4821: (83,91) ...\n",
      "0.15035247799960416\n",
      "Training model 4822: (83,92) ...\n",
      "0.11712378899983378\n",
      "Training model 4823: (83,93) ...\n",
      "0.1337678939999023\n",
      "Training model 4824: (83,94) ...\n",
      "0.12554537200003324\n",
      "Training model 4825: (83,95) ...\n",
      "0.10357070800000656\n",
      "Training model 4826: (83,96) ...\n",
      "0.10755698399998437\n",
      "Training model 4827: (83,97) ...\n",
      "0.12767404600026566\n",
      "Training model 4828: (83,98) ...\n",
      "0.11606471600043733\n",
      "Training model 4829: (83,99) ...\n",
      "0.14378774699980568\n",
      "Training model 4830: (84,85) ...\n",
      "0.18433366399995066\n",
      "Training model 4831: (84,86) ...\n",
      "0.1522490329998618\n",
      "Training model 4832: (84,87) ...\n",
      "0.1351406290000341\n",
      "Training model 4833: (84,88) ...\n",
      "0.17579641400016044\n",
      "Training model 4834: (84,89) ...\n",
      "0.13876201499988383\n",
      "Training model 4835: (84,90) ...\n",
      "0.14088291600000957\n",
      "Training model 4836: (84,91) ...\n",
      "0.1480226630001198\n",
      "Training model 4837: (84,92) ...\n",
      "0.12242184999968231\n",
      "Training model 4838: (84,93) ...\n",
      "0.15912611700014168\n",
      "Training model 4839: (84,94) ...\n",
      "0.18352935799975967\n",
      "Training model 4840: (84,95) ...\n",
      "0.10991437000029691\n",
      "Training model 4841: (84,96) ...\n",
      "0.14590529599990987\n",
      "Training model 4842: (84,97) ...\n",
      "0.14390207100041152\n",
      "Training model 4843: (84,98) ...\n",
      "0.11050373099988064\n",
      "Training model 4844: (84,99) ...\n",
      "0.1628130770000098\n",
      "Training model 4845: (85,86) ...\n",
      "0.3884913619999679\n",
      "Training model 4846: (85,87) ...\n",
      "0.14245072799985792\n",
      "Training model 4847: (85,88) ...\n",
      "0.14254614900028173\n",
      "Training model 4848: (85,89) ...\n",
      "0.14387808199990104\n",
      "Training model 4849: (85,90) ...\n",
      "0.12684259100024065\n",
      "Training model 4850: (85,91) ...\n",
      "0.2244835020001119\n",
      "Training model 4851: (85,92) ...\n",
      "0.14111815800015393\n",
      "Training model 4852: (85,93) ...\n",
      "0.21024371300018174\n",
      "Training model 4853: (85,94) ...\n",
      "0.1449625229997764\n",
      "Training model 4854: (85,95) ...\n",
      "0.12208243299983224\n",
      "Training model 4855: (85,96) ...\n",
      "0.13276435699981448\n",
      "Training model 4856: (85,97) ...\n",
      "0.17241873300008592\n",
      "Training model 4857: (85,98) ...\n",
      "0.20196511899985126\n",
      "Training model 4858: (85,99) ...\n",
      "0.23398440299979484\n",
      "Training model 4859: (86,87) ...\n",
      "0.1293149429998266\n",
      "Training model 4860: (86,88) ...\n",
      "0.133241327000178\n",
      "Training model 4861: (86,89) ...\n",
      "0.13075349299970185\n",
      "Training model 4862: (86,90) ...\n",
      "0.13965759899974728\n",
      "Training model 4863: (86,91) ...\n",
      "0.21718261899968638\n",
      "Training model 4864: (86,92) ...\n",
      "0.13586015299961218\n",
      "Training model 4865: (86,93) ...\n",
      "0.1902694190002876\n",
      "Training model 4866: (86,94) ...\n",
      "0.14265553600034764\n",
      "Training model 4867: (86,95) ...\n",
      "0.12760650800009898\n",
      "Training model 4868: (86,96) ...\n",
      "0.11882173599997259\n",
      "Training model 4869: (86,97) ...\n",
      "0.15735087400025805\n",
      "Training model 4870: (86,98) ...\n",
      "0.13871770500009006\n",
      "Training model 4871: (86,99) ...\n",
      "0.1935413320002226\n",
      "Training model 4872: (87,88) ...\n",
      "0.14906460200018046\n",
      "Training model 4873: (87,89) ...\n",
      "0.13442267900018123\n",
      "Training model 4874: (87,90) ...\n",
      "0.12009974000011425\n",
      "Training model 4875: (87,91) ...\n",
      "0.12564412500023536\n",
      "Training model 4876: (87,92) ...\n",
      "0.11394267900004706\n",
      "Training model 4877: (87,93) ...\n",
      "0.15734728400002496\n",
      "Training model 4878: (87,94) ...\n",
      "0.12302522200025123\n",
      "Training model 4879: (87,95) ...\n",
      "0.10602230499989673\n",
      "Training model 4880: (87,96) ...\n",
      "0.1467891519996556\n",
      "Training model 4881: (87,97) ...\n",
      "0.12513314600028025\n",
      "Training model 4882: (87,98) ...\n",
      "0.1068417540000155\n",
      "Training model 4883: (87,99) ...\n",
      "0.13871297600007892\n",
      "Training model 4884: (88,89) ...\n",
      "0.164094207999824\n",
      "Training model 4885: (88,90) ...\n",
      "0.3228589740001553\n",
      "Training model 4886: (88,91) ...\n",
      "0.18429833399977724\n",
      "Training model 4887: (88,92) ...\n",
      "0.18731040900001972\n",
      "Training model 4888: (88,93) ...\n",
      "0.2528935189998265\n",
      "Training model 4889: (88,94) ...\n",
      "0.19658368999989762\n",
      "Training model 4890: (88,95) ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.13124355599984483\n",
      "Training model 4891: (88,96) ...\n",
      "0.24985240600017278\n",
      "Training model 4892: (88,97) ...\n",
      "0.13195327799985535\n",
      "Training model 4893: (88,98) ...\n",
      "0.1110423649997756\n",
      "Training model 4894: (88,99) ...\n",
      "0.1476231279998501\n",
      "Training model 4895: (89,90) ...\n",
      "0.12644311299982292\n",
      "Training model 4896: (89,91) ...\n",
      "0.145393045000219\n",
      "Training model 4897: (89,92) ...\n",
      "0.154779888000121\n",
      "Training model 4898: (89,93) ...\n",
      "0.1732279309999285\n",
      "Training model 4899: (89,94) ...\n",
      "0.16466048800020872\n",
      "Training model 4900: (89,95) ...\n",
      "0.11801338499981284\n",
      "Training model 4901: (89,96) ...\n",
      "0.14236455899981593\n",
      "Training model 4902: (89,97) ...\n",
      "0.14176836300021023\n",
      "Training model 4903: (89,98) ...\n",
      "0.11082788099975005\n",
      "Training model 4904: (89,99) ...\n",
      "0.2518996369999513\n",
      "Training model 4905: (90,91) ...\n",
      "0.17034671399960644\n",
      "Training model 4906: (90,92) ...\n",
      "0.16408374599996023\n",
      "Training model 4907: (90,93) ...\n",
      "0.18998432699982004\n",
      "Training model 4908: (90,94) ...\n",
      "0.19211502799998925\n",
      "Training model 4909: (90,95) ...\n",
      "0.13376143599998613\n",
      "Training model 4910: (90,96) ...\n",
      "0.1841506490000029\n",
      "Training model 4911: (90,97) ...\n",
      "0.12525921099995685\n",
      "Training model 4912: (90,98) ...\n",
      "0.10917367799993372\n",
      "Training model 4913: (90,99) ...\n",
      "0.11876001600012387\n",
      "Training model 4914: (91,92) ...\n",
      "0.2429298000001836\n",
      "Training model 4915: (91,93) ...\n",
      "0.27050123399976655\n",
      "Training model 4916: (91,94) ...\n",
      "0.19871906099979242\n",
      "Training model 4917: (91,95) ...\n",
      "0.19576551399995878\n",
      "Training model 4918: (91,96) ...\n",
      "0.19872018599971852\n",
      "Training model 4919: (91,97) ...\n",
      "0.14110005800012004\n",
      "Training model 4920: (91,98) ...\n",
      "0.1289234480000232\n",
      "Training model 4921: (91,99) ...\n",
      "0.15129440600003363\n",
      "Training model 4922: (92,93) ...\n",
      "0.23977767099995617\n",
      "Training model 4923: (92,94) ...\n",
      "0.26704739199976757\n",
      "Training model 4924: (92,95) ...\n",
      "0.28239134900013596\n",
      "Training model 4925: (92,96) ...\n",
      "0.19425017200001093\n",
      "Training model 4926: (92,97) ...\n",
      "0.12073720699982005\n",
      "Training model 4927: (92,98) ...\n",
      "0.13647414900015065\n",
      "Training model 4928: (92,99) ...\n",
      "0.14015396100012367\n",
      "Training model 4929: (93,94) ...\n",
      "0.19710525399977996\n",
      "Training model 4930: (93,95) ...\n",
      "0.16228300300008414\n",
      "Training model 4931: (93,96) ...\n",
      "0.34448582400000305\n",
      "Training model 4932: (93,97) ...\n",
      "0.1700684999996156\n",
      "Training model 4933: (93,98) ...\n",
      "0.14134442999966268\n",
      "Training model 4934: (93,99) ...\n",
      "0.20016370199982703\n",
      "Training model 4935: (94,95) ...\n",
      "0.254917715999909\n",
      "Training model 4936: (94,96) ...\n",
      "0.16996149900023738\n",
      "Training model 4937: (94,97) ...\n",
      "0.12170233599999847\n",
      "Training model 4938: (94,98) ...\n",
      "0.13040469899988238\n",
      "Training model 4939: (94,99) ...\n",
      "0.14840529599996444\n",
      "Training model 4940: (95,96) ...\n",
      "0.15186837200008085\n",
      "Training model 4941: (95,97) ...\n",
      "0.1109677899999042\n",
      "Training model 4942: (95,98) ...\n",
      "0.10363817999996172\n",
      "Training model 4943: (95,99) ...\n",
      "0.11960754499978066\n",
      "Training model 4944: (96,97) ...\n",
      "0.1516801640000267\n",
      "Training model 4945: (96,98) ...\n",
      "0.1113447399998222\n",
      "Training model 4946: (96,99) ...\n",
      "0.12985755699992296\n",
      "Training model 4947: (97,98) ...\n",
      "0.34931761200004985\n",
      "Training model 4948: (97,99) ...\n",
      "0.29758878000029654\n",
      "Training model 4949: (98,99) ...\n",
      "0.2741220789998806\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "maxiter = 1000\n",
    "target_accuracy = 1e-5\n",
    "classes = 100\n",
    "pairwise_linsvc_sk_ovo = dict()\n",
    "# opt_reg_pairwise_linsvc_sk_ovo = dict()\n",
    "t = 0\n",
    "\n",
    "for i in range(classes):\n",
    "    for j in range(i+1, classes):\n",
    "        print('Training model '+str(t)+': ('+str(i)+','+str(j)+') ...')\n",
    "        start = timer()\n",
    "        X_train_subset, y_train_subset = subset_data(i, j, X_train, y_train)\n",
    "        \n",
    "        linsvc_sk_ovo = LinearSVC(fit_intercept=False, max_iter=maxiter, tol=target_accuracy)\n",
    "        linsvc_sk_ovo.fit(X_train_subset, y_train_subset.squeeze())\n",
    "        \n",
    "        pairwise_linsvc_sk_ovo[(i, j)] = linsvc_sk_ovo\n",
    "#         opt_reg_pairwise_linsvc_sk_ovo[(i, j)] = pairwise_linsvc_sk_ovo.C_[0]\n",
    "        \n",
    "        end = timer()\n",
    "        print(end - start)\n",
    "        t += 1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def majority_vote(array):\n",
    "    most = max(list(map(array.count, array)))\n",
    "    return random.choice(list(set(filter(lambda x: array.count(x) == most, array))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_pairwise_sk(clfs, x):\n",
    "    preds = list(map(lambda c: c[0] if clfs[c].predict(x.reshape(1, -1)) == 1 else c[1], clfs))\n",
    "    return majority_vote(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation set predictions\n",
    "y_val_preds_linsvc_sk_ovo = [predict_pairwise_sk(pairwise_linsvc_sk_ovo, n) for n in X_val]\n",
    "\n",
    "# Misclassification Error Rate for Validation Set\n",
    "1 - np.mean(y_val_preds_linsvc_sk_ovo == y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test set predictions\n",
    "# y_test_preds_linsvc_sk_ovo = list(map(lambda n: predict_pairwise_sk(pairwise_linsvc_sk_ovo, n), X_test))\n",
    "y_test_preds_linsvc_sk_ovo = [predict_pairwise_sk(pairwise_linsvc_sk_ovo, n) for n in X_test]\n",
    "\n",
    "# Write to CSV for Kaggle submission\n",
    "pd.DataFrame({'Category':y_test_preds_linsvc_sk_ovo}).reset_index()\\\n",
    "             .rename(columns={'index':'Id'}).to_csv('./comp2-subm_linsvc_sk_ovo.csv', index=False)\n",
    "\n",
    "# Write trained models to pickle file\n",
    "# pickle.dump( pairwise_clfs_sk, open( \"pairwise_clfs_sk.p\", \"wb\" ) )\n",
    "\n",
    "# Write optimal lambdas to pickle file\n",
    "# pickle.dump( opt_lamb_pairwise_sk, open( \"opt_lamb_pairwise_sk.p\", \"wb\" ) )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy (from Kaggle): 0.54666\n",
    "\n",
    "Misclassification Error: 0.45334"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pretty good performance for OvO classifier! This didn't perform as well as my OvO L2-regularized Logistic Regression classifier (difference of ~3%), but I believe the difference can be accounted for better cross-validation for optimal regularization parameters from the Logistic Regression classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4: sklearn.LinearSVC (one-vs-rest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a one-vs-rest fashion, for each class, train a linear SVM classifier using scikit-learnâ€™s function LinearSVC, with the default value for Î»c. Compute the multi-class misclassification error obtained using these classifiers trained in a one-vs-rest fashion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]217.95099875800952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "maxiter = 1000\n",
    "target_accuracy = 1e-4\n",
    "classes = 100\n",
    "\n",
    "start = timer()\n",
    "linsvc_sk_ovr = LinearSVC(fit_intercept=False, max_iter=maxiter, tol=target_accuracy, verbose=True, multi_class='ovr')\n",
    "linsvc_sk_ovr.fit(X_train_unstd, y_train)\n",
    "end = timer()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4625"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Validation set predictions\n",
    "# Accuracy for Validation Set (1 - Misclassification Error)\n",
    "linsvc_sk_ovr.score(X_val_unstd, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test set predictions\n",
    "y_test_preds_linsvc_sk_ovr = linsvc_sk_ovr.predict(X_test_unstd)\n",
    "\n",
    "# Write to CSV for Kaggle submission\n",
    "pd.DataFrame({'Category':y_test_preds_linsvc_sk_ovr}).reset_index()\\\n",
    "             .rename(columns={'index':'Id'}).to_csv('./comp2-subm_linsvc_sk_ovr.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy (from Kaggle): 0.45166\n",
    "\n",
    "Misclassification Rate: 0.54834"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interestingly OvR appeared to perform worse than OvO linear SVM classification. I initially had my doubts about OvO as a multi-class classification problem initially, but these results are proving my doubts wrong. I reflect more about OvO vs OvR in the conclusion below.\n",
    "\n",
    "Another interesting finding was that OvR linear SVM classification appears to converge much faster on unstandardized data. When I tried to train on the standardized data, it was taking an extraordinary amount of time, but unstandardized appeared to converge fairly quickly.\n",
    "\n",
    "I'm unsure of the reason for this; all literature I've found online seems to suggest the opposite: if convergence is taking too long for SVM, it is suggested that you standardize the data first."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5: Training with my implementation of linear SVM (just picked 2 classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max number of iterations of backtracking line search reached\n",
      "Max number of iterations of backtracking line search reached\n",
      "Max number of iterations of backtracking line search reached\n",
      "Max number of iterations of backtracking line search reached\n",
      "Max number of iterations of backtracking line search reached\n",
      "Max number of iterations of backtracking line search reached\n",
      "Max number of iterations of backtracking line search reached\n",
      "Max number of iterations of backtracking line search reached\n",
      "Max number of iterations of backtracking line search reached\n",
      "Max number of iterations of backtracking line search reached\n"
     ]
    }
   ],
   "source": [
    "# Subset Data\n",
    "X_train_subset, y_train_subset, X_val_subset, y_val_subset = subset_data(1, 0, X_train, y_train, X_val, y_val)\n",
    "\n",
    "# Initialize things\n",
    "n, d = X_train_subset.shape\n",
    "lam = 1\n",
    "beta_init = np.zeros(n)\n",
    "theta_init = np.zeros(n)\n",
    "\n",
    "K = gram_linear(X_train_subset, X_train_subset)\n",
    "eta_init = initstepsize(K, lam)\n",
    "maxiter = 10\n",
    "\n",
    "# Run the algorithm\n",
    "beta_list = fastgradalgo(beta_init, theta_init, K, y_train_subset, lam, eta_init, maxiter, eps=1e-3)\n",
    "beta_T = beta_list[len(beta_list)-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.025"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Misclassification Error\n",
    "misclassification_error(beta_T, X_train_subset, X_val_subset, y_val_subset.squeeze(), gram_linear)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confirmed with this test that my implementation of linear OvO SVM appears to work on a toy subset of 2 classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6: Training with my implementation of linear SVM (one-vs-one)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model 0: (0,1) ...\n",
      "2.1342854920076206\n",
      "Training model 1: (0,2) ...\n",
      "2.207382304011844\n",
      "Training model 2: (0,3) ...\n",
      "2.1286219830217306\n",
      "Training model 3: (0,4) ...\n",
      "2.211706027999753\n",
      "Training model 4: (0,5) ...\n",
      "2.1099595650157426\n",
      "Training model 5: (0,6) ...\n",
      "2.317591454979265\n",
      "Training model 6: (0,7) ...\n",
      "2.366494478977984\n",
      "Training model 7: (0,8) ...\n",
      "2.1107371099933516\n",
      "Training model 8: (0,9) ...\n",
      "2.2410722319909837\n",
      "Training model 9: (0,10) ...\n",
      "2.0303070319932885\n",
      "Training model 10: (0,11) ...\n",
      "2.332247363985516\n",
      "Training model 11: (0,12) ...\n",
      "2.298518066003453\n",
      "Training model 12: (0,13) ...\n",
      "2.3436273320112377\n",
      "Training model 13: (0,14) ...\n",
      "2.1609913780121133\n",
      "Training model 14: (0,15) ...\n",
      "2.1397291400062386\n",
      "Training model 15: (0,16) ...\n",
      "2.1406395949888974\n",
      "Training model 16: (0,17) ...\n",
      "2.1451269359968137\n",
      "Training model 17: (0,18) ...\n",
      "1.8254001589957625\n",
      "Training model 18: (0,19) ...\n",
      "2.166671246988699\n",
      "Training model 19: (0,20) ...\n",
      "2.144627733010566\n",
      "Training model 20: (0,21) ...\n",
      "1.9977746259828564\n",
      "Training model 21: (0,22) ...\n",
      "2.143303049990209\n",
      "Training model 22: (0,23) ...\n",
      "2.1795177629974205\n",
      "Training model 23: (0,24) ...\n",
      "2.144521470007021\n",
      "Training model 24: (0,25) ...\n",
      "2.1540815719927195\n",
      "Training model 25: (0,26) ...\n",
      "2.1752574220008682\n",
      "Training model 26: (0,27) ...\n",
      "2.119165679992875\n",
      "Training model 27: (0,28) ...\n",
      "2.1238077040179633\n",
      "Training model 28: (0,29) ...\n",
      "2.1492705729906447\n",
      "Training model 29: (0,30) ...\n",
      "2.1336261769756675\n",
      "Training model 30: (0,31) ...\n",
      "2.150215045985533\n",
      "Training model 31: (0,32) ...\n",
      "2.138878109981306\n",
      "Training model 32: (0,33) ...\n",
      "2.090701528999489\n",
      "Training model 33: (0,34) ...\n",
      "2.195688142994186\n",
      "Training model 34: (0,35) ...\n",
      "2.2126983930065762\n",
      "Training model 35: (0,36) ...\n",
      "2.1788633420073893\n",
      "Training model 36: (0,37) ...\n",
      "2.149335620983038\n",
      "Training model 37: (0,38) ...\n",
      "2.2044331849901937\n",
      "Training model 38: (0,39) ...\n",
      "2.1617948159982916\n",
      "Training model 39: (0,40) ...\n",
      "2.141346357006114\n",
      "Training model 40: (0,41) ...\n",
      "2.1709647989773657\n",
      "Training model 41: (0,42) ...\n",
      "2.1679534800059628\n",
      "Training model 42: (0,43) ...\n",
      "2.1608895999961533\n",
      "Training model 43: (0,44) ...\n",
      "2.140877788013313\n",
      "Training model 44: (0,45) ...\n",
      "2.1817949370015413\n",
      "Training model 45: (0,46) ...\n",
      "2.169329853000818\n",
      "Training model 46: (0,47) ...\n",
      "2.1856085489853285\n",
      "Training model 47: (0,48) ...\n",
      "2.1968086950073484\n",
      "Training model 48: (0,49) ...\n",
      "2.195344046020182\n",
      "Training model 49: (0,50) ...\n",
      "1.9994633960013743\n",
      "Training model 50: (0,51) ...\n",
      "2.1657934529939666\n",
      "Training model 51: (0,52) ...\n",
      "2.1974823560158256\n",
      "Training model 52: (0,53) ...\n",
      "2.24202540301485\n",
      "Training model 53: (0,54) ...\n",
      "2.253152945981128\n",
      "Training model 54: (0,55) ...\n",
      "2.1823715320206247\n",
      "Training model 55: (0,56) ...\n",
      "2.0221805749752093\n",
      "Training model 56: (0,57) ...\n",
      "2.2227730689919554\n",
      "Training model 57: (0,58) ...\n",
      "2.2117365839949343\n",
      "Training model 58: (0,59) ...\n",
      "2.1886454860214144\n",
      "Training model 59: (0,60) ...\n",
      "2.2171947809983976\n",
      "Training model 60: (0,61) ...\n",
      "2.217682150017936\n",
      "Training model 61: (0,62) ...\n",
      "2.2525571760197636\n",
      "Training model 62: (0,63) ...\n",
      "2.153286816988839\n",
      "Training model 63: (0,64) ...\n",
      "2.136938845011173\n",
      "Training model 64: (0,65) ...\n",
      "2.148584564012708\n",
      "Training model 65: (0,66) ...\n",
      "2.119383001991082\n",
      "Training model 66: (0,67) ...\n",
      "2.1841296020138543\n",
      "Training model 67: (0,68) ...\n",
      "2.1508619049855042\n",
      "Training model 68: (0,69) ...\n",
      "2.2251774440228473\n",
      "Training model 69: (0,70) ...\n",
      "2.1842514509917237\n",
      "Training model 70: (0,71) ...\n",
      "2.180237208987819\n",
      "Training model 71: (0,72) ...\n",
      "2.219588671985548\n",
      "Training model 72: (0,73) ...\n",
      "2.097532454004977\n",
      "Training model 73: (0,74) ...\n",
      "2.18463311198866\n",
      "Training model 74: (0,75) ...\n",
      "2.166325391008286\n",
      "Training model 75: (0,76) ...\n",
      "2.3607359860034194\n",
      "Training model 76: (0,77) ...\n",
      "2.7501276599941775\n",
      "Training model 77: (0,78) ...\n",
      "2.111553886003094\n",
      "Training model 78: (0,79) ...\n",
      "2.1388925120118074\n",
      "Training model 79: (0,80) ...\n",
      "2.124668242991902\n",
      "Training model 80: (0,81) ...\n",
      "2.1311931580130477\n",
      "Training model 81: (0,82) ...\n",
      "2.1310801369836554\n",
      "Training model 82: (0,83) ...\n",
      "2.096333366993349\n",
      "Training model 83: (0,84) ...\n",
      "2.124457729019923\n",
      "Training model 84: (0,85) ...\n",
      "2.132802357984474\n",
      "Training model 85: (0,86) ...\n",
      "2.1234977819840424\n",
      "Training model 86: (0,87) ...\n",
      "2.1225010189809836\n",
      "Training model 87: (0,88) ...\n",
      "2.1207757299998775\n",
      "Training model 88: (0,89) ...\n",
      "2.0922934800037183\n",
      "Training model 89: (0,90) ...\n",
      "2.10892875798163\n",
      "Training model 90: (0,91) ...\n",
      "2.120224568992853\n",
      "Training model 91: (0,92) ...\n",
      "2.136272629024461\n",
      "Training model 92: (0,93) ...\n",
      "2.1644098429824226\n",
      "Training model 93: (0,94) ...\n",
      "2.257949893013574\n",
      "Training model 94: (0,95) ...\n",
      "2.121231657016324\n",
      "Training model 95: (0,96) ...\n",
      "1.9642941119964235\n",
      "Training model 96: (0,97) ...\n",
      "2.157754976011347\n",
      "Training model 97: (0,98) ...\n",
      "2.1634161440015305\n",
      "Training model 98: (0,99) ...\n",
      "2.1654384520079475\n",
      "Training model 99: (1,2) ...\n",
      "2.2595715369971003\n",
      "Training model 100: (1,3) ...\n",
      "2.2006874520157\n",
      "Training model 101: (1,4) ...\n",
      "2.195790522004245\n",
      "Training model 102: (1,5) ...\n",
      "2.179460366984131\n",
      "Training model 103: (1,6) ...\n",
      "2.1677763070038054\n",
      "Training model 104: (1,7) ...\n",
      "2.1875038529979065\n",
      "Training model 105: (1,8) ...\n",
      "2.213907305005705\n",
      "Training model 106: (1,9) ...\n",
      "2.181869263004046\n",
      "Training model 107: (1,10) ...\n",
      "2.1554371590027586\n",
      "Training model 108: (1,11) ...\n",
      "2.1741866130032577\n",
      "Training model 109: (1,12) ...\n",
      "2.184024459013017\n",
      "Training model 110: (1,13) ...\n",
      "2.1709172280097846\n",
      "Training model 111: (1,14) ...\n",
      "2.004121949983528\n",
      "Training model 112: (1,15) ...\n",
      "1.853245178994257\n",
      "Training model 113: (1,16) ...\n",
      "2.1272194199846126\n",
      "Training model 114: (1,17) ...\n",
      "2.127572983998107\n",
      "Training model 115: (1,18) ...\n",
      "2.1226324989984278\n",
      "Training model 116: (1,19) ...\n",
      "2.1330011029785965\n",
      "Training model 117: (1,20) ...\n",
      "2.1902526209887583\n",
      "Training model 118: (1,21) ...\n",
      "2.192259780014865\n",
      "Training model 119: (1,22) ...\n",
      "2.1304527079919353\n",
      "Training model 120: (1,23) ...\n",
      "1.9616446679865476\n",
      "Training model 121: (1,24) ...\n",
      "2.1202705049945507\n",
      "Training model 122: (1,25) ...\n",
      "2.128095483989455\n",
      "Training model 123: (1,26) ...\n",
      "2.1188604590133764\n",
      "Training model 124: (1,27) ...\n",
      "2.1407115100009833\n",
      "Training model 125: (1,28) ...\n",
      "2.0853782240010332\n",
      "Training model 126: (1,29) ...\n",
      "2.127104540995788\n",
      "Training model 127: (1,30) ...\n",
      "1.9809821390081197\n",
      "Training model 128: (1,31) ...\n",
      "2.1238861870078836\n",
      "Training model 129: (1,32) ...\n",
      "2.1285197680117562\n",
      "Training model 130: (1,33) ...\n",
      "2.115982224000618\n",
      "Training model 131: (1,34) ...\n",
      "2.1109392390062567\n",
      "Training model 132: (1,35) ...\n",
      "2.1225600830221083\n",
      "Training model 133: (1,36) ...\n",
      "2.1252825489791576\n",
      "Training model 134: (1,37) ...\n",
      "2.1416871839901432\n",
      "Training model 135: (1,38) ...\n",
      "2.1141582890122663\n",
      "Training model 136: (1,39) ...\n",
      "2.133052059012698\n",
      "Training model 137: (1,40) ...\n",
      "2.1183861099998467\n",
      "Training model 138: (1,41) ...\n",
      "1.9758172369911335\n",
      "Training model 139: (1,42) ...\n",
      "2.102700151997851\n",
      "Training model 140: (1,43) ...\n",
      "2.18023657501908\n",
      "Training model 141: (1,44) ...\n",
      "2.1689071700093336\n",
      "Training model 142: (1,45) ...\n",
      "2.190038213011576\n",
      "Training model 143: (1,46) ...\n",
      "2.1689972530002706\n",
      "Training model 144: (1,47) ...\n",
      "2.1608110700035468\n",
      "Training model 145: (1,48) ...\n",
      "2.205752626992762\n",
      "Training model 146: (1,49) ...\n",
      "2.170715754997218\n",
      "Training model 147: (1,50) ...\n",
      "2.158636573003605\n",
      "Training model 148: (1,51) ...\n",
      "2.2134401829971466\n",
      "Training model 149: (1,52) ...\n",
      "2.1519246609823313\n",
      "Training model 150: (1,53) ...\n",
      "2.194857578026131\n",
      "Training model 151: (1,54) ...\n",
      "2.1614259910129476\n",
      "Training model 152: (1,55) ...\n",
      "2.1672909620101564\n",
      "Training model 153: (1,56) ...\n",
      "2.14656839100644\n",
      "Training model 154: (1,57) ...\n",
      "2.0189352150191553\n",
      "Training model 155: (1,58) ...\n",
      "2.174582684005145\n",
      "Training model 156: (1,59) ...\n",
      "2.1552137169928756\n",
      "Training model 157: (1,60) ...\n",
      "2.319836802984355\n",
      "Training model 158: (1,61) ...\n",
      "2.257179278996773\n",
      "Training model 159: (1,62) ...\n",
      "2.643299671006389\n",
      "Training model 160: (1,63) ...\n",
      "2.728537016984774\n",
      "Training model 161: (1,64) ...\n",
      "2.147788740985561\n",
      "Training model 162: (1,65) ...\n",
      "2.170825634006178\n",
      "Training model 163: (1,66) ...\n",
      "2.1384388050064445\n",
      "Training model 164: (1,67) ...\n",
      "2.1679934340063483\n",
      "Training model 165: (1,68) ...\n",
      "2.1514977299957536\n",
      "Training model 166: (1,69) ...\n",
      "2.15309585101204\n",
      "Training model 167: (1,70) ...\n",
      "2.135640111984685\n",
      "Training model 168: (1,71) ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1617739609791897\n",
      "Training model 169: (1,72) ...\n",
      "2.1334999880054966\n",
      "Training model 170: (1,73) ...\n",
      "2.1391311869956553\n",
      "Training model 171: (1,74) ...\n",
      "2.1544613229925744\n",
      "Training model 172: (1,75) ...\n",
      "2.2248445579898544\n",
      "Training model 173: (1,76) ...\n",
      "2.2322722929820884\n",
      "Training model 174: (1,77) ...\n",
      "2.186003848008113\n",
      "Training model 175: (1,78) ...\n",
      "1.9870705739886034\n",
      "Training model 176: (1,79) ...\n",
      "2.2211798619828187\n",
      "Training model 177: (1,80) ...\n",
      "2.1478725360066164\n",
      "Training model 178: (1,81) ...\n",
      "2.157945153012406\n",
      "Training model 179: (1,82) ...\n",
      "2.1333090759871993\n",
      "Training model 180: (1,83) ...\n",
      "2.1634680969873443\n",
      "Training model 181: (1,84) ...\n",
      "2.1392102239769883\n",
      "Training model 182: (1,85) ...\n",
      "2.1470186740043573\n",
      "Training model 183: (1,86) ...\n",
      "2.1345532510022167\n",
      "Training model 184: (1,87) ...\n",
      "2.1487194189976435\n",
      "Training model 185: (1,88) ...\n",
      "2.1330593369784765\n",
      "Training model 186: (1,89) ...\n",
      "1.998905818007188\n",
      "Training model 187: (1,90) ...\n",
      "2.1356798150227405\n",
      "Training model 188: (1,91) ...\n",
      "2.147013511013938\n",
      "Training model 189: (1,92) ...\n",
      "2.1376542890211567\n",
      "Training model 190: (1,93) ...\n",
      "2.1660308279970195\n",
      "Training model 191: (1,94) ...\n",
      "2.141880172974197\n",
      "Training model 192: (1,95) ...\n",
      "2.1651429740013555\n",
      "Training model 193: (1,96) ...\n",
      "2.1436887370073237\n",
      "Training model 194: (1,97) ...\n",
      "2.140358426986495\n",
      "Training model 195: (1,98) ...\n",
      "2.1394495140120853\n",
      "Training model 196: (1,99) ...\n",
      "2.0015745739801787\n",
      "Training model 197: (2,3) ...\n",
      "2.232894237997243\n",
      "Training model 198: (2,4) ...\n",
      "2.1775677090045065\n",
      "Training model 199: (2,5) ...\n",
      "2.174436618020991\n",
      "Training model 200: (2,6) ...\n",
      "2.2059969140100293\n",
      "Training model 201: (2,7) ...\n",
      "2.156563214986818\n",
      "Training model 202: (2,8) ...\n",
      "2.1863844440085813\n",
      "Training model 203: (2,9) ...\n",
      "2.162546100007603\n",
      "Training model 204: (2,10) ...\n",
      "2.051253301993711\n",
      "Training model 205: (2,11) ...\n",
      "2.2095852560014464\n",
      "Training model 206: (2,12) ...\n",
      "2.186844518990256\n",
      "Training model 207: (2,13) ...\n",
      "2.194339531008154\n",
      "Training model 208: (2,14) ...\n",
      "2.1921477949945256\n",
      "Training model 209: (2,15) ...\n",
      "2.177690676006023\n",
      "Training model 210: (2,16) ...\n",
      "2.1666100499860477\n",
      "Training model 211: (2,17) ...\n",
      "2.1414370400016196\n",
      "Training model 212: (2,18) ...\n",
      "2.2319997269951273\n",
      "Training model 213: (2,19) ...\n",
      "2.1995054470025934\n",
      "Training model 214: (2,20) ...\n",
      "2.1436273670115042\n",
      "Training model 215: (2,21) ...\n",
      "2.215019873023266\n",
      "Training model 216: (2,22) ...\n",
      "2.166651596984593\n",
      "Training model 217: (2,23) ...\n",
      "2.1489968269888777\n",
      "Training model 218: (2,24) ...\n",
      "2.1765843460161705\n",
      "Training model 219: (2,25) ...\n",
      "2.173560916999122\n",
      "Training model 220: (2,26) ...\n",
      "2.150497027003439\n",
      "Training model 221: (2,27) ...\n",
      "2.168856120988494\n",
      "Training model 222: (2,28) ...\n",
      "2.250561282009585\n",
      "Training model 223: (2,29) ...\n",
      "2.1310191890224814\n",
      "Training model 224: (2,30) ...\n",
      "2.2967540720128454\n",
      "Training model 225: (2,31) ...\n",
      "2.1066086319915485\n",
      "Training model 226: (2,32) ...\n",
      "2.129613393015461\n",
      "Training model 227: (2,33) ...\n",
      "2.1138429660059046\n",
      "Training model 228: (2,34) ...\n",
      "2.228030096011935\n",
      "Training model 229: (2,35) ...\n",
      "2.015254081983585\n",
      "Training model 230: (2,36) ...\n",
      "2.2002595069934614\n",
      "Training model 231: (2,37) ...\n",
      "2.185277106007561\n",
      "Training model 232: (2,38) ...\n",
      "2.2110905169975013\n",
      "Training model 233: (2,39) ...\n",
      "2.157237145002\n",
      "Training model 234: (2,40) ...\n",
      "2.1623447469901294\n",
      "Training model 235: (2,41) ...\n",
      "2.163946644985117\n",
      "Training model 236: (2,42) ...\n",
      "2.1996206589974463\n",
      "Training model 237: (2,43) ...\n",
      "2.01339930301765\n",
      "Training model 238: (2,44) ...\n",
      "2.089633348019561\n",
      "Training model 239: (2,45) ...\n",
      "2.0923356220009737\n",
      "Training model 240: (2,46) ...\n",
      "2.1127750079904217\n",
      "Training model 241: (2,47) ...\n",
      "2.101291681989096\n",
      "Training model 242: (2,48) ...\n",
      "2.5797692940104753\n",
      "Training model 243: (2,49) ...\n",
      "2.891465322987642\n",
      "Training model 244: (2,50) ...\n",
      "2.126761864987202\n",
      "Training model 245: (2,51) ...\n",
      "2.1118741749960463\n",
      "Training model 246: (2,52) ...\n",
      "2.1373258999956306\n",
      "Training model 247: (2,53) ...\n",
      "2.1148342580127064\n",
      "Training model 248: (2,54) ...\n",
      "2.197165210993262\n",
      "Training model 249: (2,55) ...\n",
      "2.1183777889818884\n",
      "Training model 250: (2,56) ...\n",
      "2.1428214379993733\n",
      "Training model 251: (2,57) ...\n",
      "2.1133764030237217\n",
      "Training model 252: (2,58) ...\n",
      "2.1217717679974157\n",
      "Training model 253: (2,59) ...\n",
      "2.110053081996739\n",
      "Training model 254: (2,60) ...\n",
      "1.9421614749880973\n",
      "Training model 255: (2,61) ...\n",
      "2.1719521089980844\n",
      "Training model 256: (2,62) ...\n",
      "2.1935930909821764\n",
      "Training model 257: (2,63) ...\n",
      "2.169507768994663\n",
      "Training model 258: (2,64) ...\n",
      "2.238473339995835\n",
      "Training model 259: (2,65) ...\n",
      "2.1584521280019544\n",
      "Training model 260: (2,66) ...\n",
      "2.1711543199780863\n",
      "Training model 261: (2,67) ...\n",
      "2.1691881300066598\n",
      "Training model 262: (2,68) ...\n",
      "2.1811614569742233\n",
      "Training model 263: (2,69) ...\n",
      "2.163613409997197\n",
      "Training model 264: (2,70) ...\n",
      "2.1648732610046864\n",
      "Training model 265: (2,71) ...\n",
      "2.161269546020776\n",
      "Training model 266: (2,72) ...\n",
      "2.179925306001678\n",
      "Training model 267: (2,73) ...\n",
      "2.062630366999656\n",
      "Training model 268: (2,74) ...\n",
      "2.189138985995669\n",
      "Training model 269: (2,75) ...\n",
      "2.206641649012454\n",
      "Training model 270: (2,76) ...\n",
      "2.1976093139965087\n",
      "Training model 271: (2,77) ...\n",
      "2.2122204070037697\n",
      "Training model 272: (2,78) ...\n",
      "2.1831501479900908\n",
      "Training model 273: (2,79) ...\n",
      "2.2115758239815477\n",
      "Training model 274: (2,80) ...\n",
      "2.18829900099081\n",
      "Training model 275: (2,81) ...\n",
      "2.3404238279908895\n",
      "Training model 276: (2,82) ...\n",
      "2.131492590997368\n",
      "Training model 277: (2,83) ...\n",
      "2.1110713810194284\n",
      "Training model 278: (2,84) ...\n",
      "2.147358816990163\n",
      "Training model 279: (2,85) ...\n",
      "2.107720108993817\n",
      "Training model 280: (2,86) ...\n",
      "2.0363295020069927\n",
      "Training model 281: (2,87) ...\n",
      "2.1779558040143456\n",
      "Training model 282: (2,88) ...\n",
      "2.2938691369781736\n",
      "Training model 283: (2,89) ...\n",
      "2.317301328992471\n",
      "Training model 284: (2,90) ...\n",
      "2.1442299420014024\n",
      "Training model 285: (2,91) ...\n",
      "2.128195664001396\n",
      "Training model 286: (2,92) ...\n",
      "2.150965230015572\n",
      "Training model 287: (2,93) ...\n",
      "2.196868272993015\n",
      "Training model 288: (2,94) ...\n",
      "2.1970711479953025\n",
      "Training model 289: (2,95) ...\n",
      "2.1646288149931934\n",
      "Training model 290: (2,96) ...\n",
      "2.2195702970202547\n",
      "Training model 291: (2,97) ...\n",
      "2.1142207120137755\n",
      "Training model 292: (2,98) ...\n",
      "2.1620652029814664\n",
      "Training model 293: (2,99) ...\n",
      "2.1691360349941533\n",
      "Training model 294: (3,4) ...\n",
      "2.1786704569822177\n",
      "Training model 295: (3,5) ...\n",
      "2.1265399380063172\n",
      "Training model 296: (3,6) ...\n",
      "2.183929557999363\n",
      "Training model 297: (3,7) ...\n",
      "2.028909384011058\n",
      "Training model 298: (3,8) ...\n",
      "2.217811021982925\n",
      "Training model 299: (3,9) ...\n",
      "2.1998623109830078\n",
      "Training model 300: (3,10) ...\n",
      "2.2135582299961243\n",
      "Training model 301: (3,11) ...\n",
      "2.143742663000012\n",
      "Training model 302: (3,12) ...\n",
      "2.1973407749901526\n",
      "Training model 303: (3,13) ...\n",
      "2.163872019998962\n",
      "Training model 304: (3,14) ...\n",
      "2.2149341470212676\n",
      "Training model 305: (3,15) ...\n",
      "2.1181889479921665\n",
      "Training model 306: (3,16) ...\n",
      "2.195220932015218\n",
      "Training model 307: (3,17) ...\n",
      "2.170977246016264\n",
      "Training model 308: (3,18) ...\n",
      "2.2266231359972153\n",
      "Training model 309: (3,19) ...\n",
      "2.1757900599914137\n",
      "Training model 310: (3,20) ...\n",
      "1.5354854009929113\n",
      "Training model 311: (3,21) ...\n",
      "2.126238541008206\n",
      "Training model 312: (3,22) ...\n",
      "2.172501311986707\n",
      "Training model 313: (3,23) ...\n",
      "2.130705129005946\n",
      "Training model 314: (3,24) ...\n",
      "2.1671145540021826\n",
      "Training model 315: (3,25) ...\n",
      "2.114101532002678\n",
      "Training model 316: (3,26) ...\n",
      "1.994235705002211\n",
      "Training model 317: (3,27) ...\n",
      "2.1000113689806312\n",
      "Training model 318: (3,28) ...\n",
      "1.980665762006538\n",
      "Training model 319: (3,29) ...\n",
      "1.9574896809936035\n",
      "Training model 320: (3,30) ...\n",
      "2.124013622000348\n",
      "Training model 321: (3,31) ...\n",
      "1.9798316640080884\n",
      "Training model 322: (3,32) ...\n",
      "2.097243038995657\n",
      "Training model 323: (3,33) ...\n",
      "2.1110234590014443\n",
      "Training model 324: (3,34) ...\n",
      "2.1220718180120457\n",
      "Training model 325: (3,35) ...\n",
      "2.431516108015785\n",
      "Training model 326: (3,36) ...\n",
      "2.9725353899993934\n",
      "Training model 327: (3,37) ...\n",
      "2.318463025003439\n",
      "Training model 328: (3,38) ...\n",
      "2.135947437986033\n",
      "Training model 329: (3,39) ...\n",
      "1.9672438629786484\n",
      "Training model 330: (3,40) ...\n",
      "2.2117850449867547\n",
      "Training model 331: (3,41) ...\n",
      "1.9895803279941902\n",
      "Training model 332: (3,42) ...\n",
      "2.1314131729886867\n",
      "Training model 333: (3,43) ...\n",
      "1.9690395059878938\n",
      "Training model 334: (3,44) ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.087732710002456\n",
      "Training model 335: (3,45) ...\n",
      "2.1247203910024837\n",
      "Training model 336: (3,46) ...\n",
      "2.1191093229863327\n",
      "Training model 337: (3,47) ...\n",
      "2.113000016019214\n",
      "Training model 338: (3,48) ...\n",
      "2.1252867500006687\n",
      "Training model 339: (3,49) ...\n",
      "2.1742976359964814\n",
      "Training model 340: (3,50) ...\n",
      "2.173365566006396\n",
      "Training model 341: (3,51) ...\n",
      "2.1198181599902455\n",
      "Training model 342: (3,52) ...\n",
      "2.1671958309889305\n",
      "Training model 343: (3,53) ...\n",
      "2.127542956994148\n",
      "Training model 344: (3,54) ...\n",
      "2.139564761018846\n",
      "Training model 345: (3,55) ...\n",
      "2.148718985990854\n",
      "Training model 346: (3,56) ...\n",
      "2.1450901970092673\n",
      "Training model 347: (3,57) ...\n",
      "2.1286419880052563\n",
      "Training model 348: (3,58) ...\n",
      "2.0960723540047184\n",
      "Training model 349: (3,59) ...\n",
      "2.122544429003028\n",
      "Training model 350: (3,60) ...\n",
      "2.1293318509997334\n",
      "Training model 351: (3,61) ...\n",
      "2.0884660049923696\n",
      "Training model 352: (3,62) ...\n",
      "2.1083399550116155\n",
      "Training model 353: (3,63) ...\n",
      "2.1504314439953305\n",
      "Training model 354: (3,64) ...\n",
      "2.015464060008526\n",
      "Training model 355: (3,65) ...\n",
      "2.1501970470126253\n",
      "Training model 356: (3,66) ...\n",
      "2.191653028014116\n",
      "Training model 357: (3,67) ...\n",
      "2.1219833759823814\n",
      "Training model 358: (3,68) ...\n",
      "2.282340450998163\n",
      "Training model 359: (3,69) ...\n",
      "2.3223749390162993\n",
      "Training model 360: (3,70) ...\n",
      "2.163162980985362\n",
      "Training model 361: (3,71) ...\n",
      "2.1484208519977983\n",
      "Training model 362: (3,72) ...\n",
      "2.17712068502442\n",
      "Training model 363: (3,73) ...\n",
      "2.1566200939996634\n",
      "Training model 364: (3,74) ...\n",
      "2.199692205991596\n",
      "Training model 365: (3,75) ...\n",
      "2.1633322270063218\n",
      "Training model 366: (3,76) ...\n",
      "2.179975278006168\n",
      "Training model 367: (3,77) ...\n",
      "2.15911030001007\n",
      "Training model 368: (3,78) ...\n",
      "2.1887915180122945\n",
      "Training model 369: (3,79) ...\n",
      "2.178849509014981\n",
      "Training model 370: (3,80) ...\n",
      "2.218773119006073\n",
      "Training model 371: (3,81) ...\n",
      "2.1372295360197313\n",
      "Training model 372: (3,82) ...\n",
      "2.1567920800007414\n",
      "Training model 373: (3,83) ...\n",
      "2.109911685984116\n",
      "Training model 374: (3,84) ...\n",
      "2.1980392209952697\n",
      "Training model 375: (3,85) ...\n",
      "2.1830054559977725\n",
      "Training model 376: (3,86) ...\n",
      "2.188540228002239\n",
      "Training model 377: (3,87) ...\n",
      "2.1711783459759317\n",
      "Training model 378: (3,88) ...\n",
      "2.176019958977122\n",
      "Training model 379: (3,89) ...\n",
      "2.168837056000484\n",
      "Training model 380: (3,90) ...\n",
      "2.0309352409967687\n",
      "Training model 381: (3,91) ...\n",
      "2.193456700013485\n",
      "Training model 382: (3,92) ...\n",
      "2.2756666539935395\n",
      "Training model 383: (3,93) ...\n",
      "2.1738740830041934\n",
      "Training model 384: (3,94) ...\n",
      "2.179895398003282\n",
      "Training model 385: (3,95) ...\n",
      "2.1658289070182946\n",
      "Training model 386: (3,96) ...\n",
      "2.1964099780016113\n",
      "Training model 387: (3,97) ...\n",
      "2.163719110976672\n",
      "Training model 388: (3,98) ...\n",
      "2.201495139976032\n",
      "Training model 389: (3,99) ...\n",
      "2.16560239600949\n",
      "Training model 390: (4,5) ...\n",
      "2.1925319980073255\n",
      "Training model 391: (4,6) ...\n",
      "2.17353446900961\n",
      "Training model 392: (4,7) ...\n",
      "2.194159923994448\n",
      "Training model 393: (4,8) ...\n",
      "2.1254674039955717\n",
      "Training model 394: (4,9) ...\n",
      "2.192042226990452\n",
      "Training model 395: (4,10) ...\n",
      "2.15729778399691\n",
      "Training model 396: (4,11) ...\n",
      "2.2197587830014527\n",
      "Training model 397: (4,12) ...\n",
      "2.162872259010328\n",
      "Training model 398: (4,13) ...\n",
      "2.172591710987035\n",
      "Training model 399: (4,14) ...\n",
      "2.154452749993652\n",
      "Training model 400: (4,15) ...\n",
      "2.1323559889860917\n",
      "Training model 401: (4,16) ...\n",
      "2.1524365649966057\n",
      "Training model 402: (4,17) ...\n",
      "2.2385528999730013\n",
      "Training model 403: (4,18) ...\n",
      "2.1682992069981992\n",
      "Training model 404: (4,19) ...\n",
      "2.172048572014319\n",
      "Training model 405: (4,20) ...\n",
      "2.128849923989037\n",
      "Training model 406: (4,21) ...\n",
      "2.075310284009902\n",
      "Training model 407: (4,22) ...\n",
      "2.2012574929976836\n",
      "Training model 408: (4,23) ...\n",
      "2.442187962005846\n",
      "Training model 409: (4,24) ...\n",
      "2.7729115890106186\n",
      "Training model 410: (4,25) ...\n",
      "2.1489623230008874\n",
      "Training model 411: (4,26) ...\n",
      "2.10943580098683\n",
      "Training model 412: (4,27) ...\n",
      "2.1223311880021356\n",
      "Training model 413: (4,28) ...\n",
      "2.110662806982873\n",
      "Training model 414: (4,29) ...\n",
      "2.1353530930064153\n",
      "Training model 415: (4,30) ...\n",
      "2.125194432999706\n",
      "Training model 416: (4,31) ...\n",
      "2.120099181018304\n",
      "Training model 417: (4,32) ...\n",
      "2.110064267006237\n",
      "Training model 418: (4,33) ...\n",
      "2.11668453598395\n",
      "Training model 419: (4,34) ...\n",
      "2.0757766429742333\n",
      "Training model 420: (4,35) ...\n",
      "2.1347991889924742\n",
      "Training model 421: (4,36) ...\n",
      "1.9567342219816055\n",
      "Training model 422: (4,37) ...\n",
      "2.2008894729951862\n",
      "Training model 423: (4,38) ...\n",
      "2.1793497939943336\n",
      "Training model 424: (4,39) ...\n",
      "2.1753995079779997\n",
      "Training model 425: (4,40) ...\n",
      "2.1627902259933762\n",
      "Training model 426: (4,41) ...\n",
      "2.208027464017505\n",
      "Training model 427: (4,42) ...\n",
      "2.1375802280090284\n",
      "Training model 428: (4,43) ...\n",
      "2.2140457869973034\n",
      "Training model 429: (4,44) ...\n",
      "2.2779005720221903\n",
      "Training model 430: (4,45) ...\n",
      "2.2519635740027297\n",
      "Training model 431: (4,46) ...\n",
      "2.1376682260015514\n",
      "Training model 432: (4,47) ...\n",
      "2.142065635009203\n",
      "Training model 433: (4,48) ...\n",
      "2.21840693501872\n",
      "Training model 434: (4,49) ...\n",
      "2.344706368021434\n",
      "Training model 435: (4,50) ...\n",
      "2.2154330190096516\n",
      "Training model 436: (4,51) ...\n",
      "2.154416298988508\n",
      "Training model 437: (4,52) ...\n",
      "2.1330612169986125\n",
      "Training model 438: (4,53) ...\n",
      "2.165568752971012\n",
      "Training model 439: (4,54) ...\n",
      "2.1593536710133776\n",
      "Training model 440: (4,55) ...\n",
      "2.207773542992072\n",
      "Training model 441: (4,56) ...\n",
      "2.1404111640003975\n",
      "Training model 442: (4,57) ...\n",
      "2.176778060995275\n",
      "Training model 443: (4,58) ...\n",
      "2.1028007630084176\n",
      "Training model 444: (4,59) ...\n",
      "2.1624148820119444\n",
      "Training model 445: (4,60) ...\n",
      "2.1469809049740434\n",
      "Training model 446: (4,61) ...\n",
      "1.967627187987091\n",
      "Training model 447: (4,62) ...\n",
      "2.1609220760001335\n",
      "Training model 448: (4,63) ...\n",
      "2.267571282980498\n",
      "Training model 449: (4,64) ...\n",
      "2.0077009100059513\n",
      "Training model 450: (4,65) ...\n",
      "2.3498981129960157\n",
      "Training model 451: (4,66) ...\n",
      "2.1351025940093677\n",
      "Training model 452: (4,67) ...\n",
      "2.181714552018093\n",
      "Training model 453: (4,68) ...\n",
      "2.1547354119829834\n",
      "Training model 454: (4,69) ...\n",
      "2.168160678993445\n",
      "Training model 455: (4,70) ...\n",
      "2.1586619000008795\n",
      "Training model 456: (4,71) ...\n",
      "2.186751447006827\n",
      "Training model 457: (4,72) ...\n",
      "2.1529227810096927\n",
      "Training model 458: (4,73) ...\n",
      "2.1909126240061596\n",
      "Training model 459: (4,74) ...\n",
      "2.1689988520229235\n",
      "Training model 460: (4,75) ...\n",
      "2.205928462994052\n",
      "Training model 461: (4,76) ...\n",
      "2.157802160974825\n",
      "Training model 462: (4,77) ...\n",
      "2.1561248369980603\n",
      "Training model 463: (4,78) ...\n",
      "2.1522682170034386\n",
      "Training model 464: (4,79) ...\n",
      "2.219197681028163\n",
      "Training model 465: (4,80) ...\n",
      "2.1437453359831125\n",
      "Training model 466: (4,81) ...\n",
      "2.1821970239980146\n",
      "Training model 467: (4,82) ...\n",
      "2.1333159820060246\n",
      "Training model 468: (4,83) ...\n",
      "2.1727895160147455\n",
      "Training model 469: (4,84) ...\n",
      "2.1605357170046773\n",
      "Training model 470: (4,85) ...\n",
      "2.1506789159902837\n",
      "Training model 471: (4,86) ...\n",
      "2.17296117200749\n",
      "Training model 472: (4,87) ...\n",
      "2.0745178360084537\n",
      "Training model 473: (4,88) ...\n",
      "2.039932115992997\n",
      "Training model 474: (4,89) ...\n",
      "2.119591044000117\n",
      "Training model 475: (4,90) ...\n",
      "2.1121360070246737\n",
      "Training model 476: (4,91) ...\n",
      "2.125701103999745\n",
      "Training model 477: (4,92) ...\n",
      "2.1103922210168093\n",
      "Training model 478: (4,93) ...\n",
      "2.123555744008627\n",
      "Training model 479: (4,94) ...\n",
      "2.113418041000841\n",
      "Training model 480: (4,95) ...\n",
      "2.105686534981942\n",
      "Training model 481: (4,96) ...\n",
      "2.115574572002515\n",
      "Training model 482: (4,97) ...\n",
      "2.0755839869962074\n",
      "Training model 483: (4,98) ...\n",
      "2.1108871930046007\n",
      "Training model 484: (4,99) ...\n",
      "2.130078084010165\n",
      "Training model 485: (5,6) ...\n",
      "2.130655504995957\n",
      "Training model 486: (5,7) ...\n",
      "2.1324382160091773\n",
      "Training model 487: (5,8) ...\n",
      "1.9645893879933283\n",
      "Training model 488: (5,9) ...\n",
      "2.120234046014957\n",
      "Training model 489: (5,10) ...\n",
      "2.0803519239998423\n",
      "Training model 490: (5,11) ...\n",
      "1.967788547015516\n",
      "Training model 491: (5,12) ...\n",
      "2.1107818849850446\n",
      "Training model 492: (5,13) ...\n",
      "2.8102919409866445\n",
      "Training model 493: (5,14) ...\n",
      "2.727888597990386\n",
      "Training model 494: (5,15) ...\n",
      "2.2244136209774297\n",
      "Training model 495: (5,16) ...\n",
      "2.215741091000382\n",
      "Training model 496: (5,17) ...\n",
      "2.1373464439820964\n",
      "Training model 497: (5,18) ...\n",
      "2.161074773001019\n",
      "Training model 498: (5,19) ...\n",
      "2.183482043998083\n",
      "Training model 499: (5,20) ...\n",
      "2.162552002002485\n",
      "Training model 500: (5,21) ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.098711406986695\n",
      "Training model 501: (5,22) ...\n",
      "2.1745306590164546\n",
      "Training model 502: (5,23) ...\n",
      "2.2673940350068733\n",
      "Training model 503: (5,24) ...\n",
      "2.2755021439807024\n",
      "Training model 504: (5,25) ...\n",
      "2.1580666640074924\n",
      "Training model 505: (5,26) ...\n",
      "2.0260792799817864\n",
      "Training model 506: (5,27) ...\n",
      "2.0998754470201675\n",
      "Training model 507: (5,28) ...\n",
      "2.1263824609923176\n",
      "Training model 508: (5,29) ...\n",
      "2.1395570900058374\n",
      "Training model 509: (5,30) ...\n",
      "2.1251667989999987\n",
      "Training model 510: (5,31) ...\n",
      "2.1591971989837475\n",
      "Training model 511: (5,32) ...\n",
      "1.814287160988897\n",
      "Training model 512: (5,33) ...\n",
      "2.1266729240014683\n",
      "Training model 513: (5,34) ...\n",
      "2.115944723977009\n",
      "Training model 514: (5,35) ...\n",
      "2.1261243390035816\n",
      "Training model 515: (5,36) ...\n",
      "1.9617598869954236\n",
      "Training model 516: (5,37) ...\n",
      "2.1334336360159796\n",
      "Training model 517: (5,38) ...\n",
      "2.12710463500116\n",
      "Training model 518: (5,39) ...\n",
      "2.1216171880078036\n",
      "Training model 519: (5,40) ...\n",
      "2.113525378983468\n",
      "Training model 520: (5,41) ...\n",
      "2.1247095339931548\n",
      "Training model 521: (5,42) ...\n",
      "2.1179758250073064\n",
      "Training model 522: (5,43) ...\n",
      "1.975399307004409\n",
      "Training model 523: (5,44) ...\n",
      "2.11526113099535\n",
      "Training model 524: (5,45) ...\n",
      "2.14301006597816\n",
      "Training model 525: (5,46) ...\n",
      "1.9717108219920192\n",
      "Training model 526: (5,47) ...\n",
      "2.1757259739970323\n",
      "Training model 527: (5,48) ...\n",
      "2.163539197004866\n",
      "Training model 528: (5,49) ...\n",
      "2.19768162802211\n",
      "Training model 529: (5,50) ...\n",
      "2.154862645023968\n",
      "Training model 530: (5,51) ...\n",
      "2.027452512003947\n",
      "Training model 531: (5,52) ...\n",
      "2.152696033997927\n",
      "Training model 532: (5,53) ...\n",
      "2.1411260690074414\n",
      "Training model 533: (5,54) ...\n",
      "2.1464749989972916\n",
      "Training model 534: (5,55) ...\n",
      "2.1374126769951545\n",
      "Training model 535: (5,56) ...\n",
      "2.1039620640221983\n",
      "Training model 536: (5,57) ...\n",
      "2.123292959993705\n",
      "Training model 537: (5,58) ...\n",
      "2.1114270870166365\n",
      "Training model 538: (5,59) ...\n",
      "2.1178830020071473\n",
      "Training model 539: (5,60) ...\n",
      "2.10930779602495\n",
      "Training model 540: (5,61) ...\n",
      "2.122341352980584\n",
      "Training model 541: (5,62) ...\n",
      "1.8242560070066247\n",
      "Training model 542: (5,63) ...\n",
      "2.1141390569973737\n",
      "Training model 543: (5,64) ...\n",
      "2.110629014990991\n",
      "Training model 544: (5,65) ...\n",
      "2.116120414022589\n",
      "Training model 545: (5,66) ...\n",
      "2.106770726997638\n",
      "Training model 546: (5,67) ...\n",
      "2.1238858150027227\n",
      "Training model 547: (5,68) ...\n",
      "2.114354807010386\n",
      "Training model 548: (5,69) ...\n",
      "2.1577185379865114\n",
      "Training model 549: (5,70) ...\n",
      "2.105809096014127\n",
      "Training model 550: (5,71) ...\n",
      "2.1107219679979607\n",
      "Training model 551: (5,72) ...\n",
      "2.105695252015721\n",
      "Training model 552: (5,73) ...\n",
      "2.134294948016759\n",
      "Training model 553: (5,74) ...\n",
      "2.0795589569897857\n",
      "Training model 554: (5,75) ...\n",
      "2.1193917939963285\n",
      "Training model 555: (5,76) ...\n",
      "2.1233612379874103\n",
      "Training model 556: (5,77) ...\n",
      "2.1216775409993716\n",
      "Training model 557: (5,78) ...\n",
      "2.1247939789900556\n",
      "Training model 558: (5,79) ...\n",
      "2.1575526619853918\n",
      "Training model 559: (5,80) ...\n",
      "2.1117531179916114\n",
      "Training model 560: (5,81) ...\n",
      "2.1213902090094052\n",
      "Training model 561: (5,82) ...\n",
      "2.1070570790034253\n",
      "Training model 562: (5,83) ...\n",
      "2.211268637009198\n",
      "Training model 563: (5,84) ...\n",
      "2.1189471110119484\n",
      "Training model 564: (5,85) ...\n",
      "2.1736970329948235\n",
      "Training model 565: (5,86) ...\n",
      "2.1212450340099167\n",
      "Training model 566: (5,87) ...\n",
      "2.2043992299877573\n",
      "Training model 567: (5,88) ...\n",
      "2.133137466007611\n",
      "Training model 568: (5,89) ...\n",
      "2.2114158990152646\n",
      "Training model 569: (5,90) ...\n",
      "2.1612086259992793\n",
      "Training model 570: (5,91) ...\n",
      "2.1796936949831434\n",
      "Training model 571: (5,92) ...\n",
      "2.1478947610012256\n",
      "Training model 572: (5,93) ...\n",
      "2.2016780769918114\n",
      "Training model 573: (5,94) ...\n",
      "2.157866385008674\n",
      "Training model 574: (5,95) ...\n",
      "2.1847157379961573\n",
      "Training model 575: (5,96) ...\n",
      "2.1670099009934347\n",
      "Training model 576: (5,97) ...\n",
      "2.757255326025188\n",
      "Training model 577: (5,98) ...\n",
      "2.6826465369958896\n",
      "Training model 578: (5,99) ...\n",
      "2.1941085220023524\n",
      "Training model 579: (6,7) ...\n",
      "2.322915386001114\n",
      "Training model 580: (6,8) ...\n",
      "2.191155577020254\n",
      "Training model 581: (6,9) ...\n",
      "2.138716981979087\n",
      "Training model 582: (6,10) ...\n",
      "2.2106869260023814\n",
      "Training model 583: (6,11) ...\n",
      "2.1403965550125577\n",
      "Training model 584: (6,12) ...\n",
      "2.179931063001277\n",
      "Training model 585: (6,13) ...\n",
      "2.156829365005251\n",
      "Training model 586: (6,14) ...\n",
      "2.0279908690135926\n",
      "Training model 587: (6,15) ...\n",
      "2.100628600019263\n",
      "Training model 588: (6,16) ...\n",
      "2.1901458200009074\n",
      "Training model 589: (6,17) ...\n",
      "2.133493307977915\n",
      "Training model 590: (6,18) ...\n",
      "2.138801891996991\n",
      "Training model 591: (6,19) ...\n",
      "2.118065310001839\n",
      "Training model 592: (6,20) ...\n",
      "2.216208739002468\n",
      "Training model 593: (6,21) ...\n",
      "2.1467791560280602\n",
      "Training model 594: (6,22) ...\n",
      "2.1821840110060293\n",
      "Training model 595: (6,23) ...\n",
      "2.1306887209939305\n",
      "Training model 596: (6,24) ...\n",
      "2.133837344998028\n",
      "Training model 597: (6,25) ...\n",
      "2.134520980005618\n",
      "Training model 598: (6,26) ...\n",
      "2.1818059159850236\n",
      "Training model 599: (6,27) ...\n",
      "2.1434851849917322\n",
      "Training model 600: (6,28) ...\n",
      "2.189037977019325\n",
      "Training model 601: (6,29) ...\n",
      "2.1413442719785962\n",
      "Training model 602: (6,30) ...\n",
      "2.0071345739997923\n",
      "Training model 603: (6,31) ...\n",
      "2.1331309419765603\n",
      "Training model 604: (6,32) ...\n",
      "2.1624250449822284\n",
      "Training model 605: (6,33) ...\n",
      "2.130691089987522\n",
      "Training model 606: (6,34) ...\n",
      "2.159757293993607\n",
      "Training model 607: (6,35) ...\n",
      "2.122496376017807\n",
      "Training model 608: (6,36) ...\n",
      "2.174372184003005\n",
      "Training model 609: (6,37) ...\n",
      "2.1351081739994697\n",
      "Training model 610: (6,38) ...\n",
      "2.141631033999147\n",
      "Training model 611: (6,39) ...\n",
      "1.94232841199846\n",
      "Training model 612: (6,40) ...\n",
      "2.117220359010389\n",
      "Training model 613: (6,41) ...\n",
      "2.1533288559876382\n",
      "Training model 614: (6,42) ...\n",
      "2.1512569389888085\n",
      "Training model 615: (6,43) ...\n",
      "2.163480464980239\n",
      "Training model 616: (6,44) ...\n",
      "2.19706227700226\n",
      "Training model 617: (6,45) ...\n",
      "2.214756703004241\n",
      "Training model 618: (6,46) ...\n",
      "2.1647841250232887\n",
      "Training model 619: (6,47) ...\n",
      "2.1121649100095965\n",
      "Training model 620: (6,48) ...\n",
      "2.0243484450038522\n",
      "Training model 621: (6,49) ...\n",
      "2.2018240129982587\n",
      "Training model 622: (6,50) ...\n",
      "2.058844530984061\n",
      "Training model 623: (6,51) ...\n",
      "2.153898566000862\n",
      "Training model 624: (6,52) ...\n",
      "2.1498390519991517\n",
      "Training model 625: (6,53) ...\n",
      "2.1566722779825795\n",
      "Training model 626: (6,54) ...\n",
      "2.1520554390153848\n",
      "Training model 627: (6,55) ...\n",
      "2.162365371012129\n",
      "Training model 628: (6,56) ...\n",
      "2.242476646992145\n",
      "Training model 629: (6,57) ...\n",
      "2.2770772490184754\n",
      "Training model 630: (6,58) ...\n",
      "2.246800135995727\n",
      "Training model 631: (6,59) ...\n",
      "2.2507875750015955\n",
      "Training model 632: (6,60) ...\n",
      "2.137439345999155\n",
      "Training model 633: (6,61) ...\n",
      "2.1745432899915613\n",
      "Training model 634: (6,62) ...\n",
      "1.8465361749986187\n",
      "Training model 635: (6,63) ...\n",
      "2.0489154840179253\n",
      "Training model 636: (6,64) ...\n",
      "1.988653553999029\n",
      "Training model 637: (6,65) ...\n",
      "2.1207814929948654\n",
      "Training model 638: (6,66) ...\n",
      "2.148705080995569\n",
      "Training model 639: (6,67) ...\n",
      "2.092809750000015\n",
      "Training model 640: (6,68) ...\n",
      "1.9791461960121524\n",
      "Training model 641: (6,69) ...\n",
      "1.9760692919953726\n",
      "Training model 642: (6,70) ...\n",
      "2.134244184009731\n",
      "Training model 643: (6,71) ...\n",
      "2.1540882940171286\n",
      "Training model 644: (6,72) ...\n",
      "2.1548520629876293\n",
      "Training model 645: (6,73) ...\n",
      "2.1106795580126345\n",
      "Training model 646: (6,74) ...\n",
      "2.147693392005749\n",
      "Training model 647: (6,75) ...\n",
      "2.1511683959979564\n",
      "Training model 648: (6,76) ...\n",
      "2.142962678015465\n",
      "Training model 649: (6,77) ...\n",
      "2.1252521540154703\n",
      "Training model 650: (6,78) ...\n",
      "2.141873245011084\n",
      "Training model 651: (6,79) ...\n",
      "2.124021844996605\n",
      "Training model 652: (6,80) ...\n",
      "2.142701936973026\n",
      "Training model 653: (6,81) ...\n",
      "2.1242350259853993\n",
      "Training model 654: (6,82) ...\n",
      "2.1407039939949755\n",
      "Training model 655: (6,83) ...\n",
      "2.1263420910108835\n",
      "Training model 656: (6,84) ...\n",
      "2.1462725049932487\n",
      "Training model 657: (6,85) ...\n",
      "2.1339599329803605\n",
      "Training model 658: (6,86) ...\n",
      "2.150168290012516\n",
      "Training model 659: (6,87) ...\n",
      "2.2372467149980366\n",
      "Training model 660: (6,88) ...\n",
      "2.7370821370277554\n",
      "Training model 661: (6,89) ...\n",
      "2.328005718998611\n",
      "Training model 662: (6,90) ...\n",
      "2.20090503297979\n",
      "Training model 663: (6,91) ...\n",
      "2.1651190399716143\n",
      "Training model 664: (6,92) ...\n",
      "2.203782870026771\n",
      "Training model 665: (6,93) ...\n",
      "2.122162777988706\n",
      "Training model 666: (6,94) ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.165527231001761\n",
      "Training model 667: (6,95) ...\n",
      "2.155392212996958\n",
      "Training model 668: (6,96) ...\n",
      "2.177077686996199\n",
      "Training model 669: (6,97) ...\n",
      "2.166996404994279\n",
      "Training model 670: (6,98) ...\n",
      "2.1706193390127737\n",
      "Training model 671: (6,99) ...\n",
      "2.156885884993244\n",
      "Training model 672: (7,8) ...\n",
      "2.182766589015955\n",
      "Training model 673: (7,9) ...\n",
      "2.213318447000347\n",
      "Training model 674: (7,10) ...\n",
      "2.157784854003694\n",
      "Training model 675: (7,11) ...\n",
      "2.2299826800008304\n",
      "Training model 676: (7,12) ...\n",
      "2.2185140420042444\n",
      "Training model 677: (7,13) ...\n",
      "2.298167522007134\n",
      "Training model 678: (7,14) ...\n",
      "2.036665003019152\n",
      "Training model 679: (7,15) ...\n",
      "2.2443395589943975\n",
      "Training model 680: (7,16) ...\n",
      "2.3020763949898537\n",
      "Training model 681: (7,17) ...\n",
      "2.106839726999169\n",
      "Training model 682: (7,18) ...\n",
      "2.146843901980901\n",
      "Training model 683: (7,19) ...\n",
      "2.301623359991936\n",
      "Training model 684: (7,20) ...\n",
      "2.2954816249839496\n",
      "Training model 685: (7,21) ...\n",
      "2.16541533000418\n",
      "Training model 686: (7,22) ...\n",
      "2.3161046750028618\n",
      "Training model 687: (7,23) ...\n",
      "2.1766546630242374\n",
      "Training model 688: (7,24) ...\n",
      "2.1711856899783015\n",
      "Training model 689: (7,25) ...\n",
      "2.1487180539988913\n",
      "Training model 690: (7,26) ...\n",
      "2.1563303279981483\n",
      "Training model 691: (7,27) ...\n",
      "2.301455495005939\n",
      "Training model 692: (7,28) ...\n",
      "2.3028181130066514\n",
      "Training model 693: (7,29) ...\n",
      "2.2489828180114273\n",
      "Training model 694: (7,30) ...\n",
      "2.312419352994766\n",
      "Training model 695: (7,31) ...\n",
      "2.236239852005383\n",
      "Training model 696: (7,32) ...\n",
      "2.320473725005286\n",
      "Training model 697: (7,33) ...\n",
      "2.102468552009668\n",
      "Training model 698: (7,34) ...\n",
      "2.117737994005438\n",
      "Training model 699: (7,35) ...\n",
      "2.1279524080164265\n",
      "Training model 700: (7,36) ...\n",
      "2.1583292400173377\n",
      "Training model 701: (7,37) ...\n",
      "2.197310665011173\n",
      "Training model 702: (7,38) ...\n",
      "2.1622860679926816\n",
      "Training model 703: (7,39) ...\n",
      "2.1650005739938933\n",
      "Training model 704: (7,40) ...\n",
      "2.162038874987047\n",
      "Training model 705: (7,41) ...\n",
      "2.1524010249995627\n",
      "Training model 706: (7,42) ...\n",
      "2.2184477600094397\n",
      "Training model 707: (7,43) ...\n",
      "2.155967694998253\n",
      "Training model 708: (7,44) ...\n",
      "2.2098367320140824\n",
      "Training model 709: (7,45) ...\n",
      "1.9982237519870978\n",
      "Training model 710: (7,46) ...\n",
      "2.1957646119990386\n",
      "Training model 711: (7,47) ...\n",
      "2.195210712001426\n",
      "Training model 712: (7,48) ...\n",
      "2.364854326006025\n",
      "Training model 713: (7,49) ...\n",
      "2.3041062929842155\n",
      "Training model 714: (7,50) ...\n",
      "2.04332330901525\n",
      "Training model 715: (7,51) ...\n",
      "2.160086538991891\n",
      "Training model 716: (7,52) ...\n",
      "2.2155802600027528\n",
      "Training model 717: (7,53) ...\n",
      "2.1317668610136025\n",
      "Training model 718: (7,54) ...\n",
      "2.3239622350083664\n",
      "Training model 719: (7,55) ...\n",
      "2.1217778620193712\n",
      "Training model 720: (7,56) ...\n",
      "2.1418059790157713\n",
      "Training model 721: (7,57) ...\n",
      "2.1235359470010735\n",
      "Training model 722: (7,58) ...\n",
      "2.14337288599927\n",
      "Training model 723: (7,59) ...\n",
      "2.1563717410026584\n",
      "Training model 724: (7,60) ...\n",
      "2.1634452019934542\n",
      "Training model 725: (7,61) ...\n",
      "1.9916559900157154\n",
      "Training model 726: (7,62) ...\n",
      "2.2300953310041223\n",
      "Training model 727: (7,63) ...\n",
      "2.0562941580137704\n",
      "Training model 728: (7,64) ...\n",
      "2.225448098004563\n",
      "Training model 729: (7,65) ...\n",
      "2.1810435179795604\n",
      "Training model 730: (7,66) ...\n",
      "2.310010543005774\n",
      "Training model 731: (7,67) ...\n",
      "2.256471419997979\n",
      "Training model 732: (7,68) ...\n",
      "2.132930699008284\n",
      "Training model 733: (7,69) ...\n",
      "2.3375466339930426\n",
      "Training model 734: (7,70) ...\n",
      "2.167024614987895\n",
      "Training model 735: (7,71) ...\n",
      "2.1040196690009907\n",
      "Training model 736: (7,72) ...\n",
      "2.1384898209944367\n",
      "Training model 737: (7,73) ...\n",
      "2.151233974000206\n",
      "Training model 738: (7,74) ...\n",
      "2.0302081830159295\n",
      "Training model 739: (7,75) ...\n",
      "2.2183689780067652\n",
      "Training model 740: (7,76) ...\n",
      "2.202553507988341\n",
      "Training model 741: (7,77) ...\n",
      "2.4790869850257877\n",
      "Training model 742: (7,78) ...\n",
      "2.7858079620054923\n",
      "Training model 743: (7,79) ...\n",
      "2.2208843889820855\n",
      "Training model 744: (7,80) ...\n",
      "2.1708981190167833\n",
      "Training model 745: (7,81) ...\n",
      "2.216104652994545\n",
      "Training model 746: (7,82) ...\n",
      "2.1235055399884004\n",
      "Training model 747: (7,83) ...\n",
      "2.14477736299159\n",
      "Training model 748: (7,84) ...\n",
      "2.2158251499931794\n",
      "Training model 749: (7,85) ...\n",
      "2.145786888024304\n",
      "Training model 750: (7,86) ...\n",
      "2.371233669022331\n",
      "Training model 751: (7,87) ...\n",
      "2.1517617830249947\n",
      "Training model 752: (7,88) ...\n",
      "2.2285938269924372\n",
      "Training model 753: (7,89) ...\n",
      "1.9967775429831818\n",
      "Training model 754: (7,90) ...\n",
      "2.127390743000433\n",
      "Training model 755: (7,91) ...\n",
      "2.1037999260006472\n",
      "Training model 756: (7,92) ...\n",
      "2.1302201729849912\n",
      "Training model 757: (7,93) ...\n",
      "2.1226858450099826\n",
      "Training model 758: (7,94) ...\n",
      "2.142683894984657\n",
      "Training model 759: (7,95) ...\n",
      "2.120844243996544\n",
      "Training model 760: (7,96) ...\n",
      "2.1266343710012734\n",
      "Training model 761: (7,97) ...\n",
      "2.131712784001138\n",
      "Training model 762: (7,98) ...\n",
      "2.136723779985914\n",
      "Training model 763: (7,99) ...\n",
      "2.127801697002724\n",
      "Training model 764: (8,9) ...\n",
      "2.1253756849910133\n",
      "Training model 765: (8,10) ...\n",
      "2.119505009992281\n",
      "Training model 766: (8,11) ...\n",
      "2.1303229029872455\n",
      "Training model 767: (8,12) ...\n",
      "2.1217847959778737\n",
      "Training model 768: (8,13) ...\n",
      "2.131528289988637\n",
      "Training model 769: (8,14) ...\n",
      "2.120292020001216\n",
      "Training model 770: (8,15) ...\n",
      "2.1285076159983873\n",
      "Training model 771: (8,16) ...\n",
      "2.132673934014747\n",
      "Training model 772: (8,17) ...\n",
      "2.1288004369998816\n",
      "Training model 773: (8,18) ...\n",
      "2.1266684430011082\n",
      "Training model 774: (8,19) ...\n",
      "2.205144895997364\n",
      "Training model 775: (8,20) ...\n",
      "2.142315289005637\n",
      "Training model 776: (8,21) ...\n",
      "2.1706637910101563\n",
      "Training model 777: (8,22) ...\n",
      "2.153676053014351\n",
      "Training model 778: (8,23) ...\n",
      "2.247463769017486\n",
      "Training model 779: (8,24) ...\n",
      "2.107223516999511\n",
      "Training model 780: (8,25) ...\n",
      "2.16034496499924\n",
      "Training model 781: (8,26) ...\n",
      "2.1726110210001934\n",
      "Training model 782: (8,27) ...\n",
      "2.185267032997217\n",
      "Training model 783: (8,28) ...\n",
      "2.1942295110202394\n",
      "Training model 784: (8,29) ...\n",
      "2.1461632779974025\n",
      "Training model 785: (8,30) ...\n",
      "2.178856705984799\n",
      "Training model 786: (8,31) ...\n",
      "2.1618839889997616\n",
      "Training model 787: (8,32) ...\n",
      "2.1619480869849212\n",
      "Training model 788: (8,33) ...\n",
      "2.173025979020167\n",
      "Training model 789: (8,34) ...\n",
      "2.033601197996177\n",
      "Training model 790: (8,35) ...\n",
      "2.1910013490123674\n",
      "Training model 791: (8,36) ...\n",
      "2.1786115569993854\n",
      "Training model 792: (8,37) ...\n",
      "2.1943107349798083\n",
      "Training model 793: (8,38) ...\n",
      "2.1827494640019722\n",
      "Training model 794: (8,39) ...\n",
      "2.1538421000004746\n",
      "Training model 795: (8,40) ...\n",
      "2.176404794008704\n",
      "Training model 796: (8,41) ...\n",
      "2.2214354839816224\n",
      "Training model 797: (8,42) ...\n",
      "2.1795396079833154\n",
      "Training model 798: (8,43) ...\n",
      "2.2062513460114133\n",
      "Training model 799: (8,44) ...\n",
      "2.1666034780209884\n",
      "Training model 800: (8,45) ...\n",
      "2.1817689139861614\n",
      "Training model 801: (8,46) ...\n",
      "2.140240086999256\n",
      "Training model 802: (8,47) ...\n",
      "2.1924660880176816\n",
      "Training model 803: (8,48) ...\n",
      "2.155140967981424\n",
      "Training model 804: (8,49) ...\n",
      "2.2035904320073314\n",
      "Training model 805: (8,50) ...\n",
      "2.17509831499774\n",
      "Training model 806: (8,51) ...\n",
      "2.1555353370204102\n",
      "Training model 807: (8,52) ...\n",
      "2.185552242997801\n",
      "Training model 808: (8,53) ...\n",
      "2.17215191401192\n",
      "Training model 809: (8,54) ...\n",
      "2.1736848129949067\n",
      "Training model 810: (8,55) ...\n",
      "2.17298277100781\n",
      "Training model 811: (8,56) ...\n",
      "2.226526632992318\n",
      "Training model 812: (8,57) ...\n",
      "2.3114424019877333\n",
      "Training model 813: (8,58) ...\n",
      "2.2313109080132563\n",
      "Training model 814: (8,59) ...\n",
      "2.129102980979951\n",
      "Training model 815: (8,60) ...\n",
      "2.0956452960090246\n",
      "Training model 816: (8,61) ...\n",
      "2.1317944529873785\n",
      "Training model 817: (8,62) ...\n",
      "2.141530014021555\n",
      "Training model 818: (8,63) ...\n",
      "2.15611400801572\n",
      "Training model 819: (8,64) ...\n",
      "2.1440606050018687\n",
      "Training model 820: (8,65) ...\n",
      "2.1850081570155453\n",
      "Training model 821: (8,66) ...\n",
      "2.171613188984338\n",
      "Training model 822: (8,67) ...\n",
      "2.1780923339829315\n",
      "Training model 823: (8,68) ...\n",
      "2.1654733259929344\n",
      "Training model 824: (8,69) ...\n",
      "2.47740653497749\n",
      "Training model 825: (8,70) ...\n",
      "2.715193005016772\n",
      "Training model 826: (8,71) ...\n",
      "2.1307429269945715\n",
      "Training model 827: (8,72) ...\n",
      "2.1199273119855206\n",
      "Training model 828: (8,73) ...\n",
      "2.1364355550031178\n",
      "Training model 829: (8,74) ...\n",
      "2.120569423015695\n",
      "Training model 830: (8,75) ...\n",
      "2.0937683439988177\n",
      "Training model 831: (8,76) ...\n",
      "2.1315334489918314\n",
      "Training model 832: (8,77) ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1262727309949696\n",
      "Training model 833: (8,78) ...\n",
      "2.132498671999201\n",
      "Training model 834: (8,79) ...\n",
      "2.135138935991563\n",
      "Training model 835: (8,80) ...\n",
      "2.127346794004552\n",
      "Training model 836: (8,81) ...\n",
      "2.138160061003873\n",
      "Training model 837: (8,82) ...\n",
      "2.1323034079978243\n",
      "Training model 838: (8,83) ...\n",
      "2.166081731003942\n",
      "Training model 839: (8,84) ...\n",
      "2.1206003400147893\n",
      "Training model 840: (8,85) ...\n",
      "2.1456715909880586\n",
      "Training model 841: (8,86) ...\n",
      "2.1369866220047697\n",
      "Training model 842: (8,87) ...\n",
      "2.137655125989113\n",
      "Training model 843: (8,88) ...\n",
      "2.1319473600015044\n",
      "Training model 844: (8,89) ...\n",
      "2.0171445720188785\n",
      "Training model 845: (8,90) ...\n",
      "2.1820588179980405\n",
      "Training model 846: (8,91) ...\n",
      "2.221115041000303\n",
      "Training model 847: (8,92) ...\n",
      "2.189824269997189\n",
      "Training model 848: (8,93) ...\n",
      "2.1775176289957017\n",
      "Training model 849: (8,94) ...\n",
      "2.1896705249964725\n",
      "Training model 850: (8,95) ...\n",
      "2.1961328590114135\n",
      "Training model 851: (8,96) ...\n",
      "2.1568837400118355\n",
      "Training model 852: (8,97) ...\n",
      "2.20665260500391\n",
      "Training model 853: (8,98) ...\n",
      "2.148952114977874\n",
      "Training model 854: (8,99) ...\n",
      "2.174132621003082\n",
      "Training model 855: (9,10) ...\n",
      "2.166824586020084\n",
      "Training model 856: (9,11) ...\n",
      "2.0173626279865857\n",
      "Training model 857: (9,12) ...\n",
      "1.9638087089988403\n",
      "Training model 858: (9,13) ...\n",
      "2.135559046990238\n",
      "Training model 859: (9,14) ...\n",
      "2.1186754039954394\n",
      "Training model 860: (9,15) ...\n",
      "1.948259947996121\n",
      "Training model 861: (9,16) ...\n",
      "2.1169215650006663\n",
      "Training model 862: (9,17) ...\n",
      "2.1364521799841896\n",
      "Training model 863: (9,18) ...\n",
      "2.1115100500173867\n",
      "Training model 864: (9,19) ...\n",
      "2.13298369399854\n",
      "Training model 865: (9,20) ...\n",
      "2.115562835999299\n",
      "Training model 866: (9,21) ...\n",
      "1.9758710470050573\n",
      "Training model 867: (9,22) ...\n",
      "2.114217644004384\n",
      "Training model 868: (9,23) ...\n",
      "2.1445760450151283\n",
      "Training model 869: (9,24) ...\n",
      "2.1299011330120265\n",
      "Training model 870: (9,25) ...\n",
      "2.1383061870001256\n",
      "Training model 871: (9,26) ...\n",
      "2.1117506599985063\n",
      "Training model 872: (9,27) ...\n",
      "2.138656186987646\n",
      "Training model 873: (9,28) ...\n",
      "2.124174997006776\n",
      "Training model 874: (9,29) ...\n",
      "2.1301969820051454\n",
      "Training model 875: (9,30) ...\n",
      "2.1092937119829003\n",
      "Training model 876: (9,31) ...\n",
      "2.1187386529927608\n",
      "Training model 877: (9,32) ...\n",
      "2.1166538940160535\n",
      "Training model 878: (9,33) ...\n",
      "2.121853671007557\n",
      "Training model 879: (9,34) ...\n",
      "2.115000208024867\n",
      "Training model 880: (9,35) ...\n",
      "2.085680210002465\n",
      "Training model 881: (9,36) ...\n",
      "2.112136020004982\n",
      "Training model 882: (9,37) ...\n",
      "2.134359409013996\n",
      "Training model 883: (9,38) ...\n",
      "2.112705075996928\n",
      "Training model 884: (9,39) ...\n",
      "2.0513127940066624\n",
      "Training model 885: (9,40) ...\n",
      "2.146519375994103\n",
      "Training model 886: (9,41) ...\n",
      "2.172436218999792\n",
      "Training model 887: (9,42) ...\n",
      "2.1615633509936742\n",
      "Training model 888: (9,43) ...\n",
      "2.1616069529845845\n",
      "Training model 889: (9,44) ...\n",
      "2.126139942003647\n",
      "Training model 890: (9,45) ...\n",
      "2.193591102026403\n",
      "Training model 891: (9,46) ...\n",
      "2.190557030000491\n",
      "Training model 892: (9,47) ...\n",
      "2.18254199999501\n",
      "Training model 893: (9,48) ...\n",
      "2.1601901370158885\n",
      "Training model 894: (9,49) ...\n",
      "2.2156867450103164\n",
      "Training model 895: (9,50) ...\n",
      "2.1571123500179965\n",
      "Training model 896: (9,51) ...\n",
      "2.1838932529790327\n",
      "Training model 897: (9,52) ...\n",
      "2.199636270990595\n",
      "Training model 898: (9,53) ...\n",
      "2.1776718819746748\n",
      "Training model 899: (9,54) ...\n",
      "2.1610495829954743\n",
      "Training model 900: (9,55) ...\n",
      "2.1617608760134317\n",
      "Training model 901: (9,56) ...\n",
      "2.1753005100181326\n",
      "Training model 902: (9,57) ...\n",
      "2.1671605050214566\n",
      "Training model 903: (9,58) ...\n",
      "2.162150065996684\n",
      "Training model 904: (9,59) ...\n",
      "2.182054978009546\n",
      "Training model 905: (9,60) ...\n",
      "2.1292674019932747\n",
      "Training model 906: (9,61) ...\n",
      "2.1771025499911048\n",
      "Training model 907: (9,62) ...\n",
      "2.188265125005273\n",
      "Training model 908: (9,63) ...\n",
      "2.5969414739811327\n",
      "Training model 909: (9,64) ...\n",
      "2.6608000329870265\n",
      "Training model 910: (9,65) ...\n",
      "2.122748640977079\n",
      "Training model 911: (9,66) ...\n",
      "2.1100182500085793\n",
      "Training model 912: (9,67) ...\n",
      "2.1113262309809215\n",
      "Training model 913: (9,68) ...\n",
      "2.072745056997519\n",
      "Training model 914: (9,69) ...\n",
      "2.12048959400272\n",
      "Training model 915: (9,70) ...\n",
      "1.9450194940145593\n",
      "Training model 916: (9,71) ...\n",
      "2.043703553004889\n",
      "Training model 917: (9,72) ...\n",
      "2.1118347449810244\n",
      "Training model 918: (9,73) ...\n",
      "2.1209575230022892\n",
      "Training model 919: (9,74) ...\n",
      "2.12717499199789\n",
      "Training model 920: (9,75) ...\n",
      "2.179690369986929\n",
      "Training model 921: (9,76) ...\n",
      "2.1065282199997455\n",
      "Training model 922: (9,77) ...\n",
      "2.1790855810104404\n",
      "Training model 923: (9,78) ...\n",
      "2.1598061559780035\n",
      "Training model 924: (9,79) ...\n",
      "2.005983486014884\n",
      "Training model 925: (9,80) ...\n",
      "2.16184253199026\n",
      "Training model 926: (9,81) ...\n",
      "2.1564198240230326\n",
      "Training model 927: (9,82) ...\n",
      "2.1363575650029816\n",
      "Training model 928: (9,83) ...\n",
      "2.128466155991191\n",
      "Training model 929: (9,84) ...\n",
      "2.109123236994492\n",
      "Training model 930: (9,85) ...\n",
      "2.113977052998962\n",
      "Training model 931: (9,86) ...\n",
      "2.110368476016447\n",
      "Training model 932: (9,87) ...\n",
      "2.114719128003344\n",
      "Training model 933: (9,88) ...\n",
      "2.1087011809868272\n",
      "Training model 934: (9,89) ...\n",
      "2.129326577996835\n",
      "Training model 935: (9,90) ...\n",
      "2.111111701000482\n",
      "Training model 936: (9,91) ...\n",
      "2.0718597439990845\n",
      "Training model 937: (9,92) ...\n",
      "2.108355523989303\n",
      "Training model 938: (9,93) ...\n",
      "2.126284008991206\n",
      "Training model 939: (9,94) ...\n",
      "2.111272164998809\n",
      "Training model 940: (9,95) ...\n",
      "2.077951386978384\n",
      "Training model 941: (9,96) ...\n",
      "2.092732007004088\n",
      "Training model 942: (9,97) ...\n",
      "2.119524634006666\n",
      "Training model 943: (9,98) ...\n",
      "2.1126929460151587\n",
      "Training model 944: (9,99) ...\n",
      "2.160525123006664\n",
      "Training model 945: (10,11) ...\n",
      "2.1859093030216172\n",
      "Training model 946: (10,12) ...\n",
      "2.161573972000042\n",
      "Training model 947: (10,13) ...\n",
      "2.1421132929972373\n",
      "Training model 948: (10,14) ...\n",
      "2.202140787994722\n",
      "Training model 949: (10,15) ...\n",
      "2.1269645870197564\n",
      "Training model 950: (10,16) ...\n",
      "2.199670078989584\n",
      "Training model 951: (10,17) ...\n",
      "2.1108400960220024\n",
      "Training model 952: (10,18) ...\n",
      "2.121708375023445\n",
      "Training model 953: (10,19) ...\n",
      "2.118297626002459\n",
      "Training model 954: (10,20) ...\n",
      "2.119939770986093\n",
      "Training model 955: (10,21) ...\n",
      "2.110126568994019\n",
      "Training model 956: (10,22) ...\n",
      "2.1154385690169875\n",
      "Training model 957: (10,23) ...\n",
      "2.112145953986328\n",
      "Training model 958: (10,24) ...\n",
      "2.118890420999378\n",
      "Training model 959: (10,25) ...\n",
      "2.108928666013526\n",
      "Training model 960: (10,26) ...\n",
      "2.1141792979906313\n",
      "Training model 961: (10,27) ...\n",
      "2.1094530939881224\n",
      "Training model 962: (10,28) ...\n",
      "2.1197218089946546\n",
      "Training model 963: (10,29) ...\n",
      "2.1103412880038377\n",
      "Training model 964: (10,30) ...\n",
      "2.142670103989076\n",
      "Training model 965: (10,31) ...\n",
      "2.133029955002712\n",
      "Training model 966: (10,32) ...\n",
      "2.1983881979831494\n",
      "Training model 967: (10,33) ...\n",
      "2.1752669409906957\n",
      "Training model 968: (10,34) ...\n",
      "2.186874293984147\n",
      "Training model 969: (10,35) ...\n",
      "2.137475188996177\n",
      "Training model 970: (10,36) ...\n",
      "2.201937056990573\n",
      "Training model 971: (10,37) ...\n",
      "2.164048286009347\n",
      "Training model 972: (10,38) ...\n",
      "2.1821418209874537\n",
      "Training model 973: (10,39) ...\n",
      "2.1500655509880744\n",
      "Training model 974: (10,40) ...\n",
      "2.201256233995082\n",
      "Training model 975: (10,41) ...\n",
      "2.1386329059896525\n",
      "Training model 976: (10,42) ...\n",
      "2.2059575589955784\n",
      "Training model 977: (10,43) ...\n",
      "2.116719536978053\n",
      "Training model 978: (10,44) ...\n",
      "2.1813590839738026\n",
      "Training model 979: (10,45) ...\n",
      "2.2036276810104027\n",
      "Training model 980: (10,46) ...\n",
      "2.155853711999953\n",
      "Training model 981: (10,47) ...\n",
      "2.1681385079864413\n",
      "Training model 982: (10,48) ...\n",
      "2.1967553209979087\n",
      "Training model 983: (10,49) ...\n",
      "2.1528967570047826\n",
      "Training model 984: (10,50) ...\n",
      "2.1880715530132875\n",
      "Training model 985: (10,51) ...\n",
      "2.114667432004353\n",
      "Training model 986: (10,52) ...\n",
      "2.187523180997232\n",
      "Training model 987: (10,53) ...\n",
      "2.154335441009607\n",
      "Training model 988: (10,54) ...\n",
      "2.206810169998789\n",
      "Training model 989: (10,55) ...\n",
      "2.0952886489976663\n",
      "Training model 990: (10,56) ...\n",
      "2.2305262210138608\n",
      "Training model 991: (10,57) ...\n",
      "2.181522377009969\n",
      "Training model 992: (10,58) ...\n",
      "2.6800972239871044\n",
      "Training model 993: (10,59) ...\n",
      "2.874595650995616\n",
      "Training model 994: (10,60) ...\n",
      "2.207308530982118\n",
      "Training model 995: (10,61) ...\n",
      "2.1343578369996976\n",
      "Training model 996: (10,62) ...\n",
      "2.185962212999584\n",
      "Training model 997: (10,63) ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.319485578977037\n",
      "Training model 998: (10,64) ...\n",
      "2.262778962001903\n",
      "Training model 999: (10,65) ...\n",
      "2.1169611969962716\n",
      "Training model 1000: (10,66) ...\n",
      "2.2140485819836613\n",
      "Training model 1001: (10,67) ...\n",
      "2.311675759992795\n",
      "Training model 1002: (10,68) ...\n",
      "2.130570080014877\n",
      "Training model 1003: (10,69) ...\n",
      "2.116248655016534\n",
      "Training model 1004: (10,70) ...\n",
      "2.142624076019274\n",
      "Training model 1005: (10,71) ...\n",
      "2.170801943022525\n",
      "Training model 1006: (10,72) ...\n",
      "2.1251859089825302\n",
      "Training model 1007: (10,73) ...\n",
      "2.109263433027081\n",
      "Training model 1008: (10,74) ...\n",
      "2.131285351002589\n",
      "Training model 1009: (10,75) ...\n",
      "2.1197918789985124\n",
      "Training model 1010: (10,76) ...\n",
      "2.1480113190191332\n",
      "Training model 1011: (10,77) ...\n",
      "2.121526397007983\n",
      "Training model 1012: (10,78) ...\n",
      "2.1295907509920653\n",
      "Training model 1013: (10,79) ...\n",
      "2.1257108130084816\n",
      "Training model 1014: (10,80) ...\n",
      "2.12785668799188\n",
      "Training model 1015: (10,81) ...\n",
      "2.1190747960063163\n",
      "Training model 1016: (10,82) ...\n",
      "2.1263550920120906\n",
      "Training model 1017: (10,83) ...\n",
      "2.1193209670018405\n",
      "Training model 1018: (10,84) ...\n",
      "2.1211193909985013\n",
      "Training model 1019: (10,85) ...\n",
      "2.1168375730048865\n",
      "Training model 1020: (10,86) ...\n",
      "1.9852169409859926\n",
      "Training model 1021: (10,87) ...\n",
      "2.1198049539816566\n",
      "Training model 1022: (10,88) ...\n",
      "2.126715268997941\n",
      "Training model 1023: (10,89) ...\n",
      "2.1267777680186555\n",
      "Training model 1024: (10,90) ...\n",
      "2.1249521980062127\n",
      "Training model 1025: (10,91) ...\n",
      "2.125059327983763\n",
      "Training model 1026: (10,92) ...\n",
      "2.1277141649916302\n",
      "Training model 1027: (10,93) ...\n",
      "1.9725013250135817\n",
      "Training model 1028: (10,94) ...\n",
      "2.146051374002127\n",
      "Training model 1029: (10,95) ...\n",
      "2.174241559987422\n",
      "Training model 1030: (10,96) ...\n",
      "2.177228022017516\n",
      "Training model 1031: (10,97) ...\n",
      "2.1700607660168316\n",
      "Training model 1032: (10,98) ...\n",
      "2.1770955069805495\n",
      "Training model 1033: (10,99) ...\n",
      "2.2001445119967684\n",
      "Training model 1034: (11,12) ...\n",
      "2.148342917993432\n",
      "Training model 1035: (11,13) ...\n",
      "2.214398487994913\n",
      "Training model 1036: (11,14) ...\n",
      "2.1570715679845307\n",
      "Training model 1037: (11,15) ...\n",
      "2.1640082730154973\n",
      "Training model 1038: (11,16) ...\n",
      "2.1675867299782112\n",
      "Training model 1039: (11,17) ...\n",
      "2.1512469080043957\n",
      "Training model 1040: (11,18) ...\n",
      "2.158372876001522\n",
      "Training model 1041: (11,19) ...\n",
      "2.1953625250025652\n",
      "Training model 1042: (11,20) ...\n",
      "2.1784359510056674\n",
      "Training model 1043: (11,21) ...\n",
      "2.1623682509816717\n",
      "Training model 1044: (11,22) ...\n",
      "2.157103291974636\n",
      "Training model 1045: (11,23) ...\n",
      "2.1717525799758732\n",
      "Training model 1046: (11,24) ...\n",
      "2.190703881002264\n",
      "Training model 1047: (11,25) ...\n",
      "2.16709861101117\n",
      "Training model 1048: (11,26) ...\n",
      "2.198566984006902\n",
      "Training model 1049: (11,27) ...\n",
      "2.1451099990226794\n",
      "Training model 1050: (11,28) ...\n",
      "2.1815423920052126\n",
      "Training model 1051: (11,29) ...\n",
      "2.1862846050062217\n",
      "Training model 1052: (11,30) ...\n",
      "1.9981626099906862\n",
      "Training model 1053: (11,31) ...\n",
      "2.1712500950088724\n",
      "Training model 1054: (11,32) ...\n",
      "2.1654303609975614\n",
      "Training model 1055: (11,33) ...\n",
      "2.1607833730231505\n",
      "Training model 1056: (11,34) ...\n",
      "2.169059535022825\n",
      "Training model 1057: (11,35) ...\n",
      "2.1846087140147574\n",
      "Training model 1058: (11,36) ...\n",
      "2.1534628109948244\n",
      "Training model 1059: (11,37) ...\n",
      "2.167401307000546\n",
      "Training model 1060: (11,38) ...\n",
      "2.151001897000242\n",
      "Training model 1061: (11,39) ...\n",
      "2.1644851099990774\n",
      "Training model 1062: (11,40) ...\n",
      "2.1391673969919793\n",
      "Training model 1063: (11,41) ...\n",
      "2.1309957759804092\n",
      "Training model 1064: (11,42) ...\n",
      "2.122824944992317\n",
      "Training model 1065: (11,43) ...\n",
      "2.1255407020216808\n",
      "Training model 1066: (11,44) ...\n",
      "2.1250585570232943\n",
      "Training model 1067: (11,45) ...\n",
      "2.123887822992401\n",
      "Training model 1068: (11,46) ...\n",
      "2.10603705199901\n",
      "Training model 1069: (11,47) ...\n",
      "2.1257108050049283\n",
      "Training model 1070: (11,48) ...\n",
      "2.124341892020311\n",
      "Training model 1071: (11,49) ...\n",
      "2.127341964020161\n",
      "Training model 1072: (11,50) ...\n",
      "1.975533771008486\n",
      "Training model 1073: (11,51) ...\n",
      "2.128517134988215\n",
      "Training model 1074: (11,52) ...\n",
      "2.1230607990000863\n",
      "Training model 1075: (11,53) ...\n",
      "2.545507129019825\n",
      "Training model 1076: (11,54) ...\n",
      "2.811680390004767\n",
      "Training model 1077: (11,55) ...\n",
      "2.1897050800034776\n",
      "Training model 1078: (11,56) ...\n",
      "2.229404481011443\n",
      "Training model 1079: (11,57) ...\n",
      "2.1664390889927745\n",
      "Training model 1080: (11,58) ...\n",
      "2.2053155619942117\n",
      "Training model 1081: (11,59) ...\n",
      "2.239890719007235\n",
      "Training model 1082: (11,60) ...\n",
      "1.9935779860243201\n",
      "Training model 1083: (11,61) ...\n",
      "2.2388408390106633\n",
      "Training model 1084: (11,62) ...\n",
      "2.158325819997117\n",
      "Training model 1085: (11,63) ...\n",
      "2.1734882580058184\n",
      "Training model 1086: (11,64) ...\n",
      "2.193010495015187\n",
      "Training model 1087: (11,65) ...\n",
      "2.2034353489871137\n",
      "Training model 1088: (11,66) ...\n",
      "2.1811869039956946\n",
      "Training model 1089: (11,67) ...\n",
      "2.215631188999396\n",
      "Training model 1090: (11,68) ...\n",
      "1.9212613640120253\n",
      "Training model 1091: (11,69) ...\n",
      "2.2522176489874255\n",
      "Training model 1092: (11,70) ...\n",
      "2.2106593000062276\n",
      "Training model 1093: (11,71) ...\n",
      "2.225771157973213\n",
      "Training model 1094: (11,72) ...\n",
      "2.2123836429964285\n",
      "Training model 1095: (11,73) ...\n",
      "2.2417293320177123\n",
      "Training model 1096: (11,74) ...\n",
      "2.173909912002273\n",
      "Training model 1097: (11,75) ...\n",
      "2.3219808580179233\n",
      "Training model 1098: (11,76) ...\n",
      "2.072621324012289\n",
      "Training model 1099: (11,77) ...\n",
      "2.1999688129872084\n",
      "Training model 1100: (11,78) ...\n",
      "2.164958025998203\n",
      "Training model 1101: (11,79) ...\n",
      "2.121401254000375\n",
      "Training model 1102: (11,80) ...\n",
      "2.1166507879970595\n",
      "Training model 1103: (11,81) ...\n",
      "2.143490924005164\n",
      "Training model 1104: (11,82) ...\n",
      "2.1435924660181627\n",
      "Training model 1105: (11,83) ...\n",
      "2.1405451059981715\n",
      "Training model 1106: (11,84) ...\n",
      "2.1612474440189544\n",
      "Training model 1107: (11,85) ...\n",
      "2.1654371790064033\n",
      "Training model 1108: (11,86) ...\n",
      "2.186739883007249\n",
      "Training model 1109: (11,87) ...\n",
      "2.17318381901714\n",
      "Training model 1110: (11,88) ...\n",
      "2.1737164829974063\n",
      "Training model 1111: (11,89) ...\n",
      "2.170434823987307\n",
      "Training model 1112: (11,90) ...\n",
      "2.2480010889994446\n",
      "Training model 1113: (11,91) ...\n",
      "2.1432043579989113\n",
      "Training model 1114: (11,92) ...\n",
      "2.1526709659956396\n",
      "Training model 1115: (11,93) ...\n",
      "2.1596710110025015\n",
      "Training model 1116: (11,94) ...\n",
      "2.238679607020458\n",
      "Training model 1117: (11,95) ...\n",
      "2.1398863549984526\n",
      "Training model 1118: (11,96) ...\n",
      "2.179867558996193\n",
      "Training model 1119: (11,97) ...\n",
      "2.1570910640002694\n",
      "Training model 1120: (11,98) ...\n",
      "2.1735887700051535\n",
      "Training model 1121: (11,99) ...\n",
      "2.210329349996755\n",
      "Training model 1122: (12,13) ...\n",
      "2.151615907001542\n",
      "Training model 1123: (12,14) ...\n",
      "2.1700312870088965\n",
      "Training model 1124: (12,15) ...\n",
      "2.163050061004469\n",
      "Training model 1125: (12,16) ...\n",
      "2.1670065700018313\n",
      "Training model 1126: (12,17) ...\n",
      "2.1800162300060038\n",
      "Training model 1127: (12,18) ...\n",
      "2.1788878399820533\n",
      "Training model 1128: (12,19) ...\n",
      "2.1636552560084965\n",
      "Training model 1129: (12,20) ...\n",
      "2.161437085014768\n",
      "Training model 1130: (12,21) ...\n",
      "2.165554015984526\n",
      "Training model 1131: (12,22) ...\n",
      "2.1769269480137154\n",
      "Training model 1132: (12,23) ...\n",
      "2.1804684810049366\n",
      "Training model 1133: (12,24) ...\n",
      "2.1734557089803275\n",
      "Training model 1134: (12,25) ...\n",
      "2.1622981740219984\n",
      "Training model 1135: (12,26) ...\n",
      "2.1803226440097205\n",
      "Training model 1136: (12,27) ...\n",
      "2.1750108799897134\n",
      "Training model 1137: (12,28) ...\n",
      "2.1136909159831703\n",
      "Training model 1138: (12,29) ...\n",
      "2.193601776001742\n",
      "Training model 1139: (12,30) ...\n",
      "2.1771831689984538\n",
      "Training model 1140: (12,31) ...\n",
      "2.193421322008362\n",
      "Training model 1141: (12,32) ...\n",
      "2.181556224997621\n",
      "Training model 1142: (12,33) ...\n",
      "2.1970339989929926\n",
      "Training model 1143: (12,34) ...\n",
      "2.171531871019397\n",
      "Training model 1144: (12,35) ...\n",
      "2.1694042420131154\n",
      "Training model 1145: (12,36) ...\n",
      "2.1134635639900807\n",
      "Training model 1146: (12,37) ...\n",
      "2.2081883220234886\n",
      "Training model 1147: (12,38) ...\n",
      "2.2020174579811282\n",
      "Training model 1148: (12,39) ...\n",
      "2.2007374970125966\n",
      "Training model 1149: (12,40) ...\n",
      "2.1570067110005766\n",
      "Training model 1150: (12,41) ...\n",
      "2.1472383580112364\n",
      "Training model 1151: (12,42) ...\n",
      "2.184763194003608\n",
      "Training model 1152: (12,43) ...\n",
      "2.174475360981887\n",
      "Training model 1153: (12,44) ...\n",
      "2.0254280640219804\n",
      "Training model 1154: (12,45) ...\n",
      "2.195230424986221\n",
      "Training model 1155: (12,46) ...\n",
      "2.253514346986776\n",
      "Training model 1156: (12,47) ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1637623909919057\n",
      "Training model 1157: (12,48) ...\n",
      "2.410427394002909\n",
      "Training model 1158: (12,49) ...\n",
      "2.911995806993218\n",
      "Training model 1159: (12,50) ...\n",
      "2.2635195949987974\n",
      "Training model 1160: (12,51) ...\n",
      "2.1943499380140565\n",
      "Training model 1161: (12,52) ...\n",
      "2.143553485017037\n",
      "Training model 1162: (12,53) ...\n",
      "2.1386664519959595\n",
      "Training model 1163: (12,54) ...\n",
      "2.1115075520065147\n",
      "Training model 1164: (12,55) ...\n",
      "2.152924524998525\n",
      "Training model 1165: (12,56) ...\n",
      "2.147705544019118\n",
      "Training model 1166: (12,57) ...\n",
      "2.0124865580000915\n",
      "Training model 1167: (12,58) ...\n",
      "2.1299753690254875\n",
      "Training model 1168: (12,59) ...\n",
      "2.1468259220127948\n",
      "Training model 1169: (12,60) ...\n",
      "2.0916478039871436\n",
      "Training model 1170: (12,61) ...\n",
      "2.155371601023944\n",
      "Training model 1171: (12,62) ...\n",
      "2.2805510780017357\n",
      "Training model 1172: (12,63) ...\n",
      "2.1500392069865484\n",
      "Training model 1173: (12,64) ...\n",
      "2.179674244020134\n",
      "Training model 1174: (12,65) ...\n",
      "2.1513820529798977\n",
      "Training model 1175: (12,66) ...\n",
      "2.1659795139858034\n",
      "Training model 1176: (12,67) ...\n",
      "2.1509400789800566\n",
      "Training model 1177: (12,68) ...\n",
      "2.1515032479946967\n",
      "Training model 1178: (12,69) ...\n",
      "2.147845530009363\n",
      "Training model 1179: (12,70) ...\n",
      "2.1469005620165262\n",
      "Training model 1180: (12,71) ...\n",
      "2.151163317990722\n",
      "Training model 1181: (12,72) ...\n",
      "2.1495966459915508\n",
      "Training model 1182: (12,73) ...\n",
      "2.152057072991738\n",
      "Training model 1183: (12,74) ...\n",
      "2.154879396985052\n",
      "Training model 1184: (12,75) ...\n",
      "2.3316973829932977\n",
      "Training model 1185: (12,76) ...\n",
      "2.2332000260066707\n",
      "Training model 1186: (12,77) ...\n",
      "2.1610833249869756\n",
      "Training model 1187: (12,78) ...\n",
      "2.1513586869987193\n",
      "Training model 1188: (12,79) ...\n",
      "2.174171814986039\n",
      "Training model 1189: (12,80) ...\n",
      "2.140162469004281\n",
      "Training model 1190: (12,81) ...\n",
      "2.153300041012699\n",
      "Training model 1191: (12,82) ...\n",
      "2.152071350981714\n",
      "Training model 1192: (12,83) ...\n",
      "2.1329426589945797\n",
      "Training model 1193: (12,84) ...\n",
      "2.1569507580134086\n",
      "Training model 1194: (12,85) ...\n",
      "2.1518761180050205\n",
      "Training model 1195: (12,86) ...\n",
      "2.1530345159990247\n",
      "Training model 1196: (12,87) ...\n",
      "2.1456022369966377\n",
      "Training model 1197: (12,88) ...\n",
      "2.155953108012909\n",
      "Training model 1198: (12,89) ...\n",
      "2.147708115982823\n",
      "Training model 1199: (12,90) ...\n",
      "2.1505418060114607\n",
      "Training model 1200: (12,91) ...\n",
      "2.150788930011913\n",
      "Training model 1201: (12,92) ...\n",
      "2.155234070989536\n",
      "Training model 1202: (12,93) ...\n",
      "2.150511657993775\n",
      "Training model 1203: (12,94) ...\n",
      "2.1474661309912335\n",
      "Training model 1204: (12,95) ...\n",
      "2.143147647002479\n",
      "Training model 1205: (12,96) ...\n",
      "2.136109207989648\n",
      "Training model 1206: (12,97) ...\n",
      "2.162144908012124\n",
      "Training model 1207: (12,98) ...\n",
      "2.145967215008568\n",
      "Training model 1208: (12,99) ...\n",
      "2.1552594670210965\n",
      "Training model 1209: (13,14) ...\n",
      "2.152847916993778\n",
      "Training model 1210: (13,15) ...\n",
      "2.1555282969784457\n",
      "Training model 1211: (13,16) ...\n",
      "2.153619904012885\n",
      "Training model 1212: (13,17) ...\n",
      "2.20225145900622\n",
      "Training model 1213: (13,18) ...\n",
      "2.1758813979977276\n",
      "Training model 1214: (13,19) ...\n",
      "2.1555868040013593\n",
      "Training model 1215: (13,20) ...\n",
      "2.1769466760160867\n",
      "Training model 1216: (13,21) ...\n",
      "2.1748012200114317\n",
      "Training model 1217: (13,22) ...\n",
      "2.1852984949946404\n",
      "Training model 1218: (13,23) ...\n",
      "2.1587831809883937\n",
      "Training model 1219: (13,24) ...\n",
      "2.187212154996814\n",
      "Training model 1220: (13,25) ...\n",
      "2.1576919950020965\n",
      "Training model 1221: (13,26) ...\n",
      "2.016227693995461\n",
      "Training model 1222: (13,27) ...\n",
      "2.260947736009257\n",
      "Training model 1223: (13,28) ...\n",
      "2.3238091790117323\n",
      "Training model 1224: (13,29) ...\n",
      "2.208748856006423\n",
      "Training model 1225: (13,30) ...\n",
      "2.125432171014836\n",
      "Training model 1226: (13,31) ...\n",
      "2.201633798016701\n",
      "Training model 1227: (13,32) ...\n",
      "2.1782023379928432\n",
      "Training model 1228: (13,33) ...\n",
      "2.1593461179872975\n",
      "Training model 1229: (13,34) ...\n",
      "2.1380319430027157\n",
      "Training model 1230: (13,35) ...\n",
      "2.164367190998746\n",
      "Training model 1231: (13,36) ...\n",
      "2.2807781789742876\n",
      "Training model 1232: (13,37) ...\n",
      "2.1618836679845117\n",
      "Training model 1233: (13,38) ...\n",
      "2.1692768319917377\n",
      "Training model 1234: (13,39) ...\n",
      "2.182678354001837\n",
      "Training model 1235: (13,40) ...\n",
      "2.2089841440028977\n",
      "Training model 1236: (13,41) ...\n",
      "2.2939627910091076\n",
      "Training model 1237: (13,42) ...\n",
      "2.0510191219800618\n",
      "Training model 1238: (13,43) ...\n",
      "2.115802622982301\n",
      "Training model 1239: (13,44) ...\n",
      "2.1217729519994464\n",
      "Training model 1240: (13,45) ...\n",
      "2.7377873089862987\n",
      "Training model 1241: (13,46) ...\n",
      "2.7910423550056294\n",
      "Training model 1242: (13,47) ...\n",
      "2.157145044999197\n",
      "Training model 1243: (13,48) ...\n",
      "2.1399671790131833\n",
      "Training model 1244: (13,49) ...\n",
      "2.1181361170019954\n",
      "Training model 1245: (13,50) ...\n",
      "2.123117697017733\n",
      "Training model 1246: (13,51) ...\n",
      "2.0854752520099282\n",
      "Training model 1247: (13,52) ...\n",
      "2.119132179999724\n",
      "Training model 1248: (13,53) ...\n",
      "2.1241331060009543\n",
      "Training model 1249: (13,54) ...\n",
      "2.1201330110197887\n",
      "Training model 1250: (13,55) ...\n",
      "2.1189369180065114\n",
      "Training model 1251: (13,56) ...\n",
      "2.0683266329870094\n",
      "Training model 1252: (13,57) ...\n",
      "2.11425511399284\n",
      "Training model 1253: (13,58) ...\n",
      "1.920235298020998\n",
      "Training model 1254: (13,59) ...\n",
      "2.122416925994912\n",
      "Training model 1255: (13,60) ...\n",
      "2.122965110000223\n",
      "Training model 1256: (13,61) ...\n",
      "1.969960505986819\n",
      "Training model 1257: (13,62) ...\n",
      "2.138679459982086\n",
      "Training model 1258: (13,63) ...\n",
      "2.1193347859953064\n",
      "Training model 1259: (13,64) ...\n",
      "2.213389415992424\n",
      "Training model 1260: (13,65) ...\n",
      "2.2224138359888457\n",
      "Training model 1261: (13,66) ...\n",
      "2.1699982110003475\n",
      "Training model 1262: (13,67) ...\n",
      "2.201572097983444\n",
      "Training model 1263: (13,68) ...\n",
      "2.1951900020067114\n",
      "Training model 1264: (13,69) ...\n",
      "2.142509835975943\n",
      "Training model 1265: (13,70) ...\n",
      "2.1043286049971357\n",
      "Training model 1266: (13,71) ...\n",
      "2.1680265290196985\n",
      "Training model 1267: (13,72) ...\n",
      "2.17330931298784\n",
      "Training model 1268: (13,73) ...\n",
      "2.19686509098392\n",
      "Training model 1269: (13,74) ...\n",
      "2.090678887005197\n",
      "Training model 1270: (13,75) ...\n",
      "2.0717228850116953\n",
      "Training model 1271: (13,76) ...\n",
      "2.2379697260039393\n",
      "Training model 1272: (13,77) ...\n",
      "2.258554024010664\n",
      "Training model 1273: (13,78) ...\n",
      "2.1852767759992275\n",
      "Training model 1274: (13,79) ...\n",
      "2.166271032008808\n",
      "Training model 1275: (13,80) ...\n",
      "2.1671957949874923\n",
      "Training model 1276: (13,81) ...\n",
      "2.0200795540004037\n",
      "Training model 1277: (13,82) ...\n",
      "2.2373853950120974\n",
      "Training model 1278: (13,83) ...\n",
      "2.2142100729979575\n",
      "Training model 1279: (13,84) ...\n",
      "2.2010444949846715\n",
      "Training model 1280: (13,85) ...\n",
      "2.1900955329765566\n",
      "Training model 1281: (13,86) ...\n",
      "2.1868722350045573\n",
      "Training model 1282: (13,87) ...\n",
      "2.2667771100241225\n",
      "Training model 1283: (13,88) ...\n",
      "2.142195326014189\n",
      "Training model 1284: (13,89) ...\n",
      "2.1628588890016545\n",
      "Training model 1285: (13,90) ...\n",
      "2.0046059000014793\n",
      "Training model 1286: (13,91) ...\n",
      "2.2079774949816056\n",
      "Training model 1287: (13,92) ...\n",
      "2.2084325489995535\n",
      "Training model 1288: (13,93) ...\n",
      "2.1934278029948473\n",
      "Training model 1289: (13,94) ...\n",
      "2.1809032519813627\n",
      "Training model 1290: (13,95) ...\n",
      "2.1785587060148828\n",
      "Training model 1291: (13,96) ...\n",
      "2.1825729190022685\n",
      "Training model 1292: (13,97) ...\n",
      "2.174637296004221\n",
      "Training model 1293: (13,98) ...\n",
      "2.1772120370005723\n",
      "Training model 1294: (13,99) ...\n",
      "2.1816990149964113\n",
      "Training model 1295: (14,15) ...\n",
      "2.165856462001102\n",
      "Training model 1296: (14,16) ...\n",
      "2.0676530940108933\n",
      "Training model 1297: (14,17) ...\n",
      "2.2319362190028187\n",
      "Training model 1298: (14,18) ...\n",
      "2.198016356996959\n",
      "Training model 1299: (14,19) ...\n",
      "2.1851759839919396\n",
      "Training model 1300: (14,20) ...\n",
      "2.177603532996727\n",
      "Training model 1301: (14,21) ...\n",
      "2.1776252249837853\n",
      "Training model 1302: (14,22) ...\n",
      "2.1575053830165416\n",
      "Training model 1303: (14,23) ...\n",
      "2.177293358981842\n",
      "Training model 1304: (14,24) ...\n",
      "2.187502588989446\n",
      "Training model 1305: (14,25) ...\n",
      "1.9808887950202916\n",
      "Training model 1306: (14,26) ...\n",
      "2.1959396119927987\n",
      "Training model 1307: (14,27) ...\n",
      "2.224719609017484\n",
      "Training model 1308: (14,28) ...\n",
      "2.2526342129858676\n",
      "Training model 1309: (14,29) ...\n",
      "2.1848938290204387\n",
      "Training model 1310: (14,30) ...\n",
      "2.183370582992211\n",
      "Training model 1311: (14,31) ...\n",
      "2.1924982969940174\n",
      "Training model 1312: (14,32) ...\n",
      "2.1987049269955605\n",
      "Training model 1313: (14,33) ...\n",
      "2.176454913977068\n",
      "Training model 1314: (14,34) ...\n",
      "2.1828274140134454\n",
      "Training model 1315: (14,35) ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1463935729989316\n",
      "Training model 1316: (14,36) ...\n",
      "1.9812218170263804\n",
      "Training model 1317: (14,37) ...\n",
      "2.189056028990308\n",
      "Training model 1318: (14,38) ...\n",
      "2.225873255985789\n",
      "Training model 1319: (14,39) ...\n",
      "2.1968962989922147\n",
      "Training model 1320: (14,40) ...\n",
      "2.193232732999604\n",
      "Training model 1321: (14,41) ...\n",
      "2.0011320849880576\n",
      "Training model 1322: (14,42) ...\n",
      "2.1932756129826885\n",
      "Training model 1323: (14,43) ...\n",
      "2.55899491297896\n",
      "Training model 1324: (14,44) ...\n",
      "3.0340823190053925\n",
      "Training model 1325: (14,45) ...\n",
      "2.1379336430109106\n",
      "Training model 1326: (14,46) ...\n",
      "2.1401025719824247\n",
      "Training model 1327: (14,47) ...\n",
      "1.9888894739851821\n",
      "Training model 1328: (14,48) ...\n",
      "2.1449155769951176\n",
      "Training model 1329: (14,49) ...\n",
      "2.1394520080066286\n",
      "Training model 1330: (14,50) ...\n",
      "2.1392877229955047\n",
      "Training model 1331: (14,51) ...\n",
      "2.143240628996864\n",
      "Training model 1332: (14,52) ...\n",
      "2.1578737880045082\n",
      "Training model 1333: (14,53) ...\n",
      "2.1394130009866785\n",
      "Training model 1334: (14,54) ...\n",
      "2.1379487219965085\n",
      "Training model 1335: (14,55) ...\n",
      "2.142308969021542\n",
      "Training model 1336: (14,56) ...\n",
      "2.13904112498858\n",
      "Training model 1337: (14,57) ...\n",
      "2.2275230730010662\n",
      "Training model 1338: (14,58) ...\n",
      "2.1372968110081274\n",
      "Training model 1339: (14,59) ...\n",
      "2.1463522700069007\n",
      "Training model 1340: (14,60) ...\n",
      "2.1376339650014415\n",
      "Training model 1341: (14,61) ...\n",
      "2.149787460017251\n",
      "Training model 1342: (14,62) ...\n",
      "2.1391907420183998\n",
      "Training model 1343: (14,63) ...\n",
      "1.9572989100124687\n",
      "Training model 1344: (14,64) ...\n",
      "2.12214922500425\n",
      "Training model 1345: (14,65) ...\n",
      "2.139661132998299\n",
      "Training model 1346: (14,66) ...\n",
      "2.1409893829841167\n",
      "Training model 1347: (14,67) ...\n",
      "2.1429140619875398\n",
      "Training model 1348: (14,68) ...\n",
      "2.136943692981731\n",
      "Training model 1349: (14,69) ...\n",
      "2.175604645977728\n",
      "Training model 1350: (14,70) ...\n",
      "2.1838769809983205\n",
      "Training model 1351: (14,71) ...\n",
      "2.2074151799897663\n",
      "Training model 1352: (14,72) ...\n",
      "2.0198993110097945\n",
      "Training model 1353: (14,73) ...\n",
      "2.2550336249987595\n",
      "Training model 1354: (14,74) ...\n",
      "2.2114583720103838\n",
      "Training model 1355: (14,75) ...\n",
      "2.2338795179966837\n",
      "Training model 1356: (14,76) ...\n",
      "2.1413911749841645\n",
      "Training model 1357: (14,77) ...\n",
      "2.3123865840025246\n",
      "Training model 1358: (14,78) ...\n",
      "2.207382227992639\n",
      "Training model 1359: (14,79) ...\n",
      "2.1745841999945696\n",
      "Training model 1360: (14,80) ...\n",
      "2.144748343009269\n",
      "Training model 1361: (14,81) ...\n",
      "2.132736752013443\n",
      "Training model 1362: (14,82) ...\n",
      "2.14639139699284\n",
      "Training model 1363: (14,83) ...\n",
      "2.125355969008524\n",
      "Training model 1364: (14,84) ...\n",
      "2.2067503259750083\n",
      "Training model 1365: (14,85) ...\n",
      "2.112985399988247\n",
      "Training model 1366: (14,86) ...\n",
      "2.1275865609932225\n",
      "Training model 1367: (14,87) ...\n",
      "2.1525434700015467\n",
      "Training model 1368: (14,88) ...\n",
      "2.0116267430130392\n",
      "Training model 1369: (14,89) ...\n",
      "2.164963771996554\n",
      "Training model 1370: (14,90) ...\n",
      "2.161154797009658\n",
      "Training model 1371: (14,91) ...\n",
      "2.1505667719757184\n",
      "Training model 1372: (14,92) ...\n",
      "2.1618073110003024\n",
      "Training model 1373: (14,93) ...\n",
      "2.1469449790020008\n",
      "Training model 1374: (14,94) ...\n",
      "2.13383876500302\n",
      "Training model 1375: (14,95) ...\n",
      "2.1174571760057006\n",
      "Training model 1376: (14,96) ...\n",
      "2.116462345002219\n",
      "Training model 1377: (14,97) ...\n",
      "2.1105617380235344\n",
      "Training model 1378: (14,98) ...\n",
      "2.1234676110034343\n",
      "Training model 1379: (14,99) ...\n",
      "2.1118773100024555\n",
      "Training model 1380: (15,16) ...\n",
      "1.81078237699694\n",
      "Training model 1381: (15,17) ...\n",
      "2.1423221250006463\n",
      "Training model 1382: (15,18) ...\n",
      "2.092015881993575\n",
      "Training model 1383: (15,19) ...\n",
      "2.1337557020015083\n",
      "Training model 1384: (15,20) ...\n",
      "2.1117562200233806\n",
      "Training model 1385: (15,21) ...\n",
      "2.1145762779924553\n",
      "Training model 1386: (15,22) ...\n",
      "2.1062956390087493\n",
      "Training model 1387: (15,23) ...\n",
      "2.1307384370011277\n",
      "Training model 1388: (15,24) ...\n",
      "2.1322057269862853\n",
      "Training model 1389: (15,25) ...\n",
      "2.1215500260004774\n",
      "Training model 1390: (15,26) ...\n",
      "2.1165767190104816\n",
      "Training model 1391: (15,27) ...\n",
      "2.112492708984064\n",
      "Training model 1392: (15,28) ...\n",
      "2.1127444499870762\n",
      "Training model 1393: (15,29) ...\n",
      "2.1687839909864124\n",
      "Training model 1394: (15,30) ...\n",
      "2.1132703390030656\n",
      "Training model 1395: (15,31) ...\n",
      "2.1172241030144505\n",
      "Training model 1396: (15,32) ...\n",
      "2.1243351089942735\n",
      "Training model 1397: (15,33) ...\n",
      "2.0693618220102508\n",
      "Training model 1398: (15,34) ...\n",
      "2.132215397024993\n",
      "Training model 1399: (15,35) ...\n",
      "2.1434437689895276\n",
      "Training model 1400: (15,36) ...\n",
      "2.1417047509748954\n",
      "Training model 1401: (15,37) ...\n",
      "2.114584933995502\n",
      "Training model 1402: (15,38) ...\n",
      "2.072908187023131\n",
      "Training model 1403: (15,39) ...\n",
      "2.1440868390200194\n",
      "Training model 1404: (15,40) ...\n",
      "2.1656560550036374\n",
      "Training model 1405: (15,41) ...\n",
      "2.17503016901901\n",
      "Training model 1406: (15,42) ...\n",
      "2.208489372016629\n",
      "Training model 1407: (15,43) ...\n",
      "2.4897103889961727\n",
      "Training model 1408: (15,44) ...\n",
      "2.9535928620025516\n",
      "Training model 1409: (15,45) ...\n",
      "2.319632081023883\n",
      "Training model 1410: (15,46) ...\n",
      "2.291727264993824\n",
      "Training model 1411: (15,47) ...\n",
      "2.186183647980215\n",
      "Training model 1412: (15,48) ...\n",
      "2.2255267669970635\n",
      "Training model 1413: (15,49) ...\n",
      "2.2268609299790114\n",
      "Training model 1414: (15,50) ...\n",
      "1.985334957978921\n",
      "Training model 1415: (15,51) ...\n",
      "2.2762318729946855\n",
      "Training model 1416: (15,52) ...\n",
      "2.3290222869836725\n",
      "Training model 1417: (15,53) ...\n",
      "2.140057462005643\n",
      "Training model 1418: (15,54) ...\n",
      "2.1441289559879806\n",
      "Training model 1419: (15,55) ...\n",
      "2.1444405949732754\n",
      "Training model 1420: (15,56) ...\n",
      "2.100393272994552\n",
      "Training model 1421: (15,57) ...\n",
      "2.143697147985222\n",
      "Training model 1422: (15,58) ...\n",
      "2.148325100017246\n",
      "Training model 1423: (15,59) ...\n",
      "2.146994253998855\n",
      "Training model 1424: (15,60) ...\n",
      "2.1361255499941763\n",
      "Training model 1425: (15,61) ...\n",
      "2.1375820339890197\n",
      "Training model 1426: (15,62) ...\n",
      "2.1376280219992623\n",
      "Training model 1427: (15,63) ...\n",
      "2.1371533980127424\n",
      "Training model 1428: (15,64) ...\n",
      "2.129792357009137\n",
      "Training model 1429: (15,65) ...\n",
      "2.083416825014865\n",
      "Training model 1430: (15,66) ...\n",
      "2.1355869740073103\n",
      "Training model 1431: (15,67) ...\n",
      "2.1088814190006815\n",
      "Training model 1432: (15,68) ...\n",
      "2.133342282992089\n",
      "Training model 1433: (15,69) ...\n",
      "2.136142622999614\n",
      "Training model 1434: (15,70) ...\n",
      "2.031118612008868\n",
      "Training model 1435: (15,71) ...\n",
      "1.9648502559866756\n",
      "Training model 1436: (15,72) ...\n",
      "1.9858208799851127\n",
      "Training model 1437: (15,73) ...\n",
      "2.20991585199954\n",
      "Training model 1438: (15,74) ...\n",
      "2.12958894399344\n",
      "Training model 1439: (15,75) ...\n",
      "2.199727236002218\n",
      "Training model 1440: (15,76) ...\n",
      "2.1693910120229702\n",
      "Training model 1441: (15,77) ...\n",
      "2.3054602300107945\n",
      "Training model 1442: (15,78) ...\n",
      "2.13976423398708\n",
      "Training model 1443: (15,79) ...\n",
      "2.139319442998385\n",
      "Training model 1444: (15,80) ...\n",
      "2.1600716969987843\n",
      "Training model 1445: (15,81) ...\n",
      "2.133189725020202\n",
      "Training model 1446: (15,82) ...\n",
      "2.140453353000339\n",
      "Training model 1447: (15,83) ...\n",
      "2.138457335997373\n",
      "Training model 1448: (15,84) ...\n",
      "2.1764524769969285\n",
      "Training model 1449: (15,85) ...\n",
      "2.141711659991415\n",
      "Training model 1450: (15,86) ...\n",
      "2.1401570699817967\n",
      "Training model 1451: (15,87) ...\n",
      "2.1517404100159183\n",
      "Training model 1452: (15,88) ...\n",
      "2.1394644280080684\n",
      "Training model 1453: (15,89) ...\n",
      "2.1667699499812443\n",
      "Training model 1454: (15,90) ...\n",
      "2.1434812160150614\n",
      "Training model 1455: (15,91) ...\n",
      "2.142137435992481\n",
      "Training model 1456: (15,92) ...\n",
      "2.14582155100652\n",
      "Training model 1457: (15,93) ...\n",
      "2.1534559809952043\n",
      "Training model 1458: (15,94) ...\n",
      "2.117581128986785\n",
      "Training model 1459: (15,95) ...\n",
      "2.177116548002232\n",
      "Training model 1460: (15,96) ...\n",
      "2.1715469410119113\n",
      "Training model 1461: (15,97) ...\n",
      "2.1668156959931366\n",
      "Training model 1462: (15,98) ...\n",
      "2.196793593990151\n",
      "Training model 1463: (15,99) ...\n",
      "2.171786916005658\n",
      "Training model 1464: (16,17) ...\n",
      "2.1585390039836057\n",
      "Training model 1465: (16,18) ...\n",
      "2.179633924009977\n",
      "Training model 1466: (16,19) ...\n",
      "2.024548343004426\n",
      "Training model 1467: (16,20) ...\n",
      "2.2029279179987498\n",
      "Training model 1468: (16,21) ...\n",
      "2.2391571800108068\n",
      "Training model 1469: (16,22) ...\n",
      "2.1894128450076096\n",
      "Training model 1470: (16,23) ...\n",
      "2.1953192240034696\n",
      "Training model 1471: (16,24) ...\n",
      "2.151941632007947\n",
      "Training model 1472: (16,25) ...\n",
      "2.179780702019343\n",
      "Training model 1473: (16,26) ...\n",
      "2.1296576960012317\n",
      "Training model 1474: (16,27) ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.028747468983056\n",
      "Training model 1475: (16,28) ...\n",
      "2.1403604979859665\n",
      "Training model 1476: (16,29) ...\n",
      "2.224660687992582\n",
      "Training model 1477: (16,30) ...\n",
      "2.2169440599973314\n",
      "Training model 1478: (16,31) ...\n",
      "2.3284565710055176\n",
      "Training model 1479: (16,32) ...\n",
      "2.186337466002442\n",
      "Training model 1480: (16,33) ...\n",
      "2.194722804997582\n",
      "Training model 1481: (16,34) ...\n",
      "2.1691448880010284\n",
      "Training model 1482: (16,35) ...\n",
      "2.1665034200123046\n",
      "Training model 1483: (16,36) ...\n",
      "2.185879083990585\n",
      "Training model 1484: (16,37) ...\n",
      "2.171383462002268\n",
      "Training model 1485: (16,38) ...\n",
      "2.1691327349981293\n",
      "Training model 1486: (16,39) ...\n",
      "2.175415511999745\n",
      "Training model 1487: (16,40) ...\n",
      "2.176719757000683\n",
      "Training model 1488: (16,41) ...\n",
      "2.125096088013379\n",
      "Training model 1489: (16,42) ...\n",
      "2.249628933001077\n",
      "Training model 1490: (16,43) ...\n",
      "2.753099794994341\n",
      "Training model 1491: (16,44) ...\n",
      "2.384080988005735\n",
      "Training model 1492: (16,45) ...\n",
      "2.2194804580067284\n",
      "Training model 1493: (16,46) ...\n",
      "2.22923041600734\n",
      "Training model 1494: (16,47) ...\n",
      "2.135541639989242\n",
      "Training model 1495: (16,48) ...\n",
      "2.1938575219828635\n",
      "Training model 1496: (16,49) ...\n",
      "2.0935727109899744\n",
      "Training model 1497: (16,50) ...\n",
      "1.9479738800146151\n",
      "Training model 1498: (16,51) ...\n",
      "2.135403456981294\n",
      "Training model 1499: (16,52) ...\n",
      "2.112498130998574\n",
      "Training model 1500: (16,53) ...\n",
      "2.1374013460008428\n",
      "Training model 1501: (16,54) ...\n",
      "2.1195154869928956\n",
      "Training model 1502: (16,55) ...\n",
      "2.135146423999686\n",
      "Training model 1503: (16,56) ...\n",
      "2.1541164930094965\n",
      "Training model 1504: (16,57) ...\n",
      "2.1331552939955145\n",
      "Training model 1505: (16,58) ...\n",
      "2.185724825016223\n",
      "Training model 1506: (16,59) ...\n",
      "2.135062076995382\n",
      "Training model 1507: (16,60) ...\n",
      "2.1431521170015913\n",
      "Training model 1508: (16,61) ...\n",
      "2.1366322560061235\n",
      "Training model 1509: (16,62) ...\n",
      "2.081937338982243\n",
      "Training model 1510: (16,63) ...\n",
      "2.103579301998252\n",
      "Training model 1511: (16,64) ...\n",
      "2.1398704510065727\n",
      "Training model 1512: (16,65) ...\n",
      "2.1579975729982834\n",
      "Training model 1513: (16,66) ...\n",
      "2.2999253789894283\n",
      "Training model 1514: (16,67) ...\n",
      "2.1625383889768273\n",
      "Training model 1515: (16,68) ...\n",
      "2.136166709999088\n",
      "Training model 1516: (16,69) ...\n",
      "2.0510618280095514\n",
      "Training model 1517: (16,70) ...\n",
      "2.1849730459798593\n",
      "Training model 1518: (16,71) ...\n",
      "2.208461813017493\n",
      "Training model 1519: (16,72) ...\n",
      "2.1594125849951524\n",
      "Training model 1520: (16,73) ...\n",
      "2.159784994000802\n",
      "Training model 1521: (16,74) ...\n",
      "2.1683512379822787\n",
      "Training model 1522: (16,75) ...\n",
      "2.1826822540024295\n",
      "Training model 1523: (16,76) ...\n",
      "2.194026421988383\n",
      "Training model 1524: (16,77) ...\n",
      "2.1681330960127525\n",
      "Training model 1525: (16,78) ...\n",
      "2.236748630995862\n",
      "Training model 1526: (16,79) ...\n",
      "2.1411062330007553\n",
      "Training model 1527: (16,80) ...\n",
      "2.158145299006719\n",
      "Training model 1528: (16,81) ...\n",
      "2.1245245030149817\n",
      "Training model 1529: (16,82) ...\n",
      "2.1688563500065356\n",
      "Training model 1530: (16,83) ...\n",
      "2.1695696740061976\n",
      "Training model 1531: (16,84) ...\n",
      "2.180731749976985\n",
      "Training model 1532: (16,85) ...\n",
      "2.1829908520157915\n",
      "Training model 1533: (16,86) ...\n",
      "2.1688498760049697\n",
      "Training model 1534: (16,87) ...\n",
      "2.190003752009943\n",
      "Training model 1535: (16,88) ...\n",
      "2.1718326279951725\n",
      "Training model 1536: (16,89) ...\n",
      "2.1973026740015484\n",
      "Training model 1537: (16,90) ...\n",
      "2.1794709080131724\n",
      "Training model 1538: (16,91) ...\n",
      "2.1772117070213426\n",
      "Training model 1539: (16,92) ...\n",
      "2.155579582991777\n",
      "Training model 1540: (16,93) ...\n",
      "2.207175041985465\n",
      "Training model 1541: (16,94) ...\n",
      "2.1574599989980925\n",
      "Training model 1542: (16,95) ...\n",
      "2.1668422520160675\n",
      "Training model 1543: (16,96) ...\n",
      "2.1839829509845003\n",
      "Training model 1544: (16,97) ...\n",
      "2.1621425960038323\n",
      "Training model 1545: (16,98) ...\n",
      "2.208618791977642\n",
      "Training model 1546: (16,99) ...\n",
      "2.1503208490030374\n",
      "Training model 1547: (17,18) ...\n",
      "2.164577796997037\n",
      "Training model 1548: (17,19) ...\n",
      "2.164838261989644\n",
      "Training model 1549: (17,20) ...\n",
      "2.1689420949842315\n",
      "Training model 1550: (17,21) ...\n",
      "2.163812249986222\n",
      "Training model 1551: (17,22) ...\n",
      "2.1746192640275694\n",
      "Training model 1552: (17,23) ...\n",
      "2.2925175550044514\n",
      "Training model 1553: (17,24) ...\n",
      "2.1440139149781317\n",
      "Training model 1554: (17,25) ...\n",
      "2.1791923150012735\n",
      "Training model 1555: (17,26) ...\n",
      "2.1556729989824817\n",
      "Training model 1556: (17,27) ...\n",
      "2.1491685090004466\n",
      "Training model 1557: (17,28) ...\n",
      "2.16618182399543\n",
      "Training model 1558: (17,29) ...\n",
      "2.1655086829850916\n",
      "Training model 1559: (17,30) ...\n",
      "2.223507589980727\n",
      "Training model 1560: (17,31) ...\n",
      "2.324301184009528\n",
      "Training model 1561: (17,32) ...\n",
      "2.178849326999625\n",
      "Training model 1562: (17,33) ...\n",
      "2.2300416530051734\n",
      "Training model 1563: (17,34) ...\n",
      "2.230782938975608\n",
      "Training model 1564: (17,35) ...\n",
      "2.167335534002632\n",
      "Training model 1565: (17,36) ...\n",
      "2.2821722039952874\n",
      "Training model 1566: (17,37) ...\n",
      "2.1655882720078807\n",
      "Training model 1567: (17,38) ...\n",
      "2.3073500799946487\n",
      "Training model 1568: (17,39) ...\n",
      "1.9984180280007422\n",
      "Training model 1569: (17,40) ...\n",
      "2.1587510970130097\n",
      "Training model 1570: (17,41) ...\n",
      "2.141352138016373\n",
      "Training model 1571: (17,42) ...\n",
      "2.167803633987205\n",
      "Training model 1572: (17,43) ...\n",
      "2.5444521559984423\n",
      "Training model 1573: (17,44) ...\n",
      "2.9313301280199084\n",
      "Training model 1574: (17,45) ...\n",
      "2.3114312529796734\n",
      "Training model 1575: (17,46) ...\n",
      "2.136761128989747\n",
      "Training model 1576: (17,47) ...\n",
      "2.1382514179858845\n",
      "Training model 1577: (17,48) ...\n",
      "2.1402496969967615\n",
      "Training model 1578: (17,49) ...\n",
      "2.1443153959990013\n",
      "Training model 1579: (17,50) ...\n",
      "2.1441909759887494\n",
      "Training model 1580: (17,51) ...\n",
      "2.156572716019582\n",
      "Training model 1581: (17,52) ...\n",
      "1.9903312340029515\n",
      "Training model 1582: (17,53) ...\n",
      "2.1431818249984644\n",
      "Training model 1583: (17,54) ...\n",
      "2.1408796939940657\n",
      "Training model 1584: (17,55) ...\n",
      "2.1266829530068208\n",
      "Training model 1585: (17,56) ...\n",
      "2.1413571260054596\n",
      "Training model 1586: (17,57) ...\n",
      "2.142476471984992\n",
      "Training model 1587: (17,58) ...\n",
      "2.143165728979511\n",
      "Training model 1588: (17,59) ...\n",
      "1.6859941769798752\n",
      "Training model 1589: (17,60) ...\n",
      "2.148157532996265\n",
      "Training model 1590: (17,61) ...\n",
      "2.145851919980487\n",
      "Training model 1591: (17,62) ...\n",
      "2.1458682480151765\n",
      "Training model 1592: (17,63) ...\n",
      "2.1395185709989164\n",
      "Training model 1593: (17,64) ...\n",
      "2.146325663983589\n",
      "Training model 1594: (17,65) ...\n",
      "2.135638467996614\n",
      "Training model 1595: (17,66) ...\n",
      "2.13879152800655\n",
      "Training model 1596: (17,67) ...\n",
      "2.136873245006427\n",
      "Training model 1597: (17,68) ...\n",
      "2.138143157993909\n",
      "Training model 1598: (17,69) ...\n",
      "2.137415017001331\n",
      "Training model 1599: (17,70) ...\n",
      "2.1356697830196936\n",
      "Training model 1600: (17,71) ...\n",
      "2.1357888109923806\n",
      "Training model 1601: (17,72) ...\n",
      "2.1372146909998264\n",
      "Training model 1602: (17,73) ...\n",
      "2.138066104002064\n",
      "Training model 1603: (17,74) ...\n",
      "2.1017766740114894\n",
      "Training model 1604: (17,75) ...\n",
      "2.0076472840155475\n",
      "Training model 1605: (17,76) ...\n",
      "2.2219484959787223\n",
      "Training model 1606: (17,77) ...\n",
      "2.274611492990516\n",
      "Training model 1607: (17,78) ...\n",
      "2.157089251006255\n",
      "Training model 1608: (17,79) ...\n",
      "2.186825131997466\n",
      "Training model 1609: (17,80) ...\n",
      "2.168473844998516\n",
      "Training model 1610: (17,81) ...\n",
      "2.194079448003322\n",
      "Training model 1611: (17,82) ...\n",
      "2.1706090410007164\n",
      "Training model 1612: (17,83) ...\n",
      "2.1857902969932184\n",
      "Training model 1613: (17,84) ...\n",
      "2.191613665985642\n",
      "Training model 1614: (17,85) ...\n",
      "2.2502386580163147\n",
      "Training model 1615: (17,86) ...\n",
      "2.1665894449979533\n",
      "Training model 1616: (17,87) ...\n",
      "2.1557363370084204\n",
      "Training model 1617: (17,88) ...\n",
      "2.150790029001655\n",
      "Training model 1618: (17,89) ...\n",
      "2.1472461670055054\n",
      "Training model 1619: (17,90) ...\n",
      "2.1494268359965645\n",
      "Training model 1620: (17,91) ...\n",
      "2.01356399100041\n",
      "Training model 1621: (17,92) ...\n",
      "2.0780626769992523\n",
      "Training model 1622: (17,93) ...\n",
      "2.2972667989961337\n",
      "Training model 1623: (17,94) ...\n",
      "2.2412454779841937\n",
      "Training model 1624: (17,95) ...\n",
      "2.225182121997932\n",
      "Training model 1625: (17,96) ...\n",
      "2.17302421698696\n",
      "Training model 1626: (17,97) ...\n",
      "2.162378451990662\n",
      "Training model 1627: (17,98) ...\n",
      "2.170788404997438\n",
      "Training model 1628: (17,99) ...\n",
      "2.0800234509806614\n",
      "Training model 1629: (18,19) ...\n",
      "2.254247517004842\n",
      "Training model 1630: (18,20) ...\n",
      "2.2032955100003164\n",
      "Training model 1631: (18,21) ...\n",
      "2.0022491220152006\n",
      "Training model 1632: (18,22) ...\n",
      "2.197001723019639\n",
      "Training model 1633: (18,23) ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.20505582500482\n",
      "Training model 1634: (18,24) ...\n",
      "2.061851829988882\n",
      "Training model 1635: (18,25) ...\n",
      "2.200738282990642\n",
      "Training model 1636: (18,26) ...\n",
      "2.166549613000825\n",
      "Training model 1637: (18,27) ...\n",
      "2.188554952008417\n",
      "Training model 1638: (18,28) ...\n",
      "2.1751136030070484\n",
      "Training model 1639: (18,29) ...\n",
      "2.209686659014551\n",
      "Training model 1640: (18,30) ...\n",
      "2.1712563220062293\n",
      "Training model 1641: (18,31) ...\n",
      "2.2204448049888015\n",
      "Training model 1642: (18,32) ...\n",
      "2.2266822770179715\n",
      "Training model 1643: (18,33) ...\n",
      "2.2236240050115157\n",
      "Training model 1644: (18,34) ...\n",
      "2.26291871900321\n",
      "Training model 1645: (18,35) ...\n",
      "2.1766070480225608\n",
      "Training model 1646: (18,36) ...\n",
      "2.198401539993938\n",
      "Training model 1647: (18,37) ...\n",
      "2.1867749159864616\n",
      "Training model 1648: (18,38) ...\n",
      "2.316472898994107\n",
      "Training model 1649: (18,39) ...\n",
      "2.1785611730010714\n",
      "Training model 1650: (18,40) ...\n",
      "2.235601874999702\n",
      "Training model 1651: (18,41) ...\n",
      "2.2583734339859802\n",
      "Training model 1652: (18,42) ...\n",
      "2.152390211005695\n",
      "Training model 1653: (18,43) ...\n",
      "2.038118828990264\n",
      "Training model 1654: (18,44) ...\n",
      "2.266888571000891\n",
      "Training model 1655: (18,45) ...\n",
      "2.3606582840147894\n",
      "Training model 1656: (18,46) ...\n",
      "2.7930985240091104\n",
      "Training model 1657: (18,47) ...\n",
      "2.1344353790045716\n",
      "Training model 1658: (18,48) ...\n",
      "2.2577765400055796\n",
      "Training model 1659: (18,49) ...\n",
      "2.121049411012791\n",
      "Training model 1660: (18,50) ...\n",
      "2.1152689879818354\n",
      "Training model 1661: (18,51) ...\n",
      "2.1193473629828077\n",
      "Training model 1662: (18,52) ...\n",
      "2.1148559369903523\n",
      "Training model 1663: (18,53) ...\n",
      "2.1224901730020065\n",
      "Training model 1664: (18,54) ...\n",
      "2.1291289970104117\n",
      "Training model 1665: (18,55) ...\n",
      "2.090166893991409\n",
      "Training model 1666: (18,56) ...\n",
      "2.117373122018762\n",
      "Training model 1667: (18,57) ...\n",
      "2.1158560600015335\n",
      "Training model 1668: (18,58) ...\n",
      "1.933178213017527\n",
      "Training model 1669: (18,59) ...\n",
      "2.1390309460111894\n",
      "Training model 1670: (18,60) ...\n",
      "2.103971853008261\n",
      "Training model 1671: (18,61) ...\n",
      "2.117277354991529\n",
      "Training model 1672: (18,62) ...\n",
      "2.0744298920035362\n",
      "Training model 1673: (18,63) ...\n",
      "2.1361455490114167\n",
      "Training model 1674: (18,64) ...\n",
      "2.1234653959982097\n",
      "Training model 1675: (18,65) ...\n",
      "2.1211462850042153\n",
      "Training model 1676: (18,66) ...\n",
      "2.1471361290023196\n",
      "Training model 1677: (18,67) ...\n",
      "2.1404496989853214\n",
      "Training model 1678: (18,68) ...\n",
      "2.1661382089951076\n",
      "Training model 1679: (18,69) ...\n",
      "2.1637087340059225\n",
      "Training model 1680: (18,70) ...\n",
      "2.180031575000612\n",
      "Training model 1681: (18,71) ...\n",
      "2.179337753012078\n",
      "Training model 1682: (18,72) ...\n",
      "2.1673444930056576\n",
      "Training model 1683: (18,73) ...\n",
      "2.3324307289731223\n",
      "Training model 1684: (18,74) ...\n",
      "2.0870492509857286\n",
      "Training model 1685: (18,75) ...\n",
      "2.150165476021357\n",
      "Training model 1686: (18,76) ...\n",
      "2.116861276997952\n",
      "Training model 1687: (18,77) ...\n",
      "2.2515209639968816\n",
      "Training model 1688: (18,78) ...\n",
      "2.21567093997146\n",
      "Training model 1689: (18,79) ...\n",
      "2.2074897499987856\n",
      "Training model 1690: (18,80) ...\n",
      "2.041352130996529\n",
      "Training model 1691: (18,81) ...\n",
      "2.182187677011825\n",
      "Training model 1692: (18,82) ...\n",
      "2.1280078679847065\n",
      "Training model 1693: (18,83) ...\n",
      "2.197704087011516\n",
      "Training model 1694: (18,84) ...\n",
      "2.051176734996261\n",
      "Training model 1695: (18,85) ...\n",
      "2.236114868981531\n",
      "Training model 1696: (18,86) ...\n",
      "2.188877994020004\n",
      "Training model 1697: (18,87) ...\n",
      "2.214806800999213\n",
      "Training model 1698: (18,88) ...\n",
      "2.0355407999886665\n",
      "Training model 1699: (18,89) ...\n",
      "2.169186646002345\n",
      "Training model 1700: (18,90) ...\n",
      "2.256565090006916\n",
      "Training model 1701: (18,91) ...\n",
      "2.223926555016078\n",
      "Training model 1702: (18,92) ...\n",
      "2.1638376860064454\n",
      "Training model 1703: (18,93) ...\n",
      "2.188648231996922\n",
      "Training model 1704: (18,94) ...\n",
      "2.1483137370087206\n",
      "Training model 1705: (18,95) ...\n",
      "2.1982329720049165\n",
      "Training model 1706: (18,96) ...\n",
      "2.1664934389991686\n",
      "Training model 1707: (18,97) ...\n",
      "2.187838566984283\n",
      "Training model 1708: (18,98) ...\n",
      "2.16908478399273\n",
      "Training model 1709: (18,99) ...\n",
      "2.180416102986783\n",
      "Training model 1710: (19,20) ...\n",
      "2.179903058015043\n",
      "Training model 1711: (19,21) ...\n",
      "2.1753287659958005\n",
      "Training model 1712: (19,22) ...\n",
      "2.172667086997535\n",
      "Training model 1713: (19,23) ...\n",
      "2.1708143170108087\n",
      "Training model 1714: (19,24) ...\n",
      "2.232671545003541\n",
      "Training model 1715: (19,25) ...\n",
      "2.1279770969995297\n",
      "Training model 1716: (19,26) ...\n",
      "2.112604315014323\n",
      "Training model 1717: (19,27) ...\n",
      "2.1783043820178136\n",
      "Training model 1718: (19,28) ...\n",
      "2.194074416998774\n",
      "Training model 1719: (19,29) ...\n",
      "2.1756389329966623\n",
      "Training model 1720: (19,30) ...\n",
      "2.166927302023396\n",
      "Training model 1721: (19,31) ...\n",
      "2.1670608230051585\n",
      "Training model 1722: (19,32) ...\n",
      "2.182430065004155\n",
      "Training model 1723: (19,33) ...\n",
      "2.1831325289967936\n",
      "Training model 1724: (19,34) ...\n",
      "2.2734714060206898\n",
      "Training model 1725: (19,35) ...\n",
      "2.001515933981864\n",
      "Training model 1726: (19,36) ...\n",
      "2.28970685400418\n",
      "Training model 1727: (19,37) ...\n",
      "2.208659661002457\n",
      "Training model 1728: (19,38) ...\n",
      "2.1655229720054194\n",
      "Training model 1729: (19,39) ...\n",
      "2.189802000008058\n",
      "Training model 1730: (19,40) ...\n",
      "2.176695861009648\n",
      "Training model 1731: (19,41) ...\n",
      "2.167042960994877\n",
      "Training model 1732: (19,42) ...\n",
      "2.153451688005589\n",
      "Training model 1733: (19,43) ...\n",
      "2.158086301002186\n",
      "Training model 1734: (19,44) ...\n",
      "2.1037522590195294\n",
      "Training model 1735: (19,45) ...\n",
      "2.133594262995757\n",
      "Training model 1736: (19,46) ...\n",
      "2.2288971670204774\n",
      "Training model 1737: (19,47) ...\n",
      "2.1970289519813377\n",
      "Training model 1738: (19,48) ...\n",
      "2.1193399710173253\n",
      "Training model 1739: (19,49) ...\n",
      "2.756865549017675\n",
      "Training model 1740: (19,50) ...\n",
      "2.139545426995028\n",
      "Training model 1741: (19,51) ...\n",
      "2.1405353090085555\n",
      "Training model 1742: (19,52) ...\n",
      "2.1437354119843803\n",
      "Training model 1743: (19,53) ...\n",
      "2.1337755490094423\n",
      "Training model 1744: (19,54) ...\n",
      "2.1412744550034404\n",
      "Training model 1745: (19,55) ...\n",
      "2.1374072849866934\n",
      "Training model 1746: (19,56) ...\n",
      "1.9960135169967543\n",
      "Training model 1747: (19,57) ...\n",
      "2.134491225006059\n",
      "Training model 1748: (19,58) ...\n",
      "2.0910496170108672\n",
      "Training model 1749: (19,59) ...\n",
      "2.1522825789870694\n",
      "Training model 1750: (19,60) ...\n",
      "2.1847820800030604\n",
      "Training model 1751: (19,61) ...\n",
      "2.2161807420197874\n",
      "Training model 1752: (19,62) ...\n",
      "2.1419554929889273\n",
      "Training model 1753: (19,63) ...\n",
      "2.193998039001599\n",
      "Training model 1754: (19,64) ...\n",
      "2.1874799799988978\n",
      "Training model 1755: (19,65) ...\n",
      "2.1855003600066993\n",
      "Training model 1756: (19,66) ...\n",
      "2.1653718780144118\n",
      "Training model 1757: (19,67) ...\n",
      "2.153027454012772\n",
      "Training model 1758: (19,68) ...\n",
      "2.171785460988758\n",
      "Training model 1759: (19,69) ...\n",
      "2.15150984399952\n",
      "Training model 1760: (19,70) ...\n",
      "2.187147588992957\n",
      "Training model 1761: (19,71) ...\n",
      "2.168096172012156\n",
      "Training model 1762: (19,72) ...\n",
      "1.9882442459929734\n",
      "Training model 1763: (19,73) ...\n",
      "2.215988717012806\n",
      "Training model 1764: (19,74) ...\n",
      "2.207079571002396\n",
      "Training model 1765: (19,75) ...\n",
      "2.3217920470051467\n",
      "Training model 1766: (19,76) ...\n",
      "2.303724773984868\n",
      "Training model 1767: (19,77) ...\n",
      "2.146206761011854\n",
      "Training model 1768: (19,78) ...\n",
      "2.150899346015649\n",
      "Training model 1769: (19,79) ...\n",
      "2.00023777000024\n",
      "Training model 1770: (19,80) ...\n",
      "2.209948034986155\n",
      "Training model 1771: (19,81) ...\n",
      "2.205237660004059\n",
      "Training model 1772: (19,82) ...\n",
      "2.168261838000035\n",
      "Training model 1773: (19,83) ...\n",
      "2.161633198003983\n",
      "Training model 1774: (19,84) ...\n",
      "2.175846457015723\n",
      "Training model 1775: (19,85) ...\n",
      "2.1786127879749984\n",
      "Training model 1776: (19,86) ...\n",
      "2.164984472008655\n",
      "Training model 1777: (19,87) ...\n",
      "2.1801135150017217\n",
      "Training model 1778: (19,88) ...\n",
      "2.168829864996951\n",
      "Training model 1779: (19,89) ...\n",
      "2.2715067450189963\n",
      "Training model 1780: (19,90) ...\n",
      "2.197739127994282\n",
      "Training model 1781: (19,91) ...\n",
      "2.1512948450108524\n",
      "Training model 1782: (19,92) ...\n",
      "2.1487782660115045\n",
      "Training model 1783: (19,93) ...\n",
      "2.1827386590011884\n",
      "Training model 1784: (19,94) ...\n",
      "2.006355034012813\n",
      "Training model 1785: (19,95) ...\n",
      "2.197933167015435\n",
      "Training model 1786: (19,96) ...\n",
      "2.186441362980986\n",
      "Training model 1787: (19,97) ...\n",
      "2.1999737120058853\n",
      "Training model 1788: (19,98) ...\n",
      "2.196840468008304\n",
      "Training model 1789: (19,99) ...\n",
      "2.0153652759909164\n",
      "Training model 1790: (20,21) ...\n",
      "2.210553962009726\n",
      "Training model 1791: (20,22) ...\n",
      "2.3246645090111997\n",
      "Training model 1792: (20,23) ...\n",
      "2.168396713997936\n",
      "Training model 1793: (20,24) ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.147461567976279\n",
      "Training model 1794: (20,25) ...\n",
      "2.1862411060137674\n",
      "Training model 1795: (20,26) ...\n",
      "2.1710259079991374\n",
      "Training model 1796: (20,27) ...\n",
      "2.1717326329962816\n",
      "Training model 1797: (20,28) ...\n",
      "2.1699654550175183\n",
      "Training model 1798: (20,29) ...\n",
      "2.163715394010069\n",
      "Training model 1799: (20,30) ...\n",
      "2.17180939798709\n",
      "Training model 1800: (20,31) ...\n",
      "2.1799733709776774\n",
      "Training model 1801: (20,32) ...\n",
      "2.1828669589885976\n",
      "Training model 1802: (20,33) ...\n",
      "2.169737588003045\n",
      "Training model 1803: (20,34) ...\n",
      "2.017398937023245\n",
      "Training model 1804: (20,35) ...\n",
      "2.057833128987113\n",
      "Training model 1805: (20,36) ...\n",
      "2.1758614029968157\n",
      "Training model 1806: (20,37) ...\n",
      "2.1805927489767782\n",
      "Training model 1807: (20,38) ...\n",
      "2.180203762021847\n",
      "Training model 1808: (20,39) ...\n",
      "2.191424704011297\n",
      "Training model 1809: (20,40) ...\n",
      "2.1771993539878167\n",
      "Training model 1810: (20,41) ...\n",
      "2.2029927159892395\n",
      "Training model 1811: (20,42) ...\n",
      "2.2209898410073947\n",
      "Training model 1812: (20,43) ...\n",
      "2.250595510995481\n",
      "Training model 1813: (20,44) ...\n",
      "2.2173425999935716\n",
      "Training model 1814: (20,45) ...\n",
      "2.208435215987265\n",
      "Training model 1815: (20,46) ...\n",
      "2.167239978996804\n",
      "Training model 1816: (20,47) ...\n",
      "2.141528697015019\n",
      "Training model 1817: (20,48) ...\n",
      "2.1512355010199826\n",
      "Training model 1818: (20,49) ...\n",
      "2.2164557070063893\n",
      "Training model 1819: (20,50) ...\n",
      "2.164211775001604\n",
      "Training model 1820: (20,51) ...\n",
      "2.2801248720206786\n",
      "Training model 1821: (20,52) ...\n",
      "2.8955176339950413\n",
      "Training model 1822: (20,53) ...\n",
      "2.5538485549914185\n",
      "Training model 1823: (20,54) ...\n",
      "2.232474532997003\n",
      "Training model 1824: (20,55) ...\n",
      "2.131953176984098\n",
      "Training model 1825: (20,56) ...\n",
      "1.9143907460093033\n",
      "Training model 1826: (20,57) ...\n",
      "2.3182952929928433\n",
      "Training model 1827: (20,58) ...\n",
      "2.1909941080084536\n",
      "Training model 1828: (20,59) ...\n",
      "2.3357353290193714\n",
      "Training model 1829: (20,60) ...\n",
      "2.1601175440009683\n",
      "Training model 1830: (20,61) ...\n",
      "2.1896391670161393\n",
      "Training model 1831: (20,62) ...\n",
      "2.127161326992791\n",
      "Training model 1832: (20,63) ...\n",
      "2.1786013710079715\n",
      "Training model 1833: (20,64) ...\n",
      "2.146017058985308\n",
      "Training model 1834: (20,65) ...\n",
      "2.2280715240049176\n",
      "Training model 1835: (20,66) ...\n",
      "2.139600048016291\n",
      "Training model 1836: (20,67) ...\n",
      "2.0139113740005996\n",
      "Training model 1837: (20,68) ...\n",
      "2.142312153999228\n",
      "Training model 1838: (20,69) ...\n",
      "2.139554035005858\n",
      "Training model 1839: (20,70) ...\n",
      "2.1452872380032204\n",
      "Training model 1840: (20,71) ...\n",
      "2.162222284998279\n",
      "Training model 1841: (20,72) ...\n",
      "2.1347958959813695\n",
      "Training model 1842: (20,73) ...\n",
      "2.1378463250002824\n",
      "Training model 1843: (20,74) ...\n",
      "2.13999173900811\n",
      "Training model 1844: (20,75) ...\n",
      "2.1049514330225065\n",
      "Training model 1845: (20,76) ...\n",
      "2.1428184770047665\n",
      "Training model 1846: (20,77) ...\n",
      "2.140662963996874\n",
      "Training model 1847: (20,78) ...\n",
      "2.1406326180149335\n",
      "Training model 1848: (20,79) ...\n",
      "2.1381109509966336\n",
      "Training model 1849: (20,80) ...\n",
      "2.148665919987252\n",
      "Training model 1850: (20,81) ...\n",
      "2.120699661987601\n",
      "Training model 1851: (20,82) ...\n",
      "2.1414700280001853\n",
      "Training model 1852: (20,83) ...\n",
      "2.1388024350162596\n",
      "Training model 1853: (20,84) ...\n",
      "2.1350468199816532\n",
      "Training model 1854: (20,85) ...\n",
      "2.1392670549976174\n",
      "Training model 1855: (20,86) ...\n",
      "2.1233726360078435\n",
      "Training model 1856: (20,87) ...\n",
      "2.13743605100899\n",
      "Training model 1857: (20,88) ...\n",
      "2.135512529988773\n",
      "Training model 1858: (20,89) ...\n",
      "2.136778084008256\n",
      "Training model 1859: (20,90) ...\n",
      "2.1060100000177044\n",
      "Training model 1860: (20,91) ...\n",
      "2.1458305069827475\n",
      "Training model 1861: (20,92) ...\n",
      "2.142969715001527\n",
      "Training model 1862: (20,93) ...\n",
      "2.142954037000891\n",
      "Training model 1863: (20,94) ...\n",
      "2.135159079974983\n",
      "Training model 1864: (20,95) ...\n",
      "2.145265144004952\n",
      "Training model 1865: (20,96) ...\n",
      "2.1511676590016577\n",
      "Training model 1866: (20,97) ...\n",
      "2.159999258001335\n",
      "Training model 1867: (20,98) ...\n",
      "2.1652418820012826\n",
      "Training model 1868: (20,99) ...\n",
      "2.1681532969814725\n",
      "Training model 1869: (21,22) ...\n",
      "2.1685896099952515\n",
      "Training model 1870: (21,23) ...\n",
      "2.1698174270277377\n",
      "Training model 1871: (21,24) ...\n",
      "2.187101587012876\n",
      "Training model 1872: (21,25) ...\n",
      "2.022160382999573\n",
      "Training model 1873: (21,26) ...\n",
      "2.2248163809999824\n",
      "Training model 1874: (21,27) ...\n",
      "2.1943511909921654\n",
      "Training model 1875: (21,28) ...\n",
      "2.1535664109978825\n",
      "Training model 1876: (21,29) ...\n",
      "2.1968042030057404\n",
      "Training model 1877: (21,30) ...\n",
      "2.1852427390113007\n",
      "Training model 1878: (21,31) ...\n",
      "2.2001174630131572\n",
      "Training model 1879: (21,32) ...\n",
      "2.1722427980275825\n",
      "Training model 1880: (21,33) ...\n",
      "2.019371294998564\n",
      "Training model 1881: (21,34) ...\n",
      "2.206123497977387\n",
      "Training model 1882: (21,35) ...\n",
      "2.1868846400175244\n",
      "Training model 1883: (21,36) ...\n",
      "2.309324737987481\n",
      "Training model 1884: (21,37) ...\n",
      "1.9194937070133165\n",
      "Training model 1885: (21,38) ...\n",
      "2.1841130279935896\n",
      "Training model 1886: (21,39) ...\n",
      "2.1400054290133994\n",
      "Training model 1887: (21,40) ...\n",
      "2.255936290981481\n",
      "Training model 1888: (21,41) ...\n",
      "2.2832014599989634\n",
      "Training model 1889: (21,42) ...\n",
      "2.213737582002068\n",
      "Training model 1890: (21,43) ...\n"
     ]
    }
   ],
   "source": [
    "# Initialize things\n",
    "n, d = X_train_subset.shape\n",
    "lam = 1\n",
    "beta_init = np.zeros(n)\n",
    "theta_init = np.zeros(n)\n",
    "maxiter = 10\n",
    "pairwise_linsvc_ovo = dict()\n",
    "t = 0\n",
    "\n",
    "for i in range(classes):\n",
    "    for j in range(i+1, classes):\n",
    "        start = timer()\n",
    "        print('Training model '+str(t)+': ('+str(i)+','+str(j)+') ...')\n",
    "        beta_list = list()\n",
    "        X_train_subset, y_train_subset = subset_data(i, j, X_train, y_train)\n",
    "        K = gram_linear(X_train_subset, X_train_subset)\n",
    "        eta_init = initstepsize(K, lam)\n",
    "        \n",
    "        beta_list = fastgradalgo(beta_init, theta_init, K, y_train_subset, lam, eta_init, maxiter, eps=1e-2)\n",
    "        beta_T = beta_list[len(beta_list)-1]\n",
    "        \n",
    "        pairwise_linsvc_ovo[(i, j)] = beta_T\n",
    "        \n",
    "        end = timer()\n",
    "        print(end - start)\n",
    "        t += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump( pairwise_linsvc_ovo, open( \"pairwise_linsvc_ovo_betas.p\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pairwise_misclassification_error_predict(clfs, X_train, X_test, y_test, kernel):\n",
    "    n_test = len(X_test)\n",
    "    y_pred = np.zeros(n_test)\n",
    "    y_vals = np.zeros(n_test)\n",
    "    \n",
    "    for i in range(n_test):\n",
    "        y_pred[i] = majority_vote(list(map(\n",
    "            lambda c: c[0] \n",
    "                if np.sign(np.dot(kernel(\n",
    "                    subset_data(c[0], c[1], X_train, y_train)[0], X_test[i, :]\n",
    "                ).reshape(-1), clfs[c])) == 1 \n",
    "                else c[1], clfs)))\n",
    "    \n",
    "    if y_test is not None:\n",
    "        return np.mean(y_pred != y_test)\n",
    "    else:\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairwise_misclassification_error_predict(pairwise_linsvc_ovo, X_train, X_val, y_val, gram_linear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_preds_linsvc_ovo = \\\n",
    "    pairwise_misclassification_error_predict(pairwise_linsvc_ovo, X_train, X_test, None, gram_linear)\n",
    "\n",
    "# Write to CSV for Kaggle submission\n",
    "pd.DataFrame({'Category':y_test_preds_linsvc_ovo}).reset_index()\\\n",
    "             .rename(columns={'index':'Id'}).to_csv('./comp2-subm_linsvc_ovo.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interestingly, I was able to train my one-vs-one SVM classifier in a reasonable amount of time (with the appropriate max_iteration parameters). However, I got stuck with making predicitions. At the point of writing, I've been running the prediction function for over 2 days and unfortunately I'm out of time to finish running it. \n",
    "\n",
    "Analyzing the computational complexity of my prediction function, it appears it should be O(n_test \\* C) where C is the number of OvO classifiers = $\\frac{k(k-1)}{2}$ where k is the number of classes. Thus this function runs at roughly O(n*$k^2$). \n",
    "\n",
    "To the best of my knowledge, all classifiers need to make predictions since we're taking a majority vote here for each prediction. Upon reflection perhaps my majority vote code could also be vectorized/optimized. I find the slowdown occurs when finding the random choice between tied codes. If we simply predicted the minimum mode of each prediction group, my code would run a lot faster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7: Training with my implementation of linear SVM (one-vs-rest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize things\n",
    "classes = 100\n",
    "n, d = X_train_subset.shape\n",
    "lam = 1\n",
    "beta_init = np.zeros(n)\n",
    "theta_init = np.zeros(n)\n",
    "maxiter = 10\n",
    "linsvc_ovr = dict()\n",
    "t = 0\n",
    "\n",
    "for i in range(classes):\n",
    "    start = timer()\n",
    "    print('Training model '+str(i)+'...')\n",
    "    beta_list = list()\n",
    "    rest_of_classes = list(np.delete(np.arange(classes), i))\n",
    "    X_train_subset, y_train_subset = subset_data(i, rest_of_classes, X_train, y_train)\n",
    "    K = gram_linear(X_train_subset, X_train_subset)\n",
    "    eta_init = initstepsize(K, lam)\n",
    "\n",
    "    beta_list = fastgradalgo(beta_init, theta_init, K, y_train_subset, lam, eta_init, maxiter, eps=1e-1)\n",
    "    beta_T = beta_list[len(beta_list)-1]\n",
    "\n",
    "    linsvc_ovr[i] = beta_T\n",
    "\n",
    "    end = timer()\n",
    "    print(end - start)\n",
    "    t += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ovr_misclassification_error_predict(clfs, X_train, X_test, y_test, kernel):\n",
    "    n_test = len(X_test)\n",
    "    y_pred = np.zeros(n_test)\n",
    "    y_vals = np.zeros(n_test)\n",
    "    \n",
    "    for i in range(n_test):\n",
    "        y_pred[i] = majority_vote(list(map(\n",
    "            lambda c: c \n",
    "                if np.dot(kernel(\n",
    "                    subset_data(c, list(np.delete(np.arange(classes), c)), X_train, y_train)[0], X_test[i, :]\n",
    "                ).reshape(-1), clfs[c]) > 0 \n",
    "                else -1, clfs)))\n",
    "    \n",
    "    if y_test is not None:\n",
    "        return np.mean(y_pred != y_test)\n",
    "    else:\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ovr_misclassification_error_predict(linsvc_ovr, X_train, X_val, y_val, gram_linear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_preds_linsvc_ovr = \\\n",
    "    pairwise_misclassification_error_predict(pairwise_linsvc_ovr, X_train, X_test, None, gram_linear)\n",
    "\n",
    "# Write to CSV for Kaggle submission\n",
    "pd.DataFrame({'Category':y_test_preds_linsvc_ovo}).reset_index()\\\n",
    "             .rename(columns={'index':'Id'}).to_csv('./comp2-subm_linsvc_ovo.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above code runs my implementation of One-vs-Rest SVM classifier. As mentioned above due to time constraints I wasn't able to complete the running of this code. The classifier trains k models (where k is the number of classes) where each class is selected as the positive class once and the rest of the classes are treated as negative.\n",
    "\n",
    "Come prediction time, each model will make a prediction: the selected prediction will be the class predicted to be the furthest away from the decision boundary (most positive value). If the prediction is negative for a particular classifier than no prediction is made for that particular classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In my experience doing this data competition project, it was interesting to me to see that OvO classifiers seemed to perform better than OvR classifiers. I reserve the possibility that I could have been doing something wrong, but after considering the two approaches more, it does make sense. \n",
    "\n",
    "One weakness of OvR classifiers is when the positive class is not predicted. Given a multi-class classification problem with many classes, the negative class predictions are essentially useless (it appears). For OvO, many negative class predictions may be wrong, but at least that specific pairwise OvO classifier is doing it's prescribed job at comparing one class vs the other. \n",
    "\n",
    "One tradeoff comes in terms of computational complexity. There needs to be more models trained for OvO classifiers (k*(k-1)/2, where as OvR only needs k classifiers. However, each OvO classifier only considers 2/k fraction of the dataset, while each OvR classifier trains on the whole dataset k times. Perhaps the relative values of k and n should give you clues as to which approach is best."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
